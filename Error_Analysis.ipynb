{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V100","authorship_tag":"ABX9TyOT9cPN1gbaBVzh1wbFlTyD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"a7cfdf9b849143278b80e7f29ef96d4e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3740c2ab171b44c5b15b5e06ab55b8ac","IPY_MODEL_1596e0a908e64fe1bf8ba4c55f249249","IPY_MODEL_d236c6f916324ce7aede41de18879f72"],"layout":"IPY_MODEL_62888df43c6c4e87903d1f36d9e2f2af"}},"3740c2ab171b44c5b15b5e06ab55b8ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_021849f95dd7463588fa12bfb36defed","placeholder":"​","style":"IPY_MODEL_cfb271fbdd3e4dada1f93848408c3ad3","value":"Downloading (…)okenizer_config.json: 100%"}},"1596e0a908e64fe1bf8ba4c55f249249":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ec9838b17db4f5ab3b44266cce5ecf5","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c1738bc35f0b43c28825a118663c96f2","value":28}},"d236c6f916324ce7aede41de18879f72":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_254fc6da957e4bb2b16858da8016b08f","placeholder":"​","style":"IPY_MODEL_807b356d3a3d44b08bb83a0ae3c2155c","value":" 28.0/28.0 [00:00&lt;00:00, 2.18kB/s]"}},"62888df43c6c4e87903d1f36d9e2f2af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"021849f95dd7463588fa12bfb36defed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfb271fbdd3e4dada1f93848408c3ad3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ec9838b17db4f5ab3b44266cce5ecf5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1738bc35f0b43c28825a118663c96f2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"254fc6da957e4bb2b16858da8016b08f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"807b356d3a3d44b08bb83a0ae3c2155c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f38bb00100a4b898c542012e16371ff":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f20e28691cac49f39b32609592af4666","IPY_MODEL_cacfa96773884a2c91c125be74e138fe","IPY_MODEL_52810c24efec472280c31c3d0acf3337"],"layout":"IPY_MODEL_3af6bcfb20c944f780594a0b1eb486ff"}},"f20e28691cac49f39b32609592af4666":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd364949bd5d4089b39b0a96dc7f7404","placeholder":"​","style":"IPY_MODEL_49eea9ff077f43d59d7b5f0b0026f59a","value":"Downloading (…)lve/main/config.json: 100%"}},"cacfa96773884a2c91c125be74e138fe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_67399c6c7fbd4b0696b546ae4d0a5572","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_30872eadeda74442b57759bc99e34118","value":570}},"52810c24efec472280c31c3d0acf3337":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5d1bb8735054267bc1a094964637b40","placeholder":"​","style":"IPY_MODEL_70ce70e69e96425d8d41a48dd29a3a0b","value":" 570/570 [00:00&lt;00:00, 45.8kB/s]"}},"3af6bcfb20c944f780594a0b1eb486ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd364949bd5d4089b39b0a96dc7f7404":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49eea9ff077f43d59d7b5f0b0026f59a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"67399c6c7fbd4b0696b546ae4d0a5572":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30872eadeda74442b57759bc99e34118":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e5d1bb8735054267bc1a094964637b40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70ce70e69e96425d8d41a48dd29a3a0b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2a887bc4b90c45018cb5acfa1763aeee":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f1e33e24cb594a9dac1478415f75fb59","IPY_MODEL_31d735d541b74cae8c7d66e200ded15b","IPY_MODEL_4f73feb6d53a4eb49bc5017601a62443"],"layout":"IPY_MODEL_f1d2372b657649f4b764feb13d75c4d9"}},"f1e33e24cb594a9dac1478415f75fb59":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fe7627be91a84100b9356929f76d3d5f","placeholder":"​","style":"IPY_MODEL_991d968ec35e4a7894d9187982f2cdd5","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"31d735d541b74cae8c7d66e200ded15b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1142f30c082454794fc67f7aa701d81","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4aeecfa438f4441c8140042e114c2775","value":231508}},"4f73feb6d53a4eb49bc5017601a62443":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7bb3537f64343cb970e466c4167db52","placeholder":"​","style":"IPY_MODEL_130b0b914b4048e58a2b75d0c636b8b9","value":" 232k/232k [00:00&lt;00:00, 1.39MB/s]"}},"f1d2372b657649f4b764feb13d75c4d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe7627be91a84100b9356929f76d3d5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"991d968ec35e4a7894d9187982f2cdd5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d1142f30c082454794fc67f7aa701d81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4aeecfa438f4441c8140042e114c2775":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a7bb3537f64343cb970e466c4167db52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"130b0b914b4048e58a2b75d0c636b8b9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a15ec6f52df1496e83f2a595427b8f84":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4643e20984f4412f842f90e50d3867ff","IPY_MODEL_6d4c846730e54bfbb251c40239b1d7d7","IPY_MODEL_0ae84c91100a40a98a513e8cf73d27ca"],"layout":"IPY_MODEL_255f2fcd8e2d482a9ecce1c2082c4c07"}},"4643e20984f4412f842f90e50d3867ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_26e29e92f6b24460aca75b44133dc570","placeholder":"​","style":"IPY_MODEL_c6f56a70db8946948d7dbc581e71a374","value":"Downloading (…)/main/tokenizer.json: 100%"}},"6d4c846730e54bfbb251c40239b1d7d7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a03ea5883734ea496b72630b0c9f771","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_13b92174a6904b79b01cbe9cbc108e11","value":466062}},"0ae84c91100a40a98a513e8cf73d27ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b6477d01a0c48a4b364f1374b2fc0e4","placeholder":"​","style":"IPY_MODEL_b78f33c2f86f4a1bbc777c0307c208f8","value":" 466k/466k [00:00&lt;00:00, 1.89MB/s]"}},"255f2fcd8e2d482a9ecce1c2082c4c07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26e29e92f6b24460aca75b44133dc570":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6f56a70db8946948d7dbc581e71a374":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a03ea5883734ea496b72630b0c9f771":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13b92174a6904b79b01cbe9cbc108e11":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6b6477d01a0c48a4b364f1374b2fc0e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b78f33c2f86f4a1bbc777c0307c208f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ae09c812fb447878f9c1bf95b1cb96f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_808e861f397e4d99ba9256342ac250e0","IPY_MODEL_4c9223a4713e4b09a38095f0173fa0dc","IPY_MODEL_74128d32040d47d0af90622454e197e4"],"layout":"IPY_MODEL_11e6920d30c64572834ad61e8c6b2792"}},"808e861f397e4d99ba9256342ac250e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_55a0d62e186c4bb298e5f3e0ff1506d3","placeholder":"​","style":"IPY_MODEL_a85a1e9ec0024efba0ebc7ff1aefb7e4","value":"Downloading model.safetensors: 100%"}},"4c9223a4713e4b09a38095f0173fa0dc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ada7673543942bf9040e99e1f7a92fe","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cde4b98c85d14a9385f5f76e9c975683","value":440449768}},"74128d32040d47d0af90622454e197e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f276daa75ef4c8b974894a4d85eb0d1","placeholder":"​","style":"IPY_MODEL_6216ce3997d54a448b8ab763b403d611","value":" 440M/440M [00:01&lt;00:00, 358MB/s]"}},"11e6920d30c64572834ad61e8c6b2792":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55a0d62e186c4bb298e5f3e0ff1506d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a85a1e9ec0024efba0ebc7ff1aefb7e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ada7673543942bf9040e99e1f7a92fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cde4b98c85d14a9385f5f76e9c975683":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1f276daa75ef4c8b974894a4d85eb0d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6216ce3997d54a448b8ab763b403d611":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25584bc1aa1b4c7884cf6423e44e2bc4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d79f2659ece8424aa06cec9abcbc6bbd","IPY_MODEL_20594eff7a1c4ee4a7fb43cb49d9d5ef","IPY_MODEL_76c025cb89494b77b4f8466253f87e7c"],"layout":"IPY_MODEL_5d36526386884def85976b3c8aeaa718"}},"d79f2659ece8424aa06cec9abcbc6bbd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eef3b114a66e4d19af719c5edafa9dc2","placeholder":"​","style":"IPY_MODEL_808dfb1adc964143978d19f2a500f0f3","value":"Running tokenizer on train dataset: 100%"}},"20594eff7a1c4ee4a7fb43cb49d9d5ef":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ac4b62d985b4d52805678291ac9efa9","max":5583,"min":0,"orientation":"horizontal","style":"IPY_MODEL_47e29e0542f040a3bb29cbacd5d0b785","value":5583}},"76c025cb89494b77b4f8466253f87e7c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff048be67a3440e18a8bdaa57e97b6e4","placeholder":"​","style":"IPY_MODEL_1f748b4d412b42aca566451900ffb39c","value":" 5583/5583 [00:00&lt;00:00, 10792.64 examples/s]"}},"5d36526386884def85976b3c8aeaa718":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eef3b114a66e4d19af719c5edafa9dc2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"808dfb1adc964143978d19f2a500f0f3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ac4b62d985b4d52805678291ac9efa9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47e29e0542f040a3bb29cbacd5d0b785":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ff048be67a3440e18a8bdaa57e97b6e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f748b4d412b42aca566451900ffb39c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1eKIYY-HE4qJ","executionInfo":{"status":"ok","timestamp":1693762482021,"user_tz":-60,"elapsed":64422,"user":{"displayName":"Sumit Gupta","userId":"07308348120090087318"}},"outputId":"fdbe7a21-1b25-439d-f3f0-febadb5e2ef5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Collecting transformers\n","  Downloading transformers-4.32.1-py3-none-any.whl (7.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.32.1\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n","Collecting datasets\n","  Downloading datasets-2.14.4-py3-none-any.whl (519 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.3/519.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, dill, multiprocess, datasets\n","Successfully installed datasets-2.14.4 dill-0.3.7 multiprocess-0.70.15 xxhash-3.3.0\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.10.1)\n","Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.23.5)\n","Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.32.1)\n","Collecting accelerate\n","  Downloading accelerate-0.22.0-py3-none-any.whl (251 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.2/251.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.16.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.3.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n","Requirement already satisfied: torch!=1.12.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.0.1+cu118)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers[torch]) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers[torch]) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]) (3.27.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]) (16.0.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.9->transformers[torch]) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.9->transformers[torch]) (1.3.0)\n","Installing collected packages: accelerate\n","Successfully installed accelerate-0.22.0\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.3.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Collecting nlpaug\n","  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.23.5)\n","Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.5.3)\n","Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.31.0)\n","Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (4.6.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (3.12.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (1.16.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.66.1)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.11.2)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2023.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2023.7.22)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.4.1)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (1.7.1)\n","Installing collected packages: nlpaug\n","Successfully installed nlpaug-1.1.11\n"]}],"source":["! pip install torch\n","! pip install transformers\n","! pip install scikit-learn\n","! pip install tqdm\n","! pip install numpy\n","! pip install datasets\n","! pip install nltk\n","import nltk\n","nltk.download('stopwords')\n","! pip install scipy\n","! pip install transformers[torch] accelerate\n","\n","! pip install datasets\n","import json\n","from datasets import Dataset\n","\n","import pandas as pd\n","! pip install nlpaug"]},{"cell_type":"code","source":["##Unfair-TOS\n","# Load JSON data from file\n","file_path = '/content/sample_data/incorrect_predictions_dataset (4).json'\n","with open(file_path, 'r') as json_file:\n","    data = json.load(json_file)\n","\n","# Create a dictionary to store original_labels\n","labels_dict = {}\n","text_dict ={}\n","labels =[]\n","\n","# Iterate through the data and extract original_labels\n","for entry in data:\n","    if \"original_labels\" in entry:\n","        original_labels = entry[\"original_labels\"]\n","        if \"Index\" in entry:\n","            index = entry[\"Index\"]\n","            labels_dict[index] = original_labels\n","        if \"text\" in entry:\n","            text = entry[\"text\"]\n","            text_dict[index]={\n","                \"original_labels\": original_labels,\n","                \"text\": text\n","            }\n","        elif len(labels_dict) > 0:\n","            last_index = max(labels_dict.keys())\n","            labels_dict[last_index].extend(original_labels)\n","        labels.append(original_labels)\n","\n","print(\"*********\")\n","print(len(text_dict))\n","# Initialize lists to store texts and labels\n","texts = []\n","text= []\n","#labels = label_lists[0:173]\n","print(\"#####\")\n","print(len(labels))\n","# Iterate through the data and extract relevant information\n","for entry in data:\n","    if \"text\" in entry:\n","        text = entry[\"text\"]\n","        if \"Index\" in entry:\n","            index = entry[\"Index\"]\n","            #labels.append(labels_dict.get(index, []))\n","        else:\n","            # Use the last index available in labels_dict\n","            last_index = max(labels_dict.keys())\n","            #labels.append(labels_dict.get(last_index, []))\n","        texts.append(text)\n","\n","print(\"Number of Texts:\", len(texts))\n","print(\"Number of Labels:\", len(labels))\n","\n","original_label_counts = {}\n","for label_list in labels:\n","    for label in label_list:\n","        if label in original_label_counts:\n","            original_label_counts[label] += 1\n","        else:\n","            original_label_counts[label] = 1\n","\n","# Find the most occurring original label\n","most_common_original_label = max(original_label_counts, key=original_label_counts.get)\n","print(\"Most Common Original Label:\", most_common_original_label)\n","print(\"Occurrences:\", original_label_counts[most_common_original_label])\n","\n","\n","first_occurrence_index = None\n","for index, label_list in enumerate(labels):\n","    if most_common_original_label in label_list:\n","        first_occurrence_index = index\n","        break\n","\n","print(\"First Occurrence Index of Label 2:\", first_occurrence_index)\n","\n","print(\"Text:\", texts[first_occurrence_index])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kA5Xfml5ZDqH","executionInfo":{"status":"ok","timestamp":1693762482022,"user_tz":-60,"elapsed":32,"user":{"displayName":"Sumit Gupta","userId":"07308348120090087318"}},"outputId":"6c315034-1c8b-4fd7-a8c3-60090173a0d0"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["*********\n","0\n","#####\n","171\n","Number of Texts: 171\n","Number of Labels: 171\n","Most Common Original Label: 2\n","Occurrences: 38\n","First Occurrence Index of Label 2: 2\n","Text: academia.edu reserves the right , at its sole discretion , to modify the site , services and these terms , at any time and without prior notice .\n"]}]},{"cell_type":"code","source":["import nlpaug.augmenter.word as naw\n","import random\n","\n","# Most common original label and corresponding text\n","most_common_original_label = most_common_original_label\n","corresponding_text = texts[first_occurrence_index]\n","\n","# Initialize augmenter\n","aug = naw.SynonymAug(aug_src='wordnet', aug_p=0.3)\n","\n","# Apply data augmentation to the corresponding text\n","augmented_texts = [aug.augment(corresponding_text) for _ in range(50)]  # Generate 5 augmented examples\n","\n","# Print augmented texts\n","print(\"Original Text:\", corresponding_text)\n","print(len(augmented_texts))\n","\n","augmented_labels=[]\n","for i in range(len(augmented_texts)+1):\n","    augmented_labels.append([most_common_original_label])\n","\n","print(len(augmented_labels))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QBMDfBUMpwhK","executionInfo":{"status":"ok","timestamp":1693763858394,"user_tz":-60,"elapsed":553,"user":{"displayName":"Sumit Gupta","userId":"07308348120090087318"}},"outputId":"9687a995-4337-4f8b-9fe5-bb389e2a4b4e"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Text: academia.edu reserves the right , at its sole discretion , to modify the site , services and these terms , at any time and without prior notice .\n","50\n","51\n"]}]},{"cell_type":"code","source":["from datasets import load_dataset\n","existing_dataset = load_dataset(\"lex_glue\", 'unfair_tos')\n","augmented_texts_flat = [text[0] for text in augmented_texts]\n","data = {\n","    \"text\": [corresponding_text] + augmented_texts_flat,\n","    \"label\": [most_common_original_label] * (len(augmented_texts) + 1)  # Use the most common label\n","}\n","augmented_dataset = Dataset.from_dict(data)\n","\n","# Create a Dataset instance\n","augmented_dataset = Dataset.from_dict(data)\n","merged_dataset = Dataset.from_dict({\n","    \"text\": existing_dataset[\"train\"][\"text\"] + augmented_dataset[\"text\"],\n","    \"labels\": existing_dataset[\"train\"][\"labels\"] + augmented_labels,\n","})"],"metadata":{"id":"-U2a7pIZpeIj","executionInfo":{"status":"ok","timestamp":1693763863442,"user_tz":-60,"elapsed":1693,"user":{"displayName":"Sumit Gupta","userId":"07308348120090087318"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["from dataclasses import dataclass\n","from typing import Optional, Tuple\n","\n","import torch\n","import numpy as np\n","from torch import nn\n","from transformers.file_utils import ModelOutput\n","\n","\n","@dataclass\n","class SimpleOutput(ModelOutput):\n","    last_hidden_state: torch.FloatTensor = None\n","    past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n","    hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n","    attentions: Optional[Tuple[torch.FloatTensor]] = None\n","    cross_attentions: Optional[Tuple[torch.FloatTensor]] = None\n","\n","\n","def sinusoidal_init(num_embeddings: int, embedding_dim: int):\n","    # keep dim 0 for padding token position encoding zero vector\n","    position_enc = np.array([\n","        [pos / np.power(10000, 2 * i / embedding_dim) for i in range(embedding_dim)]\n","        if pos != 0 else np.zeros(embedding_dim) for pos in range(num_embeddings)])\n","\n","    position_enc[1:, 0::2] = np.sin(position_enc[1:, 0::2])  # dim 2i\n","    position_enc[1:, 1::2] = np.cos(position_enc[1:, 1::2])  # dim 2i+1\n","    return torch.from_numpy(position_enc).type(torch.FloatTensor)\n","\n","\n","class HierarchicalBert(nn.Module):\n","\n","    def __init__(self, encoder, max_segments=64, max_segment_length=128):\n","        super(HierarchicalBert, self).__init__()\n","        supported_models = ['bert', 'roberta', 'deberta']\n","        assert encoder.config.model_type in supported_models  # other model types are not supported so far\n","        # Pre-trained segment (token-wise) encoder, e.g., BERT\n","        self.encoder = encoder\n","        # Specs for the segment-wise encoder\n","        self.hidden_size = encoder.config.hidden_size\n","        self.max_segments = max_segments\n","        self.max_segment_length = max_segment_length\n","        # Init sinusoidal positional embeddings\n","        self.seg_pos_embeddings = nn.Embedding(max_segments + 1, encoder.config.hidden_size,\n","                                               padding_idx=0,\n","                                               _weight=sinusoidal_init(max_segments + 1, encoder.config.hidden_size))\n","        # Init segment-wise transformer-based encoder\n","        self.seg_encoder = nn.Transformer(d_model=encoder.config.hidden_size,\n","                                          nhead=encoder.config.num_attention_heads,\n","                                          batch_first=True, dim_feedforward=encoder.config.intermediate_size,\n","                                          activation=encoder.config.hidden_act,\n","                                          dropout=encoder.config.hidden_dropout_prob,\n","                                          layer_norm_eps=encoder.config.layer_norm_eps,\n","                                          num_encoder_layers=2, num_decoder_layers=0).encoder\n","\n","    def forward(self,\n","                input_ids=None,\n","                attention_mask=None,\n","                token_type_ids=None,\n","                position_ids=None,\n","                head_mask=None,\n","                inputs_embeds=None,\n","                labels=None,\n","                output_attentions=None,\n","                output_hidden_states=None,\n","                return_dict=None,\n","                ):\n","        # Hypothetical Example\n","        # Batch of 4 documents: (batch_size, n_segments, max_segment_length) --> (4, 64, 128)\n","        # BERT-BASE encoder: 768 hidden units\n","\n","        # Squash samples and segments into a single axis (batch_size * n_segments, max_segment_length) --> (256, 128)\n","        input_ids_reshape = input_ids.contiguous().view(-1, input_ids.size(-1))\n","        attention_mask_reshape = attention_mask.contiguous().view(-1, attention_mask.size(-1))\n","        if token_type_ids is not None:\n","            token_type_ids_reshape = token_type_ids.contiguous().view(-1, token_type_ids.size(-1))\n","        else:\n","            token_type_ids_reshape = None\n","\n","        # Encode segments with BERT --> (256, 128, 768)\n","        encoder_outputs = self.encoder(input_ids=input_ids_reshape,\n","                                       attention_mask=attention_mask_reshape,\n","                                       token_type_ids=token_type_ids_reshape)[0]\n","\n","        # Reshape back to (batch_size, n_segments, max_segment_length, output_size) --> (4, 64, 128, 768)\n","        encoder_outputs = encoder_outputs.contiguous().view(input_ids.size(0), self.max_segments,\n","                                                            self.max_segment_length,\n","                                                            self.hidden_size)\n","\n","        # Gather CLS outputs per segment --> (4, 64, 768)\n","        encoder_outputs = encoder_outputs[:, :, 0]\n","\n","        # Infer real segments, i.e., mask paddings\n","        seg_mask = (torch.sum(input_ids, 2) != 0).to(input_ids.dtype)\n","        # Infer and collect segment positional embeddings\n","        seg_positions = torch.arange(1, self.max_segments + 1).to(input_ids.device) * seg_mask\n","        # Add segment positional embeddings to segment inputs\n","        encoder_outputs += self.seg_pos_embeddings(seg_positions)\n","\n","        # Encode segments with segment-wise transformer\n","        seg_encoder_outputs = self.seg_encoder(encoder_outputs)\n","\n","        # Collect document representation\n","        outputs, _ = torch.max(seg_encoder_outputs, 1)\n","\n","        return SimpleOutput(last_hidden_state=outputs, hidden_states=outputs)\n","\n","\n","if __name__ == \"__main__\":\n","    from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n","    tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","\n","    # Use as a stand-alone encoder\n","    bert = AutoModel.from_pretrained('bert-base-uncased')\n","    model = HierarchicalBert(encoder=bert, max_segments=64, max_segment_length=128)\n","\n","    fake_inputs = {'input_ids': [], 'attention_mask': [], 'token_type_ids': []}\n","    for i in range(4):\n","        # Tokenize segment\n","        temp_inputs = tokenizer(['dog ' * 126] * 64)\n","        fake_inputs['input_ids'].append(temp_inputs['input_ids'])\n","        fake_inputs['attention_mask'].append(temp_inputs['attention_mask'])\n","        fake_inputs['token_type_ids'].append(temp_inputs['token_type_ids'])\n","\n","    fake_inputs['input_ids'] = torch.as_tensor(fake_inputs['input_ids'])\n","    fake_inputs['attention_mask'] = torch.as_tensor(fake_inputs['attention_mask'])\n","    fake_inputs['token_type_ids'] = torch.as_tensor(fake_inputs['token_type_ids'])\n","\n","    output = model(fake_inputs['input_ids'], fake_inputs['attention_mask'], fake_inputs['token_type_ids'])\n","\n","    # 4 document representations of 768 features are expected\n","    assert output[0].shape == torch.Size([4, 768])\n","\n","    # Use with HuggingFace AutoModelForSequenceClassification and Trainer API\n","\n","    # Init Classifier\n","    model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=10)\n","    # Replace flat BERT encoder with hierarchical BERT encoder\n","    model.bert = HierarchicalBert(encoder=model.bert, max_segments=64, max_segment_length=128)\n","    output = model(fake_inputs['input_ids'], fake_inputs['attention_mask'], fake_inputs['token_type_ids'])\n","\n","    # 4 document outputs with 10 (num_labels) logits are expected\n","    assert output.logits.shape == torch.Size([4, 10])\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":233,"referenced_widgets":["a7cfdf9b849143278b80e7f29ef96d4e","3740c2ab171b44c5b15b5e06ab55b8ac","1596e0a908e64fe1bf8ba4c55f249249","d236c6f916324ce7aede41de18879f72","62888df43c6c4e87903d1f36d9e2f2af","021849f95dd7463588fa12bfb36defed","cfb271fbdd3e4dada1f93848408c3ad3","7ec9838b17db4f5ab3b44266cce5ecf5","c1738bc35f0b43c28825a118663c96f2","254fc6da957e4bb2b16858da8016b08f","807b356d3a3d44b08bb83a0ae3c2155c","1f38bb00100a4b898c542012e16371ff","f20e28691cac49f39b32609592af4666","cacfa96773884a2c91c125be74e138fe","52810c24efec472280c31c3d0acf3337","3af6bcfb20c944f780594a0b1eb486ff","bd364949bd5d4089b39b0a96dc7f7404","49eea9ff077f43d59d7b5f0b0026f59a","67399c6c7fbd4b0696b546ae4d0a5572","30872eadeda74442b57759bc99e34118","e5d1bb8735054267bc1a094964637b40","70ce70e69e96425d8d41a48dd29a3a0b","2a887bc4b90c45018cb5acfa1763aeee","f1e33e24cb594a9dac1478415f75fb59","31d735d541b74cae8c7d66e200ded15b","4f73feb6d53a4eb49bc5017601a62443","f1d2372b657649f4b764feb13d75c4d9","fe7627be91a84100b9356929f76d3d5f","991d968ec35e4a7894d9187982f2cdd5","d1142f30c082454794fc67f7aa701d81","4aeecfa438f4441c8140042e114c2775","a7bb3537f64343cb970e466c4167db52","130b0b914b4048e58a2b75d0c636b8b9","a15ec6f52df1496e83f2a595427b8f84","4643e20984f4412f842f90e50d3867ff","6d4c846730e54bfbb251c40239b1d7d7","0ae84c91100a40a98a513e8cf73d27ca","255f2fcd8e2d482a9ecce1c2082c4c07","26e29e92f6b24460aca75b44133dc570","c6f56a70db8946948d7dbc581e71a374","1a03ea5883734ea496b72630b0c9f771","13b92174a6904b79b01cbe9cbc108e11","6b6477d01a0c48a4b364f1374b2fc0e4","b78f33c2f86f4a1bbc777c0307c208f8","2ae09c812fb447878f9c1bf95b1cb96f","808e861f397e4d99ba9256342ac250e0","4c9223a4713e4b09a38095f0173fa0dc","74128d32040d47d0af90622454e197e4","11e6920d30c64572834ad61e8c6b2792","55a0d62e186c4bb298e5f3e0ff1506d3","a85a1e9ec0024efba0ebc7ff1aefb7e4","0ada7673543942bf9040e99e1f7a92fe","cde4b98c85d14a9385f5f76e9c975683","1f276daa75ef4c8b974894a4d85eb0d1","6216ce3997d54a448b8ab763b403d611"]},"id":"YCBHM1z2trTp","executionInfo":{"status":"ok","timestamp":1693762557485,"user_tz":-60,"elapsed":59077,"user":{"displayName":"Sumit Gupta","userId":"07308348120090087318"}},"outputId":"33cea561-4c9e-404c-f001-57bd9566303c"},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7cfdf9b849143278b80e7f29ef96d4e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f38bb00100a4b898c542012e16371ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a887bc4b90c45018cb5acfa1763aeee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a15ec6f52df1496e83f2a595427b8f84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ae09c812fb447878f9c1bf95b1cb96f"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["from torch import nn\n","from transformers import Trainer\n","\n","\n","class MultilabelTrainer(Trainer):\n","    def compute_loss(self, model, inputs, return_outputs=False):\n","        labels = inputs.pop(\"labels\")\n","        outputs = model(**inputs)\n","        logits = outputs.logits\n","        loss_fct = nn.BCEWithLogitsLoss()\n","        loss = loss_fct(logits.view(-1, self.model.config.num_labels),\n","                        labels.float().view(-1, self.model.config.num_labels))\n","        return (loss, outputs) if return_outputs else loss\n","\n","\n","\n"],"metadata":{"id":"bflMzu1vvORs","executionInfo":{"status":"ok","timestamp":1693762557487,"user_tz":-60,"elapsed":35,"user":{"displayName":"Sumit Gupta","userId":"07308348120090087318"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["#!/usr/bin/env python\n","# coding=utf-8\n","\"\"\" Finetuning models on UNFAIR-ToC (e.g. Bert, RoBERTa, LEGAL-BERT).\"\"\"\n","\n","import logging\n","import os\n","import random\n","import sys\n","from dataclasses import dataclass, field\n","from typing import Optional\n","\n","import datasets\n","from datasets import load_dataset\n","from sklearn.metrics import f1_score\n","\n","from scipy.special import expit\n","import glob\n","import shutil\n","import numpy as np\n","\n","import transformers\n","from transformers import (\n","    AutoConfig,\n","    AutoModelForSequenceClassification,\n","    AutoTokenizer,\n","    DataCollatorWithPadding,\n","    EvalPrediction,\n","    HfArgumentParser,\n","    TrainingArguments,\n","    default_data_collator,\n","    set_seed,\n","    EarlyStoppingCallback,\n",")\n","from transformers.trainer_utils import get_last_checkpoint\n","from transformers.utils import check_min_version\n","from transformers.utils.versions import require_version\n","\n","\n","# Will error if the minimal version of Transformers is not installed. Remove at your own risks.\n","check_min_version(\"4.9.0\")\n","\n","require_version(\"datasets>=1.8.0\", \"To fix: pip install -r examples/pytorch/text-classification/requirements.txt\")\n","\n","logger = logging.getLogger(__name__)\n","\n","\n","@dataclass\n","class DataTrainingArguments:\n","    \"\"\"\n","    Arguments pertaining to what data we are going to input our model for training and eval.\n","\n","    Using `HfArgumentParser` we can turn this class\n","    into argparse arguments to be able to specify them on\n","    the command line.\n","    \"\"\"\n","\n","    max_seq_length: Optional[int] = field(\n","        default=128,\n","        metadata={\n","            \"help\": \"The maximum total input sequence length after tokenization. Sequences longer \"\n","            \"than this will be truncated, sequences shorter will be padded.\"\n","        },\n","    )\n","    overwrite_cache: bool = field(\n","        default=False, metadata={\"help\": \"Overwrite the cached preprocessed datasets or not.\"}\n","    )\n","    pad_to_max_length: bool = field(\n","        default=True,\n","        metadata={\n","            \"help\": \"Whether to pad all samples to `max_seq_length`. \"\n","            \"If False, will pad the samples dynamically when batching to the maximum length in the batch.\"\n","        },\n","    )\n","    max_train_samples: Optional[int] = field(\n","        default=None,\n","        metadata={\n","            \"help\": \"For debugging purposes or quicker training, truncate the number of training examples to this \"\n","            \"value if set.\"\n","        },\n","    )\n","    max_eval_samples: Optional[int] = field(\n","        default=None,\n","        metadata={\n","            \"help\": \"For debugging purposes or quicker training, truncate the number of evaluation examples to this \"\n","            \"value if set.\"\n","        },\n","    )\n","    max_predict_samples: Optional[int] = field(\n","        default=None,\n","        metadata={\n","            \"help\": \"For debugging purposes or quicker training, truncate the number of prediction examples to this \"\n","            \"value if set.\"\n","        },\n","    )\n","    server_ip: Optional[str] = field(default=None, metadata={\"help\": \"For distant debugging.\"})\n","    server_port: Optional[str] = field(default=None, metadata={\"help\": \"For distant debugging.\"})\n","\n","\n","@dataclass\n","class ModelArguments:\n","    \"\"\"\n","    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n","    \"\"\"\n","\n","    model_name_or_path: str = field(\n","        default=None, metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n","    )\n","    config_name: Optional[str] = field(\n","        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n","    )\n","    tokenizer_name: Optional[str] = field(\n","        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n","    )\n","    cache_dir: Optional[str] = field(\n","        default=None,\n","        metadata={\"help\": \"Where do you want to store the pretrained models downloaded from huggingface.co\"},\n","    )\n","    do_lower_case: Optional[bool] = field(\n","        default=True,\n","        metadata={\"help\": \"arg to indicate if tokenizer should do lower case in AutoTokenizer.from_pretrained()\"},\n","    )\n","    use_fast_tokenizer: bool = field(\n","        default=True,\n","        metadata={\"help\": \"Whether to use one of the fast tokenizer (backed by the tokenizers library) or not.\"},\n","    )\n","    model_revision: str = field(\n","        default=\"main\",\n","        metadata={\"help\": \"The specific model version to use (can be a branch name, tag name or commit id).\"},\n","    )\n","    use_auth_token: bool = field(\n","        default=False,\n","        metadata={\n","            \"help\": \"Will use the token generated when running `transformers-cli login` (necessary to use this script \"\n","            \"with private models).\"\n","        },\n","    )\n","\n","\n","def main(training_args):\n","    # See all possible arguments in src/transformers/training_args.py\n","    # or by passing the --help flag to this script.\n","    # We now keep distinct sets of args, for a cleaner separation of concerns.\n","\n","    model_args = ModelArguments(\n","        model_name_or_path=\"nlpaueb/legal-bert-base-uncased\",\n","        #hierarchical=True,\n","        do_lower_case=True,\n","        use_fast_tokenizer=True,\n","    )\n","    data_args = DataTrainingArguments(\n","        max_seq_length=128,\n","        #max_segments=64,\n","        #max_seg_length=128,\n","        overwrite_cache=False,\n","        pad_to_max_length=True,\n","    )\n","\n","    # Setup distant debugging if needed\n","    if data_args.server_ip and data_args.server_port:\n","        # Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script\n","        import ptvsd\n","\n","        print(\"Waiting for debugger attach\")\n","        ptvsd.enable_attach(address=(data_args.server_ip, data_args.server_port), redirect_output=True)\n","        ptvsd.wait_for_attach()\n","\n","    # Fix boolean parameter\n","    if model_args.do_lower_case == 'False' or not model_args.do_lower_case:\n","        model_args.do_lower_case = False\n","        'Tokenizer do_lower_case False'\n","    else:\n","        model_args.do_lower_case = True\n","\n","    # Setup logging\n","    logging.basicConfig(\n","        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n","        datefmt=\"%m/%d/%Y %H:%M:%S\",\n","        handlers=[logging.StreamHandler(sys.stdout)],\n","    )\n","\n","    log_level = training_args.get_process_log_level()\n","    logger.setLevel(log_level)\n","    datasets.utils.logging.set_verbosity(log_level)\n","    transformers.utils.logging.set_verbosity(log_level)\n","    transformers.utils.logging.enable_default_handler()\n","    transformers.utils.logging.enable_explicit_format()\n","\n","    # Log on each process the small summary:\n","    logger.warning(\n","        f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n","        + f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"\n","    )\n","    logger.info(f\"Training/evaluation parameters {training_args}\")\n","\n","    # Detecting last checkpoint.\n","    last_checkpoint = None\n","    if os.path.isdir(training_args.output_dir) and training_args.do_train and not training_args.overwrite_output_dir:\n","        last_checkpoint = get_last_checkpoint(training_args.output_dir)\n","        if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:\n","            raise ValueError(\n","                f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n","                \"Use --overwrite_output_dir to overcome.\"\n","            )\n","        elif last_checkpoint is not None:\n","            logger.info(\n","                f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"\n","                \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n","            )\n","\n","    # Set seed before initializing model.\n","    set_seed(training_args.seed)\n","\n","    # In distributed training, the load_dataset function guarantees that only one local process can concurrently\n","    # download the dataset.\n","    # Downloading and loading eurlex dataset from the hub.\n","    if training_args.do_train:\n","        train_dataset = merged_dataset\n","\n","    if training_args.do_eval:\n","        eval_dataset = load_dataset(\"lex_glue\", \"unfair_tos\", split=\"validation\", data_dir='data', cache_dir=model_args.cache_dir)\n","\n","    if training_args.do_predict:\n","        predict_dataset = load_dataset(\"lex_glue\", \"unfair_tos\", split=\"test\", data_dir='data', cache_dir=model_args.cache_dir)\n","\n","    # Labels\n","    label_list = list(range(8))\n","    num_labels = len(label_list)\n","\n","    # Load pretrained model and tokenizer\n","    # In distributed training, the .from_pretrained methods guarantee that only one local process can concurrently\n","    # download model & vocab.\n","    config = AutoConfig.from_pretrained(\n","        model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n","        num_labels=num_labels,\n","        finetuning_task=\"unfair_toc\",\n","        cache_dir=model_args.cache_dir,\n","        revision=model_args.model_revision,\n","        use_auth_token=True if model_args.use_auth_token else None,\n","    )\n","\n","    if config.model_type == 'big_bird':\n","        config.attention_type = 'original_full'\n","\n","    if config.model_type == 'longformer':\n","        config.attention_window = [128] * config.num_hidden_layers\n","\n","    tokenizer = AutoTokenizer.from_pretrained(\n","        model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,\n","        do_lower_case=model_args.do_lower_case,\n","        cache_dir=model_args.cache_dir,\n","        use_fast=model_args.use_fast_tokenizer,\n","        revision=model_args.model_revision,\n","        use_auth_token=True if model_args.use_auth_token else None,\n","    )\n","    model = AutoModelForSequenceClassification.from_pretrained(\n","        model_args.model_name_or_path,\n","        from_tf=bool(\".ckpt\" in model_args.model_name_or_path),\n","        config=config,\n","        cache_dir=model_args.cache_dir,\n","        revision=model_args.model_revision,\n","        use_auth_token=True if model_args.use_auth_token else None,\n","    )\n","\n","    # Preprocessing the datasets\n","    # Padding strategy\n","    if data_args.pad_to_max_length:\n","        padding = \"max_length\"\n","    else:\n","        # We will pad later, dynamically at batch creation, to the max sequence length in each batch\n","        padding = False\n","\n","    def preprocess_function(examples):\n","        # Tokenize the texts\n","        batch = tokenizer(\n","            examples[\"text\"],\n","            padding=padding,\n","            max_length=data_args.max_seq_length,\n","            truncation=True,\n","        )\n","        batch[\"labels\"] = [[1 if label in labels else 0 for label in label_list] for labels in\n","                              examples[\"labels\"]]\n","\n","        return batch\n","\n","    if training_args.do_train:\n","\n","        if data_args.max_train_samples is not None:\n","            train_dataset = train_dataset.select(range(data_args.max_train_samples))\n","            print(\"#################\")\n","            print (train_dataset('labels'))\n","\n","        with training_args.main_process_first(desc=\"train dataset map pre-processing\"):\n","            train_dataset = train_dataset.map(\n","                preprocess_function,\n","                batched=True,\n","                load_from_cache_file=not data_args.overwrite_cache,\n","                desc=\"Running tokenizer on train dataset\",\n","            )\n","        # Log a few random samples from the training set:\n","        for index in random.sample(range(len(train_dataset)), 3):\n","            logger.info(f\"Sample {index} of the training set: {train_dataset[index]}.\")\n","\n","    if training_args.do_eval:\n","        if data_args.max_eval_samples is not None:\n","            eval_dataset = eval_dataset.select(range(data_args.max_eval_samples))\n","        with training_args.main_process_first(desc=\"validation dataset map pre-processing\"):\n","            eval_dataset = eval_dataset.map(\n","                preprocess_function,\n","                batched=True,\n","                load_from_cache_file=not data_args.overwrite_cache,\n","                desc=\"Running tokenizer on validation dataset\",\n","            )\n","\n","    if training_args.do_predict:\n","        if data_args.max_predict_samples is not None:\n","            predict_dataset = predict_dataset.select(range(data_args.max_predict_samples))\n","        with training_args.main_process_first(desc=\"prediction dataset map pre-processing\"):\n","            predict_dataset = predict_dataset.map(\n","                preprocess_function,\n","                batched=True,\n","                load_from_cache_file=not data_args.overwrite_cache,\n","                desc=\"Running tokenizer on prediction dataset\",\n","            )\n","\n","    # You can define your custom compute_metrics function. It takes an `EvalPrediction` object (a namedtuple with a\n","    # predictions and label_ids field) and has to return a dictionary string to float.\n","    def compute_metrics(p: EvalPrediction):\n","        # Fix gold labels\n","        y_true = np.zeros((p.label_ids.shape[0], p.label_ids.shape[1] + 1), dtype=np.int32)\n","        y_true[:, :-1] = p.label_ids\n","        y_true[:, -1] = (np.sum(p.label_ids, axis=1) == 0).astype('int32')\n","        # Fix predictions\n","        logits = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n","        preds = (expit(logits) > 0.5).astype('int32')\n","        y_pred = np.zeros((p.label_ids.shape[0], p.label_ids.shape[1] + 1), dtype=np.int32)\n","        y_pred[:, :-1] = preds\n","        y_pred[:, -1] = (np.sum(preds, axis=1) == 0).astype('int32')\n","        # Compute scores\n","        macro_f1 = f1_score(y_true=y_true, y_pred=y_pred, average='macro', zero_division=0)\n","        micro_f1 = f1_score(y_true=y_true, y_pred=y_pred, average='micro', zero_division=0)\n","        return {'macro-f1': macro_f1, 'micro-f1': micro_f1}\n","\n","    # Data collator will default to DataCollatorWithPadding, so we change it if we already did the padding.\n","    if data_args.pad_to_max_length:\n","        data_collator = default_data_collator\n","    elif training_args.fp16:\n","        data_collator = DataCollatorWithPadding(tokenizer, pad_to_multiple_of=8)\n","    else:\n","        data_collator = None\n","\n","    # Initialize our Trainer\n","    trainer = MultilabelTrainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=train_dataset if training_args.do_train else None,\n","        eval_dataset=eval_dataset if training_args.do_eval else None,\n","        compute_metrics=compute_metrics,\n","        tokenizer=tokenizer,\n","        data_collator=data_collator,\n","        callbacks=[EarlyStoppingCallback(early_stopping_patience=15)]\n","    )\n","\n","    # Training\n","    if training_args.do_train:\n","        checkpoint = None\n","        if training_args.resume_from_checkpoint is not None:\n","            checkpoint = training_args.resume_from_checkpoint\n","        elif last_checkpoint is not None:\n","            checkpoint = last_checkpoint\n","        train_result = trainer.train(resume_from_checkpoint=checkpoint)\n","        metrics = train_result.metrics\n","        max_train_samples = (\n","            data_args.max_train_samples if data_args.max_train_samples is not None else len(train_dataset)\n","        )\n","        metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n","\n","        trainer.save_model()  # Saves the tokenizer too for easy upload\n","\n","        trainer.log_metrics(\"train\", metrics)\n","        trainer.save_metrics(\"train\", metrics)\n","        trainer.save_state()\n","\n","    # Evaluation\n","    if training_args.do_eval:\n","        logger.info(\"*** Evaluate ***\")\n","        metrics = trainer.evaluate(eval_dataset=eval_dataset)\n","\n","        max_eval_samples = data_args.max_eval_samples if data_args.max_eval_samples is not None else len(eval_dataset)\n","        metrics[\"eval_samples\"] = min(max_eval_samples, len(eval_dataset))\n","\n","        trainer.log_metrics(\"eval\", metrics)\n","        trainer.save_metrics(\"eval\", metrics)\n","\n","    # Prediction\n","    if training_args.do_predict:\n","        logger.info(\"*** Predict ***\")\n","        predictions, labels, metrics = trainer.predict(predict_dataset, metric_key_prefix=\"predict\")\n","\n","        max_predict_samples = (\n","            data_args.max_predict_samples if data_args.max_predict_samples is not None else len(predict_dataset)\n","        )\n","        metrics[\"predict_samples\"] = min(max_predict_samples, len(predict_dataset))\n","\n","        trainer.log_metrics(\"predict\", metrics)\n","        trainer.save_metrics(\"predict\", metrics)\n","\n","        output_predict_file = os.path.join(training_args.output_dir, \"test_predictions.csv\")\n","        if trainer.is_world_process_zero():\n","            with open(output_predict_file, \"w\") as writer:\n","                if isinstance(predictions[0], np.float32):\n","                   pred_line = f'{predictions[0]:.5f}'\n","                   writer.write(pred_line)\n","                else:\n","                    for key, value in metrics.items():\n","                        if isinstance(value, float):\n","                           writer.write(f\"{key} = {value:.5f}\\n\")\n","                        else:\n","                           writer.write(f\"{key} = {value}\\n\")\n","\n","\n","    # Clean up checkpoints\n","    checkpoints = [filepath for filepath in glob.glob(f'{training_args.output_dir}/*/') if '/checkpoint' in filepath]\n","    for checkpoint in checkpoints:\n","        shutil.rmtree(checkpoint)\n","\n","\n","if __name__ == \"__main__\":\n"," #    For Evaluation\n","    training_args = TrainingArguments(\n","        do_train = True,\n","        do_eval = True,\n","        do_predict = True,\n","        output_dir=os.getcwd(),\n","        overwrite_output_dir=True,\n","        num_train_epochs=20,\n","        per_device_train_batch_size=8,\n","        per_device_eval_batch_size=8,\n","        save_steps=500,\n","        save_total_limit=2,\n","        fp16=False,\n","        logging_dir=\"./logs\",\n","        logging_steps=200,\n","        evaluation_strategy=\"steps\",\n","        eval_steps=500,\n","        logging_first_step=False,\n","        load_best_model_at_end = True,\n","        metric_for_best_model=\"micro-f1\",\n","    )\n","    main(training_args)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["25584bc1aa1b4c7884cf6423e44e2bc4","d79f2659ece8424aa06cec9abcbc6bbd","20594eff7a1c4ee4a7fb43cb49d9d5ef","76c025cb89494b77b4f8466253f87e7c","5d36526386884def85976b3c8aeaa718","eef3b114a66e4d19af719c5edafa9dc2","808dfb1adc964143978d19f2a500f0f3","1ac4b62d985b4d52805678291ac9efa9","47e29e0542f040a3bb29cbacd5d0b785","ff048be67a3440e18a8bdaa57e97b6e4","1f748b4d412b42aca566451900ffb39c"]},"id":"r1niXEIhuJI9","executionInfo":{"status":"ok","timestamp":1693765174060,"user_tz":-60,"elapsed":1302171,"user":{"displayName":"Sumit Gupta","userId":"07308348120090087318"}},"outputId":"d965ab09-7fd4-474e-c0ac-71c1e404abec"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:__main__:Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False\n","[WARNING|modeling_utils.py:3553] 2023-09-03 17:57:56,109 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["Running tokenizer on train dataset:   0%|          | 0/5583 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25584bc1aa1b4c7884cf6423e44e2bc4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='13960' max='13960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [13960/13960 21:24, Epoch 20/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro-f1</th>\n","      <th>Micro-f1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.065600</td>\n","      <td>0.039637</td>\n","      <td>0.354686</td>\n","      <td>0.922808</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.032700</td>\n","      <td>0.030331</td>\n","      <td>0.582154</td>\n","      <td>0.926136</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.027200</td>\n","      <td>0.026419</td>\n","      <td>0.725193</td>\n","      <td>0.943644</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.021100</td>\n","      <td>0.025829</td>\n","      <td>0.733401</td>\n","      <td>0.942152</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.019700</td>\n","      <td>0.027778</td>\n","      <td>0.750638</td>\n","      <td>0.946568</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.010300</td>\n","      <td>0.026271</td>\n","      <td>0.767480</td>\n","      <td>0.951363</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.009700</td>\n","      <td>0.028838</td>\n","      <td>0.742079</td>\n","      <td>0.945352</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.005300</td>\n","      <td>0.032501</td>\n","      <td>0.738618</td>\n","      <td>0.945852</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.005100</td>\n","      <td>0.037548</td>\n","      <td>0.747403</td>\n","      <td>0.949367</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.003400</td>\n","      <td>0.032396</td>\n","      <td>0.778011</td>\n","      <td>0.948148</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.003500</td>\n","      <td>0.033751</td>\n","      <td>0.742106</td>\n","      <td>0.942354</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.002900</td>\n","      <td>0.035146</td>\n","      <td>0.760737</td>\n","      <td>0.949684</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>0.002900</td>\n","      <td>0.036020</td>\n","      <td>0.760997</td>\n","      <td>0.951778</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.003700</td>\n","      <td>0.032103</td>\n","      <td>0.765231</td>\n","      <td>0.949869</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>0.002400</td>\n","      <td>0.040724</td>\n","      <td>0.733814</td>\n","      <td>0.934697</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.001400</td>\n","      <td>0.039710</td>\n","      <td>0.752814</td>\n","      <td>0.947758</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>0.003800</td>\n","      <td>0.036541</td>\n","      <td>0.753955</td>\n","      <td>0.947024</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>0.001600</td>\n","      <td>0.038416</td>\n","      <td>0.764531</td>\n","      <td>0.952672</td>\n","    </tr>\n","    <tr>\n","      <td>9500</td>\n","      <td>0.001500</td>\n","      <td>0.036908</td>\n","      <td>0.777546</td>\n","      <td>0.952526</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>0.000800</td>\n","      <td>0.038642</td>\n","      <td>0.765827</td>\n","      <td>0.949913</td>\n","    </tr>\n","    <tr>\n","      <td>10500</td>\n","      <td>0.001000</td>\n","      <td>0.036838</td>\n","      <td>0.780854</td>\n","      <td>0.952692</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>0.000300</td>\n","      <td>0.038950</td>\n","      <td>0.771893</td>\n","      <td>0.950991</td>\n","    </tr>\n","    <tr>\n","      <td>11500</td>\n","      <td>0.000400</td>\n","      <td>0.039897</td>\n","      <td>0.773220</td>\n","      <td>0.954248</td>\n","    </tr>\n","    <tr>\n","      <td>12000</td>\n","      <td>0.000400</td>\n","      <td>0.041772</td>\n","      <td>0.770314</td>\n","      <td>0.951655</td>\n","    </tr>\n","    <tr>\n","      <td>12500</td>\n","      <td>0.000500</td>\n","      <td>0.041857</td>\n","      <td>0.766538</td>\n","      <td>0.951841</td>\n","    </tr>\n","    <tr>\n","      <td>13000</td>\n","      <td>0.000400</td>\n","      <td>0.042204</td>\n","      <td>0.769133</td>\n","      <td>0.951634</td>\n","    </tr>\n","    <tr>\n","      <td>13500</td>\n","      <td>0.000200</td>\n","      <td>0.042020</td>\n","      <td>0.765716</td>\n","      <td>0.950970</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["***** train metrics *****\n","  epoch                    =       20.0\n","  total_flos               =  6840695GF\n","  train_loss               =     0.0091\n","  train_runtime            = 0:21:24.69\n","  train_samples            =       5583\n","  train_samples_per_second =     86.916\n","  train_steps_per_second   =     10.866\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["***** eval metrics *****\n","  epoch                   =       20.0\n","  eval_loss               =     0.0399\n","  eval_macro-f1           =     0.7732\n","  eval_micro-f1           =     0.9542\n","  eval_runtime            = 0:00:06.13\n","  eval_samples            =       2275\n","  eval_samples_per_second =    371.002\n","  eval_steps_per_second   =     46.477\n","***** predict metrics *****\n","  predict_loss               =     0.0384\n","  predict_macro-f1           =     0.8296\n","  predict_micro-f1           =      0.958\n","  predict_runtime            = 0:00:04.52\n","  predict_samples            =       1607\n","  predict_samples_per_second =    355.192\n","  predict_steps_per_second   =     44.427\n"]}]},{"cell_type":"code","source":["##LEDGAR\n","##Unfair-TOS\n","# Load JSON data from file\n","file_path = '/content/sample_data/incorrect_predictions_dataset (5).json'\n","\n","with open(file_path, 'r') as json_file:\n","    data = json.load(json_file)\n","\n","# Create a dictionary to store original_labels\n","labels_dict = {}\n","text_dict ={}\n","labels =[]\n","\n","# Iterate through the data and extract original_labels\n","for entry in data:\n","    if \"original_labels\" in entry:\n","        original_labels = entry[\"original_labels\"]\n","        if \"Index\" in entry:\n","            index = entry[\"Index\"]\n","            labels_dict[index] = original_labels\n","        if \"text\" in entry:\n","            text = entry[\"text\"]\n","            text_dict[index]={\n","                \"original_labels\": original_labels,\n","                \"text\": text\n","            }\n","        elif len(labels_dict) > 0:\n","            last_index = max(labels_dict.keys())\n","            labels_dict[last_index].extend(original_labels)\n","        labels.append(original_labels)\n","\n","print(\"*********\")\n","print(len(text_dict))\n","# Initialize lists to store texts and labels\n","texts = []\n","text= []\n","#labels = label_lists[0:173]\n","print(\"#####\")\n","print(len(labels))\n","# Iterate through the data and extract relevant information\n","for entry in data:\n","    if \"text\" in entry:\n","        text = entry[\"text\"]\n","        if \"Index\" in entry:\n","            index = entry[\"Index\"]\n","            #labels.append(labels_dict.get(index, []))\n","        else:\n","            # Use the last index available in labels_dict\n","            last_index = max(labels_dict.keys())\n","            #labels.append(labels_dict.get(last_index, []))\n","        texts.append(text)\n","\n","print(\"Number of Texts:\", len(texts))\n","print(\"Number of Labels:\", len(labels))\n","\n","original_label_counts = {}\n","for label_list in labels:\n","    for label in label_list:\n","        if label in original_label_counts:\n","            original_label_counts[label] += 1\n","        else:\n","            original_label_counts[label] = 1\n","\n","# Find the most occurring original label\n","most_common_original_label = max(original_label_counts, key=original_label_counts.get)\n","print(\"Most Common Original Label:\", most_common_original_label)\n","print(\"Occurrences:\", original_label_counts[most_common_original_label])\n","\n","\n","first_occurrence_index = None\n","for index, label_list in enumerate(labels):\n","    if most_common_original_label in label_list:\n","        first_occurrence_index = index\n","        break\n","\n","print(\"First Occurrence Index of Label 2:\", first_occurrence_index)\n","\n","print(\"Text:\", texts[first_occurrence_index])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9T7YX4JPgvHm","executionInfo":{"status":"ok","timestamp":1692678957579,"user_tz":-60,"elapsed":504,"user":{"displayName":"Sumit Gupta","userId":"07308348120090087318"}},"outputId":"fa9ae0ab-efbc-4244-8906-b002817eebcf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["*********\n","0\n","#####\n","10000\n","Number of Texts: 10000\n","Number of Labels: 10000\n","Most Common Original Label: 47\n","Occurrences: 582\n","First Occurrence Index of Label 2: 14\n","Text: The validity and interpretation of this Agreement, and the terms and conditions set forth herein, shall be construed and interpreted in accordance with and governed by the laws of the State of California, without giving effect to any provisions relating to conflict of laws.\n"]}]},{"cell_type":"code","source":["##EcTHR(B)\n","# Load JSON data from file\n","file_path = '/content/sample_data/incorrect_predictions_dataset (3).json'\n","\n","with open(file_path, 'r') as json_file:\n","    data = json.load(json_file)\n","\n","# Create a dictionary to store original_labels\n","labels_dict = {}\n","text_dict ={}\n","labels =[]\n","\n","# Iterate through the data and extract original_labels\n","for entry in data:\n","    if \"original_labels\" in entry:\n","        original_labels = entry[\"original_labels\"]\n","        if \"Index\" in entry:\n","            index = entry[\"Index\"]\n","            labels_dict[index] = original_labels\n","        if \"text\" in entry:\n","            text = entry[\"text\"]\n","            text_dict[index]={\n","                \"original_labels\": original_labels,\n","                \"text\": text\n","            }\n","        elif len(labels_dict) > 0:\n","            last_index = max(labels_dict.keys())\n","            labels_dict[last_index].extend(original_labels)\n","        labels.append(original_labels)\n","\n","print(\"*********\")\n","print(len(text_dict))\n","# Initialize lists to store texts and labels\n","texts = []\n","text= []\n","#labels = label_lists[0:173]\n","print(\"#####\")\n","print(len(labels))\n","# Iterate through the data and extract relevant information\n","for entry in data:\n","    if \"text\" in entry:\n","        text = entry[\"text\"]\n","        if \"Index\" in entry:\n","            index = entry[\"Index\"]\n","            #labels.append(labels_dict.get(index, []))\n","        else:\n","            # Use the last index available in labels_dict\n","            last_index = max(labels_dict.keys())\n","            #labels.append(labels_dict.get(last_index, []))\n","        texts.append(text)\n","\n","print(\"Number of Texts:\", len(texts))\n","print(\"Number of Labels:\", len(labels))\n","\n","original_label_counts = {}\n","for label_list in labels:\n","    for label in label_list:\n","        if label in original_label_counts:\n","            original_label_counts[label] += 1\n","        else:\n","            original_label_counts[label] = 1\n","\n","# Find the most occurring original label\n","most_common_original_label = max(original_label_counts, key=original_label_counts.get)\n","print(\"Most Common Original Label:\", most_common_original_label)\n","print(\"Occurrences:\", original_label_counts[most_common_original_label])\n","\n","\n","first_occurrence_index = None\n","for index, label_list in enumerate(labels):\n","    if most_common_original_label in label_list:\n","        first_occurrence_index = index\n","        break\n","\n","print(\"First Occurrence Index of Label :\", first_occurrence_index)\n","\n","print(\"Text:\", texts[first_occurrence_index])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zp2Yrry3iCuC","executionInfo":{"status":"ok","timestamp":1692679941077,"user_tz":-60,"elapsed":852,"user":{"displayName":"Sumit Gupta","userId":"07308348120090087318"}},"outputId":"2fbe91df-33dd-4a8f-a689-131403455cf6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["*********\n","0\n","#####\n","1000\n","Number of Texts: 1000\n","Number of Labels: 1000\n","Most Common Original Label: 3\n","Occurrences: 394\n","First Occurrence Index of Label : 2\n","Text: ['5.  The applicant was born in 1965 and lives in Smědčice.', '6.  On 9 November 2006 the applicant requested a building permit for temporary stables for horses. On 6 January 2011 the Rokycany Planning Office (stavební úřad) dismissed his request and on 26 May 2011 the Plzeň Regional Office (krajský úřad) upheld that decision.', '7.  On 29 March 2013 the Plzeň Regional Court (krajský soud) dismissed a complaint lodged by the applicant against the decision of the Plzeň Regional Office.', '8.  On 31 July 2013 the Supreme Administrative Court (Nejvyšší správní soud) dismissed an appeal on points of law lodged by the applicant. The decision was served on the applicant on 28 August 2013.', '9.  On 29 October 2013 the applicant lodged a constitutional complaint (ústavní stížnost).', '10.  On 31 March 2014 the Constitutional Court (Ústavní soud) rejected the applicant’s appeal as being lodged out of time. It held that as the Supreme Administrative Court’s decision had been served on him on 28 August 2013, the last day of the two-month time-limit for lodging a constitutional appeal was 28 October 2013.', '11.  On 8 April 2014 the applicant wrote to the Constitutional Court urging it to set aside its decision. He argued that as 28 October 2013 had been a national holiday, domestic procedural rules provided that the last day for lodging his appeal had been the following day, namely 29 October 2013.', '12.  By a letter of 11 April 2014 the Registrar (generální sekretář) of the Constitutional Court acknowledged that the judge-rapporteur had undoubtedly overlooked the fact that the time-limit had been complied with. However, as the Constitutional Court did not have the power to set aside its own decision, he advised the applicant to lodge an application with the European Court of Human Rights.']\n"]}]},{"cell_type":"code","source":["##EctHR(A)\n","# Load JSON data from file\n","file_path = '/content/sample_data/incorrect_predictions_dataset (6).json'\n","\n","with open(file_path, 'r') as json_file:\n","    data = json.load(json_file)\n","\n","# Create a dictionary to store original_labels\n","labels_dict = {}\n","text_dict ={}\n","labels =[]\n","\n","# Iterate through the data and extract original_labels\n","for entry in data:\n","    if \"original_labels\" in entry:\n","        original_labels = entry[\"original_labels\"]\n","        if \"Index\" in entry:\n","            index = entry[\"Index\"]\n","            labels_dict[index] = original_labels\n","        if \"text\" in entry:\n","            text = entry[\"text\"]\n","            text_dict[index]={\n","                \"original_labels\": original_labels,\n","                \"text\": text\n","            }\n","        elif len(labels_dict) > 0:\n","            last_index = max(labels_dict.keys())\n","            labels_dict[last_index].extend(original_labels)\n","        labels.append(original_labels)\n","\n","print(\"*********\")\n","print(len(text_dict))\n","# Initialize lists to store texts and labels\n","texts = []\n","text= []\n","#labels = label_lists[0:173]\n","print(\"#####\")\n","print(len(labels))\n","# Iterate through the data and extract relevant information\n","for entry in data:\n","    if \"text\" in entry:\n","        text = entry[\"text\"]\n","        if \"Index\" in entry:\n","            index = entry[\"Index\"]\n","            #labels.append(labels_dict.get(index, []))\n","        else:\n","            # Use the last index available in labels_dict\n","            last_index = max(labels_dict.keys())\n","            #labels.append(labels_dict.get(last_index, []))\n","        texts.append(text)\n","\n","print(\"Number of Texts:\", len(texts))\n","print(\"Number of Labels:\", len(labels))\n","\n","original_label_counts = {}\n","for label_list in labels:\n","    for label in label_list:\n","        if label in original_label_counts:\n","            original_label_counts[label] += 1\n","        else:\n","            original_label_counts[label] = 1\n","\n","# Find the most occurring original label\n","most_common_original_label = max(original_label_counts, key=original_label_counts.get)\n","print(\"Most Common Original Label:\", most_common_original_label)\n","print(\"Occurrences:\", original_label_counts[most_common_original_label])\n","\n","\n","first_occurrence_index = None\n","for index, label_list in enumerate(labels):\n","    if most_common_original_label in label_list:\n","        first_occurrence_index = index\n","        break\n","\n","print(\"First Occurrence Index of Label :\", first_occurrence_index)\n","\n","print(\"Text:\", texts[first_occurrence_index])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C39IWwZLlm5K","executionInfo":{"status":"ok","timestamp":1692680643049,"user_tz":-60,"elapsed":1031,"user":{"displayName":"Sumit Gupta","userId":"07308348120090087318"}},"outputId":"515e1e85-31c4-4769-fa4b-7f388ece50e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["*********\n","0\n","#####\n","1000\n","Number of Texts: 1000\n","Number of Labels: 1000\n","Most Common Original Label: 3\n","Occurrences: 299\n","First Occurrence Index of Label : 2\n","Text: ['5.  The applicant was born in 1965 and lives in Smědčice.', '6.  On 9 November 2006 the applicant requested a building permit for temporary stables for horses. On 6 January 2011 the Rokycany Planning Office (stavební úřad) dismissed his request and on 26 May 2011 the Plzeň Regional Office (krajský úřad) upheld that decision.', '7.  On 29 March 2013 the Plzeň Regional Court (krajský soud) dismissed a complaint lodged by the applicant against the decision of the Plzeň Regional Office.', '8.  On 31 July 2013 the Supreme Administrative Court (Nejvyšší správní soud) dismissed an appeal on points of law lodged by the applicant. The decision was served on the applicant on 28 August 2013.', '9.  On 29 October 2013 the applicant lodged a constitutional complaint (ústavní stížnost).', '10.  On 31 March 2014 the Constitutional Court (Ústavní soud) rejected the applicant’s appeal as being lodged out of time. It held that as the Supreme Administrative Court’s decision had been served on him on 28 August 2013, the last day of the two-month time-limit for lodging a constitutional appeal was 28 October 2013.', '11.  On 8 April 2014 the applicant wrote to the Constitutional Court urging it to set aside its decision. He argued that as 28 October 2013 had been a national holiday, domestic procedural rules provided that the last day for lodging his appeal had been the following day, namely 29 October 2013.', '12.  By a letter of 11 April 2014 the Registrar (generální sekretář) of the Constitutional Court acknowledged that the judge-rapporteur had undoubtedly overlooked the fact that the time-limit had been complied with. However, as the Constitutional Court did not have the power to set aside its own decision, he advised the applicant to lodge an application with the European Court of Human Rights.']\n"]}]}]}