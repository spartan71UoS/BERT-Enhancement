{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"2f89f97c7368470fb0ef3ce28d8a11b4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ce5f656f447048ccac175fd73b55e58e","IPY_MODEL_cdc34063596945faaa7644096d0ec815","IPY_MODEL_256462799bbf436586f10cef999b8f63"],"layout":"IPY_MODEL_5838e4540e2644e4a093edd3101ef155"}},"ce5f656f447048ccac175fd73b55e58e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_db3b2a0847c145d7ac8a322f855a5e72","placeholder":"​","style":"IPY_MODEL_e44e0af0661d4f17ab6c7cdbb0605175","value":"Running tokenizer on train dataset: 100%"}},"cdc34063596945faaa7644096d0ec815":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_770e708189cf4885af012f324a7869ec","max":9000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c6b0898c534e4bc2a900af64ce4ed7dd","value":9000}},"256462799bbf436586f10cef999b8f63":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f026678d68dd40649278ba05fd27b92e","placeholder":"​","style":"IPY_MODEL_b278865cbfa849558704797ee74a78f4","value":" 9000/9000 [00:50&lt;00:00, 168.79 examples/s]"}},"5838e4540e2644e4a093edd3101ef155":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db3b2a0847c145d7ac8a322f855a5e72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e44e0af0661d4f17ab6c7cdbb0605175":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"770e708189cf4885af012f324a7869ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6b0898c534e4bc2a900af64ce4ed7dd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f026678d68dd40649278ba05fd27b92e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b278865cbfa849558704797ee74a78f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c8c76c1130c4440a372955e36cc8902":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_92d0c2b058fc41ecbc5f22c71d16c8f3","IPY_MODEL_0b7920ff168d4b61b01dc47b555678e1","IPY_MODEL_d31746dceff74918813229b3e088a3d4"],"layout":"IPY_MODEL_92d91e48c97a45cba44c53a46c4ed910"}},"92d0c2b058fc41ecbc5f22c71d16c8f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b15ca471fcee45d8911723f86888f727","placeholder":"​","style":"IPY_MODEL_8e48b8b7563e4725aabc1b461495142d","value":"Running tokenizer on validation dataset: 100%"}},"0b7920ff168d4b61b01dc47b555678e1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1366e323131b4c688db200c8ec755555","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b7cc7ebbd2a24c0fa304dc2f0ae64710","value":1000}},"d31746dceff74918813229b3e088a3d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e6333808d72440d9f31cea54a125bf5","placeholder":"​","style":"IPY_MODEL_7aa3f25a952349d6850a186a2cf0a9bf","value":" 1000/1000 [00:05&lt;00:00, 194.70 examples/s]"}},"92d91e48c97a45cba44c53a46c4ed910":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b15ca471fcee45d8911723f86888f727":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e48b8b7563e4725aabc1b461495142d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1366e323131b4c688db200c8ec755555":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7cc7ebbd2a24c0fa304dc2f0ae64710":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4e6333808d72440d9f31cea54a125bf5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7aa3f25a952349d6850a186a2cf0a9bf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b5ec0a07e0234c729246a99a5d9a3e83":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0d6a3fefdefc47cfa681e9fbee26ab94","IPY_MODEL_65abf54748d54aafa76decf30d916b7b","IPY_MODEL_ad6017cd3b244c2783fe093cc076b48f"],"layout":"IPY_MODEL_62d002120a224ae4bcd29532844e3853"}},"0d6a3fefdefc47cfa681e9fbee26ab94":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b795e964bb04df5a043fe8e677c0a56","placeholder":"​","style":"IPY_MODEL_e29b4885a96b45d6829cf979d2708c94","value":"Running tokenizer on prediction dataset: 100%"}},"65abf54748d54aafa76decf30d916b7b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_645c1dc1b0314456a684efb79886e1c5","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_73c441cb624c42b19d95376a6bee0f68","value":1000}},"ad6017cd3b244c2783fe093cc076b48f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_225717a7e11843bca9cf9478c1d4af5e","placeholder":"​","style":"IPY_MODEL_bd65a300338a4693a7322b6dab0c7ac4","value":" 1000/1000 [00:05&lt;00:00, 177.49 examples/s]"}},"62d002120a224ae4bcd29532844e3853":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b795e964bb04df5a043fe8e677c0a56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e29b4885a96b45d6829cf979d2708c94":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"645c1dc1b0314456a684efb79886e1c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73c441cb624c42b19d95376a6bee0f68":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"225717a7e11843bca9cf9478c1d4af5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd65a300338a4693a7322b6dab0c7ac4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"287e30e99c8c4dcabaf690414eeaaa87":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d29b2dec3a1d43e0905224e52c8417f7","IPY_MODEL_db74ae34db374803b0d0809479562db2","IPY_MODEL_0c1db1c090dc4374a3f2daf074204ee1"],"layout":"IPY_MODEL_da291cd3d0b4495bbaf93752d9eeda31"}},"d29b2dec3a1d43e0905224e52c8417f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bec3f6ddeb5e4d868c491bbcec1f7073","placeholder":"​","style":"IPY_MODEL_33923af374b84ff9b9b124497f4053a4","value":"Downloading (…)okenizer_config.json: 100%"}},"db74ae34db374803b0d0809479562db2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c0ce1bfd50444f08a5cad5998564823","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3849754a1ad84b209be72b543f0a224c","value":28}},"0c1db1c090dc4374a3f2daf074204ee1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76d657f0e06e47ff853c10413b9b77b5","placeholder":"​","style":"IPY_MODEL_6976cc179e2848b9a6f818655a2010c3","value":" 28.0/28.0 [00:00&lt;00:00, 2.07kB/s]"}},"da291cd3d0b4495bbaf93752d9eeda31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bec3f6ddeb5e4d868c491bbcec1f7073":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33923af374b84ff9b9b124497f4053a4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c0ce1bfd50444f08a5cad5998564823":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3849754a1ad84b209be72b543f0a224c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"76d657f0e06e47ff853c10413b9b77b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6976cc179e2848b9a6f818655a2010c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"630f783d3c1b460d89d6175a77a6406f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d200ff919be04ab09bec021237089ea5","IPY_MODEL_7b341142a20745538efe30ecaadd377f","IPY_MODEL_2382e6c48e1e456a90f2074df71dc81a"],"layout":"IPY_MODEL_25c8c8e81b664bcab34ca55710683001"}},"d200ff919be04ab09bec021237089ea5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b659002170e349d8878a936d82050538","placeholder":"​","style":"IPY_MODEL_342b02891d8141938e97bc084925965c","value":"Downloading (…)lve/main/config.json: 100%"}},"7b341142a20745538efe30ecaadd377f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_94d5a463aeb3441494abf80d6794144f","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8109f30a5caa49b693a97a19be216bcb","value":570}},"2382e6c48e1e456a90f2074df71dc81a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fe037c135a54eb8828f53cb85fe9ab4","placeholder":"​","style":"IPY_MODEL_5648b2252eaf4b87a79ea3fc0be5e3bd","value":" 570/570 [00:00&lt;00:00, 50.3kB/s]"}},"25c8c8e81b664bcab34ca55710683001":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b659002170e349d8878a936d82050538":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"342b02891d8141938e97bc084925965c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"94d5a463aeb3441494abf80d6794144f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8109f30a5caa49b693a97a19be216bcb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8fe037c135a54eb8828f53cb85fe9ab4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5648b2252eaf4b87a79ea3fc0be5e3bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eb2c696d553e4e26ba9cdb882ec4a43e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_382dc9306b2f434088f5762364a9596d","IPY_MODEL_ed2df6bc13404ac5908f0a8047a6c095","IPY_MODEL_7ef3b1c379ce4f6da097640619b3d61f"],"layout":"IPY_MODEL_b9b4a5b0357a4992b0571fc825dbe926"}},"382dc9306b2f434088f5762364a9596d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_efa930e3a4164262bc70939f02bbf36e","placeholder":"​","style":"IPY_MODEL_32bd2aab24b445c2af11117657861233","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"ed2df6bc13404ac5908f0a8047a6c095":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a5317e5a3c324848ac8c0902bbdcd991","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9dd7eed4a57d4a2ab7355fee726871a8","value":231508}},"7ef3b1c379ce4f6da097640619b3d61f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ebd1912d6dd43b28e8d9d7ce90eebc2","placeholder":"​","style":"IPY_MODEL_1cd0269b17624ac6ae3ccd0e5ac0d2b5","value":" 232k/232k [00:00&lt;00:00, 948kB/s]"}},"b9b4a5b0357a4992b0571fc825dbe926":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efa930e3a4164262bc70939f02bbf36e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32bd2aab24b445c2af11117657861233":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a5317e5a3c324848ac8c0902bbdcd991":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9dd7eed4a57d4a2ab7355fee726871a8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8ebd1912d6dd43b28e8d9d7ce90eebc2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1cd0269b17624ac6ae3ccd0e5ac0d2b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5f2dc2e97e494dcba490ce69d44011fc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ebeae4d55614414db67370ca357dadec","IPY_MODEL_cea9a0dbf74f4f9cbc65c259d799d111","IPY_MODEL_16f3d881bf174217b99c65b0f686f1a0"],"layout":"IPY_MODEL_39ab58ae08874af79c8b5732a3b53480"}},"ebeae4d55614414db67370ca357dadec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0057bfa29a49408eb4af39e5ec835d9e","placeholder":"​","style":"IPY_MODEL_f7e7851053f64abda95dff2e47836896","value":"Downloading (…)/main/tokenizer.json: 100%"}},"cea9a0dbf74f4f9cbc65c259d799d111":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4768f682d084632ade179ef82243f7f","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f1b2fb21fe7f4e6aa0a8181b6901bd9b","value":466062}},"16f3d881bf174217b99c65b0f686f1a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5c67ce56af7432eac354bf903f976dd","placeholder":"​","style":"IPY_MODEL_2b755a3a872443a9a2e8d81aa4a3727b","value":" 466k/466k [00:00&lt;00:00, 24.2MB/s]"}},"39ab58ae08874af79c8b5732a3b53480":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0057bfa29a49408eb4af39e5ec835d9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7e7851053f64abda95dff2e47836896":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e4768f682d084632ade179ef82243f7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1b2fb21fe7f4e6aa0a8181b6901bd9b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b5c67ce56af7432eac354bf903f976dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b755a3a872443a9a2e8d81aa4a3727b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d81ed8a2cfa14187b973549b1060fbc1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ffbd4738441f4a42805c20fbda649013","IPY_MODEL_ddd4287505b548278095e3387c58a3b5","IPY_MODEL_59f25258bd44486db285487e66cdc2ff"],"layout":"IPY_MODEL_6c693e9c571f4656b820bb9f75750cc5"}},"ffbd4738441f4a42805c20fbda649013":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b2b91fd0c3042d9900b9769e6b0fd4e","placeholder":"​","style":"IPY_MODEL_643da12a123a44dc9cc45f74884f62ce","value":"Downloading model.safetensors: 100%"}},"ddd4287505b548278095e3387c58a3b5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1431a66d40d49d1b392007670c7adde","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a705c489bd1745f4ad0e878d6dfeca15","value":440449768}},"59f25258bd44486db285487e66cdc2ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d51cc638e58b4dec92dbacdb4b5ac57f","placeholder":"​","style":"IPY_MODEL_d440d3729e2f4a4facba257cd9e61f25","value":" 440M/440M [00:01&lt;00:00, 502MB/s]"}},"6c693e9c571f4656b820bb9f75750cc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b2b91fd0c3042d9900b9769e6b0fd4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"643da12a123a44dc9cc45f74884f62ce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b1431a66d40d49d1b392007670c7adde":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a705c489bd1745f4ad0e878d6dfeca15":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d51cc638e58b4dec92dbacdb4b5ac57f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d440d3729e2f4a4facba257cd9e61f25":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6b4acf12f3f949d49edf5a30f81f9faa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_33d039029cc6442397351ad47d639f5b","IPY_MODEL_da68f34c3c364bfbbb8d77551b2782d1","IPY_MODEL_c07f1bb9535d41b191e1e7de34449f83"],"layout":"IPY_MODEL_8c60dde2364c4d4c9701b8519da757f8"}},"33d039029cc6442397351ad47d639f5b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7fe872209484907a7cdde4bb99dfc06","placeholder":"​","style":"IPY_MODEL_1e659bd88b0349f4bf20943604ae57e6","value":"Running tokenizer on train dataset: 100%"}},"da68f34c3c364bfbbb8d77551b2782d1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_031fbd39dd8940d1b4d3095ee1a76947","max":9000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1b10dadefd96440f9b4896753dc268cc","value":9000}},"c07f1bb9535d41b191e1e7de34449f83":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7f4e5cda3b14ecfb3f2580a15a30dd1","placeholder":"​","style":"IPY_MODEL_8ba2987477c3430d997d5d223e08ba49","value":" 9000/9000 [00:49&lt;00:00, 171.63 examples/s]"}},"8c60dde2364c4d4c9701b8519da757f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7fe872209484907a7cdde4bb99dfc06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e659bd88b0349f4bf20943604ae57e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"031fbd39dd8940d1b4d3095ee1a76947":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b10dadefd96440f9b4896753dc268cc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c7f4e5cda3b14ecfb3f2580a15a30dd1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ba2987477c3430d997d5d223e08ba49":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d21c33da17784f868469dc4c1d26d786":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8258689509564276be46f14c28a2046f","IPY_MODEL_d289fee5780b44fc96256e30792fdf53","IPY_MODEL_7626427795544c51a557c418edf88642"],"layout":"IPY_MODEL_2a97195deff94945956e892256c03943"}},"8258689509564276be46f14c28a2046f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_af301bd5a73b4ec281d71bb95b8c6f70","placeholder":"​","style":"IPY_MODEL_15a7139db05d436cadc66b0430b3d586","value":"Running tokenizer on validation dataset: 100%"}},"d289fee5780b44fc96256e30792fdf53":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dcba1eb30435432c8dbc950210d3e0ed","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2984f00f639447e0972d59d8744a0d89","value":1000}},"7626427795544c51a557c418edf88642":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_02e41b6218ee45a1b28e2daf122729d5","placeholder":"​","style":"IPY_MODEL_c626a973ad6146d6990ea34f2b125e13","value":" 1000/1000 [00:05&lt;00:00, 197.10 examples/s]"}},"2a97195deff94945956e892256c03943":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af301bd5a73b4ec281d71bb95b8c6f70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15a7139db05d436cadc66b0430b3d586":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dcba1eb30435432c8dbc950210d3e0ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2984f00f639447e0972d59d8744a0d89":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"02e41b6218ee45a1b28e2daf122729d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c626a973ad6146d6990ea34f2b125e13":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d2d5a2060454e2984e7695bc4ce13e6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7e777bd423e14a9ea27e09a36e2939bf","IPY_MODEL_1d79629e65044930af373af82aecc873","IPY_MODEL_006f640a19794042a9828344eae4ba66"],"layout":"IPY_MODEL_e4440e587aa44c70a8638d3d0d675f82"}},"7e777bd423e14a9ea27e09a36e2939bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4623d92ce52242f08a9d89d744559a11","placeholder":"​","style":"IPY_MODEL_cd7c74a461fa4ba389a7f5a5d071893e","value":"Running tokenizer on prediction dataset: 100%"}},"1d79629e65044930af373af82aecc873":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_43165da527204f75b6ee8effc7023fd2","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cd2c3bac40a94799acfb8d7165aed6d5","value":1000}},"006f640a19794042a9828344eae4ba66":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a06a14de6c3e40b083762e9e8bffb6c6","placeholder":"​","style":"IPY_MODEL_0a3b25b7230a46d5a97d7acb5350cac8","value":" 1000/1000 [00:05&lt;00:00, 177.56 examples/s]"}},"e4440e587aa44c70a8638d3d0d675f82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4623d92ce52242f08a9d89d744559a11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd7c74a461fa4ba389a7f5a5d071893e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"43165da527204f75b6ee8effc7023fd2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd2c3bac40a94799acfb8d7165aed6d5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a06a14de6c3e40b083762e9e8bffb6c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a3b25b7230a46d5a97d7acb5350cac8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a7aa9c3bcfd24b6791b6f900370f005b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2b52aab60c78461ba767c24555a3656b","IPY_MODEL_a00b9fc84bfd4f95a2e12c415d4a849c","IPY_MODEL_be06199c2b1d4ae2a07894bc2987d6fe"],"layout":"IPY_MODEL_c595cdbe30834a0091317366bd21f08b"}},"2b52aab60c78461ba767c24555a3656b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1255e55f5f0491f901b8e5302fd8790","placeholder":"​","style":"IPY_MODEL_a6fc09d762b24169bdc70e32d7978260","value":"Filter: 100%"}},"a00b9fc84bfd4f95a2e12c415d4a849c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2604d340be284cd8abd95904cb9a4398","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_de57eb04125a417e978b9608efe74909","value":1000}},"be06199c2b1d4ae2a07894bc2987d6fe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba94466392da4095acb863389f3d60d3","placeholder":"​","style":"IPY_MODEL_a475aaa9c50543d18b1f3ff8c7975ab8","value":" 1000/1000 [00:10&lt;00:00, 96.84 examples/s]"}},"c595cdbe30834a0091317366bd21f08b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1255e55f5f0491f901b8e5302fd8790":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6fc09d762b24169bdc70e32d7978260":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2604d340be284cd8abd95904cb9a4398":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de57eb04125a417e978b9608efe74909":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ba94466392da4095acb863389f3d60d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a475aaa9c50543d18b1f3ff8c7975ab8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"abbf9abb049044749bd89a04045a4869":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9afe29df5d4141908d09cc5439cf1f0d","IPY_MODEL_cad439087738493f95be41ca8df53c50","IPY_MODEL_20d5b1610ac34a7ba5b5375a09702ef6"],"layout":"IPY_MODEL_6ed417e5a79649158339e4569a197a9e"}},"9afe29df5d4141908d09cc5439cf1f0d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a8071e91ad34684aac95ae6afcb99a4","placeholder":"​","style":"IPY_MODEL_ba2e6916c1a04605b09fc7c4eb2bd543","value":"Filter: 100%"}},"cad439087738493f95be41ca8df53c50":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_119e268986034d7283b3e3405fd2065a","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_59490df592364b18ad7642f3573be79b","value":1000}},"20d5b1610ac34a7ba5b5375a09702ef6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_890424d5b06d4edea0e9f3dc8fe6e613","placeholder":"​","style":"IPY_MODEL_5d67da807ed14a43b572cb452f7d847f","value":" 1000/1000 [00:10&lt;00:00, 98.22 examples/s]"}},"6ed417e5a79649158339e4569a197a9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a8071e91ad34684aac95ae6afcb99a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba2e6916c1a04605b09fc7c4eb2bd543":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"119e268986034d7283b3e3405fd2065a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59490df592364b18ad7642f3573be79b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"890424d5b06d4edea0e9f3dc8fe6e613":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d67da807ed14a43b572cb452f7d847f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d4c3a19a49604df8b90a50ff9d220801":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_befdd07cc38f435a950da0ae8d1a442e","IPY_MODEL_16ee4fa46db243d5af2ddb855b2bd371","IPY_MODEL_e98d421961d7412db3f15e5490d67a5b"],"layout":"IPY_MODEL_85bc634cac77438ab91c125c5205ce06"}},"befdd07cc38f435a950da0ae8d1a442e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78962328631149ad8f3d677d8fadbd34","placeholder":"​","style":"IPY_MODEL_8f9518de5d5f45a69b084023d94b024d","value":"Map: 100%"}},"16ee4fa46db243d5af2ddb855b2bd371":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_77e349ee00b14b5eb2464d4c49354950","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_efc4e93e6dc6499d9c9a05b84fd6af16","value":1000}},"e98d421961d7412db3f15e5490d67a5b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf19bc3ac34c4ae58ed831709355132e","placeholder":"​","style":"IPY_MODEL_5eb08e922ff24be6b6f2279186b94c61","value":" 1000/1000 [00:00&lt;00:00, 8685.87 examples/s]"}},"85bc634cac77438ab91c125c5205ce06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78962328631149ad8f3d677d8fadbd34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f9518de5d5f45a69b084023d94b024d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"77e349ee00b14b5eb2464d4c49354950":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efc4e93e6dc6499d9c9a05b84fd6af16":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cf19bc3ac34c4ae58ed831709355132e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5eb08e922ff24be6b6f2279186b94c61":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc05f1ab61904c54bc09d2fb9481dc9e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_59cf61ca0d484739a98119018701a4af","IPY_MODEL_d6733d51c9a149dea796585f6e31de0c","IPY_MODEL_c64ec7f8bd3f4e9995212d5ba8e8c8ed"],"layout":"IPY_MODEL_7419e0ad49d5472da04eef5672a11fd1"}},"59cf61ca0d484739a98119018701a4af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f89a1bf08614982aaa0b9d0f9ffb654","placeholder":"​","style":"IPY_MODEL_3511c0d020b548159c37ed2686dafbe8","value":"Generating train split: 100%"}},"d6733d51c9a149dea796585f6e31de0c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_844ae73426dc4f71abc7c9174e1cf829","max":9000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9b2447ba944c4201b765b46dcdddd13c","value":9000}},"c64ec7f8bd3f4e9995212d5ba8e8c8ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_def3ab23d75348caa485d9a7e2c9f969","placeholder":"​","style":"IPY_MODEL_37abc9c1f1c5437a8fc9fdcc330bbbb3","value":" 9000/9000 [00:02&lt;00:00, 3521.03 examples/s]"}},"7419e0ad49d5472da04eef5672a11fd1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f89a1bf08614982aaa0b9d0f9ffb654":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3511c0d020b548159c37ed2686dafbe8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"844ae73426dc4f71abc7c9174e1cf829":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b2447ba944c4201b765b46dcdddd13c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"def3ab23d75348caa485d9a7e2c9f969":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37abc9c1f1c5437a8fc9fdcc330bbbb3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1e385b4518054708ba047a00aedea970":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2e2ac5558c6249f28fd66951d28b1c41","IPY_MODEL_24e4d8f3fad3414a8a12d969e31865f6","IPY_MODEL_deed90d693cf4965b53feee4821d1304"],"layout":"IPY_MODEL_3d255e8d34e448bba6a017b08317174b"}},"2e2ac5558c6249f28fd66951d28b1c41":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2a0b883e12f4da49a2736f8fe79b167","placeholder":"​","style":"IPY_MODEL_73499b12091a489fbb4ab1e3c8780825","value":"Generating test split: 100%"}},"24e4d8f3fad3414a8a12d969e31865f6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f71d06e1c35476b99d954b1cd89a540","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3d2d870aa2024a459320c0ecf74dcbe2","value":1000}},"deed90d693cf4965b53feee4821d1304":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_68cd87c9fb5b4e1da5a3811a304bfb2a","placeholder":"​","style":"IPY_MODEL_82846ab8a4b4418280d7f76c68f57306","value":" 1000/1000 [00:01&lt;00:00, 1111.81 examples/s]"}},"3d255e8d34e448bba6a017b08317174b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2a0b883e12f4da49a2736f8fe79b167":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73499b12091a489fbb4ab1e3c8780825":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f71d06e1c35476b99d954b1cd89a540":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d2d870aa2024a459320c0ecf74dcbe2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"68cd87c9fb5b4e1da5a3811a304bfb2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82846ab8a4b4418280d7f76c68f57306":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"544a2c80725f4f49b8658dc7fc6f06e6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b69d0a6862394c7cbe11c899ab807ab8","IPY_MODEL_ed7bde10d3f047bf9cac28c8977724ed","IPY_MODEL_a626e461dd2f4536a25f5ca7d088e628"],"layout":"IPY_MODEL_a0b68d6e236c49a99f873ebf8d2409a1"}},"b69d0a6862394c7cbe11c899ab807ab8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_02de353f90774ac888ad924d30e5f83e","placeholder":"​","style":"IPY_MODEL_b2ada760a0f646c28c88957379d8b774","value":"Generating validation split: 100%"}},"ed7bde10d3f047bf9cac28c8977724ed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_96ef4825c8884952949376f51c0fcce1","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7e91bb99bae241cb8365eca872517881","value":1000}},"a626e461dd2f4536a25f5ca7d088e628":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_23122cfb87d64e0092a7ab83bdb513d7","placeholder":"​","style":"IPY_MODEL_8189d3cb6c0c4b71870681514cb01ec0","value":" 1000/1000 [00:01&lt;00:00, 1234.95 examples/s]"}},"a0b68d6e236c49a99f873ebf8d2409a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02de353f90774ac888ad924d30e5f83e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2ada760a0f646c28c88957379d8b774":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96ef4825c8884952949376f51c0fcce1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e91bb99bae241cb8365eca872517881":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"23122cfb87d64e0092a7ab83bdb513d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8189d3cb6c0c4b71870681514cb01ec0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f70d15af949d414b803634e6c1f391ec":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_50a3899eba3944c78fb6c4808351bc75","IPY_MODEL_f7b8a26f8c6e4033a87bf12675381e4f","IPY_MODEL_7bebc66ed79a412297f25d8acac99c6b"],"layout":"IPY_MODEL_23a4f9555da346089dd06b580437fbde"}},"50a3899eba3944c78fb6c4808351bc75":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fe379558ffa46a18c8f7ddd0d387fb9","placeholder":"​","style":"IPY_MODEL_b6156c33b1e145d988ac668d5ed86b82","value":"Running tokenizer on train dataset: 100%"}},"f7b8a26f8c6e4033a87bf12675381e4f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9ce81938f464d8cb2502102171fefe0","max":10000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c80f835a0a074c5ab7e6d7752e58783e","value":10000}},"7bebc66ed79a412297f25d8acac99c6b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a27785b1a5f4de1a7441f006a455d24","placeholder":"​","style":"IPY_MODEL_908d186dab7f4724a276e14810a0bcac","value":" 10000/10000 [00:59&lt;00:00, 145.25 examples/s]"}},"23a4f9555da346089dd06b580437fbde":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fe379558ffa46a18c8f7ddd0d387fb9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6156c33b1e145d988ac668d5ed86b82":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a9ce81938f464d8cb2502102171fefe0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c80f835a0a074c5ab7e6d7752e58783e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3a27785b1a5f4de1a7441f006a455d24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"908d186dab7f4724a276e14810a0bcac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b9918cbf1be4a5e851a706e93b62111":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c61389f402eb45ecb85d7f2153f570d7","IPY_MODEL_c19d04ec54bb40048e82623d557016e7","IPY_MODEL_91db8b9d7b9d4085bafc06be36160e1c"],"layout":"IPY_MODEL_ff8e9b636914415cb133d330b1e35dde"}},"c61389f402eb45ecb85d7f2153f570d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f2524c7b3ff42468c72e0796888aa71","placeholder":"​","style":"IPY_MODEL_b62c3fd8540a45c082c7821566c4cb4f","value":"Running tokenizer on validation dataset: 100%"}},"c19d04ec54bb40048e82623d557016e7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef407401a7c244e8b0deda161fff7a1f","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8afcf9e5dcfe4797bf16b9fc6cf45beb","value":1000}},"91db8b9d7b9d4085bafc06be36160e1c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2b773b636bf4dca9457430ac7583d2c","placeholder":"​","style":"IPY_MODEL_59756d9dc6a94f828f7e5567a5c882d1","value":" 1000/1000 [00:05&lt;00:00, 184.03 examples/s]"}},"ff8e9b636914415cb133d330b1e35dde":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f2524c7b3ff42468c72e0796888aa71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b62c3fd8540a45c082c7821566c4cb4f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef407401a7c244e8b0deda161fff7a1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8afcf9e5dcfe4797bf16b9fc6cf45beb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f2b773b636bf4dca9457430ac7583d2c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59756d9dc6a94f828f7e5567a5c882d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bbf6fb7e11c742cd8550ebfc38e2c527":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_de57dae9dee646708073ffef9f51b889","IPY_MODEL_56ffa4b2535144f88902fe8ba483652c","IPY_MODEL_83d5c422812243e88e502271914ed04e"],"layout":"IPY_MODEL_578e6906573b4df6bf39f84481857bcd"}},"de57dae9dee646708073ffef9f51b889":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_96184b13cb2b404a8fa385ea595120e7","placeholder":"​","style":"IPY_MODEL_24dd9366a23044deb987bc4ad360bb56","value":"Running tokenizer on prediction dataset: 100%"}},"56ffa4b2535144f88902fe8ba483652c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_762b0854af66448d858cb3d0b3146302","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_77ae753e09cc4b4a980ba4822c88a50b","value":1000}},"83d5c422812243e88e502271914ed04e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0e6c5bf9ddd46039f9870cb09bbfc23","placeholder":"​","style":"IPY_MODEL_e2e29ed56b66437d960355dd115bb985","value":" 1000/1000 [00:05&lt;00:00, 192.42 examples/s]"}},"578e6906573b4df6bf39f84481857bcd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96184b13cb2b404a8fa385ea595120e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24dd9366a23044deb987bc4ad360bb56":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"762b0854af66448d858cb3d0b3146302":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77ae753e09cc4b4a980ba4822c88a50b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b0e6c5bf9ddd46039f9870cb09bbfc23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2e29ed56b66437d960355dd115bb985":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WOGVj229u42s","executionInfo":{"status":"ok","timestamp":1692586982623,"user_tz":-60,"elapsed":51894,"user":{"displayName":"Sumit Gupta","userId":"07308348120090087318"}},"outputId":"5ad98895-4754-4f79-a6d2-709f4dc8c066"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Collecting transformers\n","  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m110.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.16.4 safetensors-0.3.2 tokenizers-0.13.3 transformers-4.31.0\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n","Collecting datasets\n","  Downloading datasets-2.14.4-py3-none-any.whl (519 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.3/519.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, dill, multiprocess, datasets\n","Successfully installed datasets-2.14.4 dill-0.3.7 multiprocess-0.70.15 xxhash-3.3.0\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.6)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.10.1)\n","Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.23.5)\n","Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.31.0)\n","Collecting accelerate\n","  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.16.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.3.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n","Requirement already satisfied: torch!=1.12.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.0.1+cu118)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]) (3.27.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]) (16.0.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.9->transformers[torch]) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.9->transformers[torch]) (1.3.0)\n","Installing collected packages: accelerate\n","Successfully installed accelerate-0.21.0\n"]}],"source":["! pip install torch\n","! pip install transformers\n","! pip install scikit-learn\n","! pip install tqdm\n","! pip install numpy\n","! pip install datasets\n","! pip install nltk\n","import nltk\n","nltk.download('stopwords')\n","! pip install scipy\n","! pip install transformers[torch] accelerate\n"]},{"cell_type":"code","source":["from datasets import load_dataset\n","existing_dataset = load_dataset(\"lex_glue\", 'ecthr_b')\n","train=existing_dataset[\"train\"]\n","print(train[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XYw0Md6sMoty","executionInfo":{"status":"ok","timestamp":1692069587536,"user_tz":-60,"elapsed":3180,"user":{"displayName":"Sumit Gupta","userId":"07308348120090087318"}},"outputId":"f3d00a31-88ac-488e-de05-ae528bc2750c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'text': ['9.  The applicant is the monarch of Liechtenstein, born in 1945 and living in Vaduz (Liechtenstein).', '10.  The applicant’s late father, the former monarch of Liechtenstein, had been the owner of the painting Szene an einem römischen Kalkofen (alias Der große Kalkofen) of Pieter van Laer, which had formed part of his family’s art collection since at least 1767. Until the end of the Second World War the painting had been in one of the family’s castles on the territory of the now Czech Republic.', '11.  In 1946 the former Czechoslovakia confiscated the property of the applicant’s father which was situated in its territory, including the painting in question, under Decree no. 12 on the “confiscation and accelerated allocation of agricultural property of German and Hungarian persons and of those having committed treason and acted as enemies of the Czech and Slovak people” (dekretu prezidenta republiky č. 12/1945 Sb. o konfiskaci a urychleném rozdělení majetku Němců, Mad’arů, zrádců a nepřátel), issued by the President of the former Czechoslovakia on 21 June 1945 (“the Beneš Decrees” – “Benešovy dekrety”).', '12.  On 21 November 1951 the Bratislava Administrative Court (správní soud) dismissed the appeal lodged by the applicant’s father. \\nIn its reasoning on the merits of the case, the Administrative Court stated that the defendant office had come to the conclusion that the appellant was a person of German nationality within the meaning of the provision in Article 1 § 1 (a) of the decree, on the basis of a finding that this was and had been generally known. It noted that the defence of the complaint directed against this finding was restricted to the representation that this finding was not supported in the files and that, due to this shortcoming, it had not been necessary to deal with the finding in greater detail. The Administrative Court considered that this approach was mistaken as, under the relevant provision of the administrative regulations, no evidence was required for facts which were generally known and, therefore, it was not necessary for evidence to be contained in the administrative files; however, counter-evidence against an official finding that a certain fact was generally known would have been admitted. \\nThe Administrative Court concluded that, as the appellant had failed to raise the objection that the issue was not a fact of general knowledge and to contend that he was in a position to bring counter-evidence, the finding of the defendant office had remained uncontested.', '13.  In 1991 the municipality of Cologne obtained the painting as a temporary loan from the Brno Historical Monuments Office in the Czech Republic.', '14.  On 11 November 1991 the Cologne Regional Court (Landgericht) granted the applicant’s request for an interim injunction ordering the municipality of Cologne to hand over the painting to a bailiff at the end of the exhibition. The painting was sequestrated on 17 December 1991.', '15.  At the beginning of 1992 the applicant instituted proceedings before the Cologne Regional Court against the municipality of Cologne, requesting that the defendant consent to the delivery of the painting to him by the bailiff. He argued that, as his late father’s heir, he was the owner of the painting. He submitted that the painting had not been subject to expropriation measures in the former Czechoslovakia and that in any event such measures were invalid or irrelevant on account of violation of the ordre public of the Federal Republic of Germany.', '16.  The Brno Historical Monuments Office intervened in these proceedings in support of the defendant. It submitted that the applicant’s father had lost his ownership of the painting as a result of the confiscation in 1946 and that the lawfulness of this confiscation had been confirmed by the Bratislava Administrative Court in its decision of 21 November 1951.', '17.  On 10 October 1995 the Cologne Regional Court, following a hearing, declared the applicant’s action inadmissible. In the court’s view, Chapter 6, Article 3, of the Convention on the Settlement of Matters Arising out of the War and the Occupation (Vertrag zur Regelung aus Krieg und Besatzung entstandener Fragen – “the Settlement Convention”) of 23 October 1954 between the United States of America, the United Kingdom of Great Britain and Northern Ireland, the French Republic and the Federal Republic of Germany excluded German jurisdiction over the applicant’s case. \\nIn its reasoning, the Regional Court noted that, under the terms of that Article’s paragraph 3 taken in conjunction with paragraph 1, claims or actions against persons having acquired or transferred title to property on the basis of measures carried out with regard to German external assets or other property, seized for the purpose of reparation or restitution, or as a result of the state of war, or on the basis of specific agreements, were not admissible. These particular provisions had been confirmed upon German unification.\\nAccording to the Regional Court, Chapter 6, Article 3 § 3, of the Settlement Convention applied, mutatis mutandis, to the applicant’s claims against the defendant, which had obtained the painting on loan and had not acquired property, because any review of the aforementioned measures should be excluded.\\nThe Regional Court found that the confiscation of the applicant’s father’s property under Decree no. 12 on the “confiscation and accelerated allocation of agricultural property of German and Hungarian persons and of those having committed treason and acted as enemies of the Czech and Slovak people”, issued by the President of the former Czechoslovakia on 21 June 1945, constituted a measure within the meaning of Chapter 6, Article 3 § 3. \\nThe Regional Court rejected, in particular, the applicant’s argument that this provision did not apply as it only concerned measures carried out with regard to German external assets or other property and his father had never been a German citizen. In this respect, the court, referring to case-law of the Federal Court of Justice (Bundesgerichtshof), stated that the view of the confiscating State was decisive. The aim and purpose of this provision, namely to sanction, without any further examination, confiscation measures implemented abroad could only be achieved by excluding such measures from judicial review in Germany.\\nMoreover, the Regional Court found that the confiscation measure in question pursued one of the purposes mentioned in Chapter 6, Article 3 § 3. Having regard to German case-law regarding other “Beneš Decrees”, especially Decree no. 108 on the “confiscation of enemy property and the national reform fund”, it considered that Decree no. 12, while also pursuing economic aims, was intended to expropriate the property of German and Hungarian nationals, that is, “enemy property”.\\nThe Regional Court further noted that the applicant’s father’s painting had been expropriated under Decree no. 12. The competent Czechoslovakian authorities had interpreted its provisions as applying to the applicant’s father, regarding him as a “person of German nationality”.  The applicant’s father had unsuccessfully appealed against this decision which had been confirmed by the Bratislava Administrative Court in 1951. The German courts were not in a position to review the lawfulness of the confiscation at issue.\\nFinally, the Regional Court considered that the painting at issue, as part of the inventory of the agricultural property, had been included in the confiscation measure. \\nThe Regional Court dismissed the applicant’s request to suspend the proceedings in order to await the outcome of proceedings to be instituted under the German Equalisation of Burdens Act (Lastenausgleichsgesetz) concerning compensation for damage and losses due to, inter alia, expulsion and destruction during the Second World War and the post-war period in the then Soviet-occupied zone of Germany and of Berlin. The Regional Court considered that the question underlying the litigation before it would not be clarified in such proceedings. Irrespective of the question of whether the plaintiff was of German origin, he had no equalisation claims under the said legislation, which only applied to persons who resided in the Federal Republic of Germany or West Berlin on 31 December 1952. In any event, there was no right to compensation for the loss of works of art (Kunstgegenstände).', '18.  On 9 July 1996 the Cologne Court of Appeal (Oberlandesgericht) dismissed the applicant’s appeal. The Court of Appeal confirmed that the applicant’s action was inadmissible as German jurisdiction in respect of his claim was excluded under Chapter 6, Article 3 § 1, in conjunction with paragraph 3, of the Settlement Convention.\\nThe Court of Appeal considered that the notion of German jurisdiction included the competence, derived from State sovereignty and generally vested by the State in the courts, to administer justice. German jurisdiction was delimited by international agreements, customary international law and the generally recognised rules of international law. Chapter 6, Article 3 § 3, taken in conjunction with paragraph 1, of the Settlements Convention excluded German jurisdiction in respect of claims and actions against persons, who, as a consequence of reparation measures, had directly or indirectly acquired title to German property confiscated abroad.\\nThe Court of Appeal confirmed that the provisions in question continued to be in force under the Treaty of 12 September 1990 on the Final Settlement with respect to Germany. Article 7 of this Treaty, which provided for the termination of the operation of quadripartite rights and responsibilities with respect to Berlin and Germany as a whole, was amended by the Agreement of 27 and 28 September 1990 according to which the Settlement Convention was suspended and later terminated with the exception of the provisions specified in paragraph 3 of that Agreement, inter alia, Chapter 6, Article 3 §§ 1 and 3. That Agreement was valid under public international law and under German constitutional law.\\nThe Court of Appeal further considered that Chapter 6, Article 3 § 3, of the Settlement Convention applied in the applicant’s case. In the court’s view, this provision was the procedural consequence of the notion that the legal relations resulting from the liquidation of German property abroad by foreign powers for the purpose of reparation were “final and unchallengeable” (Endgültigkeit und Unanfechtbarkeit) for the Federal Republic of Germany and the private persons concerned. \\nAccording to the Court of Appeal, the applicant’s constitutional rights, in particular his right to property, his right of access to a court and his right to a decision by the legally competent court (gesetzlicher Richter), had not been infringed. Basic rights protected individuals against acts of domestic public authorities and not against the exercise of public authority by a foreign State abroad. The domestic legislator was therefore not prevented from limiting domestic legal protection against violations of basic rights by a foreign State if this was necessary to attain more important goals.\\nWhen applying Chapter 6, Article 3 § 3, of the Settlement Convention, the domestic law of the expropriating State concerning the concrete confiscation measure had to be taken into account, as this provision was aimed at excluding litigation in Germany regarding confiscation measures based on legislation concerning enemy property. \\nAs regards the applicant’s objections against the lawfulness, in particular under public international law, of the confiscation and expropriation of his father’s property, the Court of Appeal found that by virtue of Chapter 6, Article 3 § 3 of the Settlement Convention, German courts had no jurisdiction. Likewise, this provision did not allow recourse to be had to general rules of public international law or to German ordre public when examining the admissibility of the action. The applicant’s argument that the provisions of the Settlement Convention and their application to him as a national and head of a neutral State violated the law of peace was accordingly rejected.\\nAccording to the Court of Appeal, the painting at issue constituted external assets within the meaning of Chapter 6, Article 3 § 1, of the Settlement Convention, referred to in paragraph 3 of Article 3. The Court of Appeal noted that the applicant’s father had indisputably never had German nationality. However, following the case-law of the Federal Court of Justice, it considered that the notion of “German external assets” had to be interpreted in the light of the law of the expropriating State. The confiscation in dispute had been found to be in compliance with the legislation of the expropriating State: the competent Czechoslovakian administrative authorities as well as the Bratislava Administrative Court had found that Presidential Decree no. 12 of 21 June 1945 applied to the applicant’s father’s confiscated property. Article 1 § 1 (a) of this decree provided for the confiscation of agricultural properties of “all persons of German or Hungarian nationality” irrespective of their citizenship. The notions of “German nationality”, or of “German origin” (“deutsche Volkszugehörigkeit”), likewise used at that time, comprised as relevant elements a person’s citizenship and nationality, the latter depending on the mother tongue. At the relevant time, the Czechoslovakian authorities indisputably regarded the applicant’s father as of German origin in that broader sense.\\nThe Court of Appeal also found that the painting at issue, as part of the confiscated agricultural property, had been subject to the expropriation measure. There were no doubts as to the effectiveness of the expropriation, as it was sufficient under the relevant case-law that such expropriations had been implemented and that the previous owners had been deprived of their factual power of disposition. Furthermore, the painting had been confiscated for the purpose of reparation within the meaning of Chapter 6, Article 3 §§ 1 and 3, of the Settlement Agreement. The limitation of the confiscation measures to persons belonging to enemy States in itself justified such a conclusion. The assets of the persons concerned were confiscated as enemy assets.  \\nFinally, the Court of Appeal considered that both the defendant and the intervener belonged to the group of persons protected by Chapter 6, Article 3 § 3, of the Settlement Agreement. German jurisdiction was excluded whenever the plaintiff intended to challenge measures within the meaning of Chapter 6, Article 3 § 1.', '19.  On 25 September 1997 the Federal Court of Justice refused to entertain the applicant’s appeal on points of law, as the case was of no fundamental importance and, in any event, had no prospect of success.', '20.  On 28 January 1998 the Third Section of the Second Division (3. Kammer des zweiten Senats) of the Federal Constitutional Court (Bundesverfassungsgericht) refused to entertain the applicant’s constitutional complaint (Verfassungsbeschwerde), as it offered no prospect of success. \\nThe Federal Constitutional Court considered in particular that, for the purposes of the civil court decisions, questions as to the existence or non-existence of certain rules of customary international law on the confiscation of neutral assets or on the determination of citizenship were irrelevant as they concerned the issue of the lawfulness of the expropriation by the former Czechoslovakia. The German civil courts had not decided this issue and, under public international law, they had not been obliged to do so. Moreover, to the extent that the civil courts had regarded the expropriation as a measure within the meaning of Chapter 6, Article 3 § 1, of the Settlement Convention, they had expressly refrained from qualifying the applicant’s father’s nationality. Their interpretation of the terms “measures with regard to German external assets” as comprising any measures which, in the intention of the expropriating State, were directed against German assets, could not be objected to under constitutional law. The bar on litigation did not constitute an agreement to the detriment of Liechtenstein, as only the Federal Republic of Germany and its courts were under this treaty obligation.\\nThe Federal Constitutional Court further recalled that the exclusion of jurisdiction did not amount to a violation of the right of property as these clauses and the Settlement Convention as a whole served to settle matters dating back to a time before the entry into force of the German Basic Law (Grundgesetz) on 23 May 1949.\\nFinally, there was no indication of arbitrariness or of a violation of other constitutional rights. The Federal Constitutional Court confirmed that Chapter 6, Article 3 §§ 1 and 3, of the Settlement Convention had not been set aside by the Treaty on the Final Settlement with respect to Germany: while Germany obtained full sovereignty, its obligations under treaties with the Three Powers were not affected. This had also been the legal opinion of the Federal Republic of Germany and the Three Powers, which otherwise would not have settled the suspension and termination of parts of the Settlement Convention in a separate agreement.\\nThe decision was served on 2 February 1998.', '21.  On 9 June 1998 the Cologne Regional Court discharged its interim injunction of 11 November 1991. The bailiff thereupon handed the painting over to the Cologne municipality, which had it returned to the Czech Republic.'], 'labels': [8, 3, 9]}\n"]}]},{"cell_type":"code","source":["from dataclasses import dataclass\n","from typing import Optional, Tuple\n","\n","import torch\n","import numpy as np\n","from torch import nn\n","from transformers.file_utils import ModelOutput\n","\n","\n","@dataclass\n","class SimpleOutput(ModelOutput):\n","    last_hidden_state: torch.FloatTensor = None\n","    past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n","    hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n","    attentions: Optional[Tuple[torch.FloatTensor]] = None\n","    cross_attentions: Optional[Tuple[torch.FloatTensor]] = None\n","\n","\n","def sinusoidal_init(num_embeddings: int, embedding_dim: int):\n","    # keep dim 0 for padding token position encoding zero vector\n","    position_enc = np.array([\n","        [pos / np.power(10000, 2 * i / embedding_dim) for i in range(embedding_dim)]\n","        if pos != 0 else np.zeros(embedding_dim) for pos in range(num_embeddings)])\n","\n","    position_enc[1:, 0::2] = np.sin(position_enc[1:, 0::2])  # dim 2i\n","    position_enc[1:, 1::2] = np.cos(position_enc[1:, 1::2])  # dim 2i+1\n","    return torch.from_numpy(position_enc).type(torch.FloatTensor)\n","\n","\n","class HierarchicalBert(nn.Module):\n","\n","    def __init__(self, encoder, max_segments=64, max_segment_length=128):\n","        super(HierarchicalBert, self).__init__()\n","        supported_models = ['bert', 'roberta', 'deberta']\n","        assert encoder.config.model_type in supported_models  # other model types are not supported so far\n","        # Pre-trained segment (token-wise) encoder, e.g., BERT\n","        self.encoder = encoder\n","        # Specs for the segment-wise encoder\n","        self.hidden_size = encoder.config.hidden_size\n","        self.max_segments = max_segments\n","        self.max_segment_length = max_segment_length\n","        # Init sinusoidal positional embeddings\n","        self.seg_pos_embeddings = nn.Embedding(max_segments + 1, encoder.config.hidden_size,\n","                                               padding_idx=0,\n","                                               _weight=sinusoidal_init(max_segments + 1, encoder.config.hidden_size))\n","        # Init segment-wise transformer-based encoder\n","        self.seg_encoder = nn.Transformer(d_model=encoder.config.hidden_size,\n","                                          nhead=encoder.config.num_attention_heads,\n","                                          batch_first=True, dim_feedforward=encoder.config.intermediate_size,\n","                                          activation=encoder.config.hidden_act,\n","                                          dropout=encoder.config.hidden_dropout_prob,\n","                                          layer_norm_eps=encoder.config.layer_norm_eps,\n","                                          num_encoder_layers=2, num_decoder_layers=0).encoder\n","\n","    def forward(self,\n","                input_ids=None,\n","                attention_mask=None,\n","                token_type_ids=None,\n","                position_ids=None,\n","                head_mask=None,\n","                inputs_embeds=None,\n","                labels=None,\n","                output_attentions=None,\n","                output_hidden_states=None,\n","                return_dict=None,\n","                ):\n","        # Hypothetical Example\n","        # Batch of 4 documents: (batch_size, n_segments, max_segment_length) --> (4, 64, 128)\n","        # BERT-BASE encoder: 768 hidden units\n","\n","        # Squash samples and segments into a single axis (batch_size * n_segments, max_segment_length) --> (256, 128)\n","        input_ids_reshape = input_ids.contiguous().view(-1, input_ids.size(-1))\n","        attention_mask_reshape = attention_mask.contiguous().view(-1, attention_mask.size(-1))\n","        if token_type_ids is not None:\n","            token_type_ids_reshape = token_type_ids.contiguous().view(-1, token_type_ids.size(-1))\n","        else:\n","            token_type_ids_reshape = None\n","\n","        # Encode segments with BERT --> (256, 128, 768)\n","        encoder_outputs = self.encoder(input_ids=input_ids_reshape,\n","                                       attention_mask=attention_mask_reshape,\n","                                       token_type_ids=token_type_ids_reshape)[0]\n","\n","        # Reshape back to (batch_size, n_segments, max_segment_length, output_size) --> (4, 64, 128, 768)\n","        encoder_outputs = encoder_outputs.contiguous().view(input_ids.size(0), self.max_segments,\n","                                                            self.max_segment_length,\n","                                                            self.hidden_size)\n","\n","        # Gather CLS outputs per segment --> (4, 64, 768)\n","        encoder_outputs = encoder_outputs[:, :, 0]\n","\n","        # Infer real segments, i.e., mask paddings\n","        seg_mask = (torch.sum(input_ids, 2) != 0).to(input_ids.dtype)\n","        # Infer and collect segment positional embeddings\n","        seg_positions = torch.arange(1, self.max_segments + 1).to(input_ids.device) * seg_mask\n","        # Add segment positional embeddings to segment inputs\n","        encoder_outputs += self.seg_pos_embeddings(seg_positions)\n","\n","        # Encode segments with segment-wise transformer\n","        seg_encoder_outputs = self.seg_encoder(encoder_outputs)\n","\n","        # Collect document representation\n","        outputs, _ = torch.max(seg_encoder_outputs, 1)\n","\n","        return SimpleOutput(last_hidden_state=outputs, hidden_states=outputs)\n","\n","\n","if __name__ == \"__main__\":\n","    from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n","    tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","\n","    # Use as a stand-alone encoder\n","    bert = AutoModel.from_pretrained('bert-base-uncased')\n","    model = HierarchicalBert(encoder=bert, max_segments=64, max_segment_length=128)\n","\n","    fake_inputs = {'input_ids': [], 'attention_mask': [], 'token_type_ids': []}\n","    for i in range(4):\n","        # Tokenize segment\n","        temp_inputs = tokenizer(['dog ' * 126] * 64)\n","        fake_inputs['input_ids'].append(temp_inputs['input_ids'])\n","        fake_inputs['attention_mask'].append(temp_inputs['attention_mask'])\n","        fake_inputs['token_type_ids'].append(temp_inputs['token_type_ids'])\n","\n","    fake_inputs['input_ids'] = torch.as_tensor(fake_inputs['input_ids'])\n","    fake_inputs['attention_mask'] = torch.as_tensor(fake_inputs['attention_mask'])\n","    fake_inputs['token_type_ids'] = torch.as_tensor(fake_inputs['token_type_ids'])\n","\n","    output = model(fake_inputs['input_ids'], fake_inputs['attention_mask'], fake_inputs['token_type_ids'])\n","\n","    # 4 document representations of 768 features are expected\n","    assert output[0].shape == torch.Size([4, 768])\n","\n","    # Use with HuggingFace AutoModelForSequenceClassification and Trainer API\n","\n","    # Init Classifier\n","    model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=10)\n","    # Replace flat BERT encoder with hierarchical BERT encoder\n","    model.bert = HierarchicalBert(encoder=model.bert, max_segments=64, max_segment_length=128)\n","    output = model(fake_inputs['input_ids'], fake_inputs['attention_mask'], fake_inputs['token_type_ids'])\n","\n","    # 4 document outputs with 10 (num_labels) logits are expected\n","    assert output.logits.shape == torch.Size([4, 10])\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":233,"referenced_widgets":["287e30e99c8c4dcabaf690414eeaaa87","d29b2dec3a1d43e0905224e52c8417f7","db74ae34db374803b0d0809479562db2","0c1db1c090dc4374a3f2daf074204ee1","da291cd3d0b4495bbaf93752d9eeda31","bec3f6ddeb5e4d868c491bbcec1f7073","33923af374b84ff9b9b124497f4053a4","6c0ce1bfd50444f08a5cad5998564823","3849754a1ad84b209be72b543f0a224c","76d657f0e06e47ff853c10413b9b77b5","6976cc179e2848b9a6f818655a2010c3","630f783d3c1b460d89d6175a77a6406f","d200ff919be04ab09bec021237089ea5","7b341142a20745538efe30ecaadd377f","2382e6c48e1e456a90f2074df71dc81a","25c8c8e81b664bcab34ca55710683001","b659002170e349d8878a936d82050538","342b02891d8141938e97bc084925965c","94d5a463aeb3441494abf80d6794144f","8109f30a5caa49b693a97a19be216bcb","8fe037c135a54eb8828f53cb85fe9ab4","5648b2252eaf4b87a79ea3fc0be5e3bd","eb2c696d553e4e26ba9cdb882ec4a43e","382dc9306b2f434088f5762364a9596d","ed2df6bc13404ac5908f0a8047a6c095","7ef3b1c379ce4f6da097640619b3d61f","b9b4a5b0357a4992b0571fc825dbe926","efa930e3a4164262bc70939f02bbf36e","32bd2aab24b445c2af11117657861233","a5317e5a3c324848ac8c0902bbdcd991","9dd7eed4a57d4a2ab7355fee726871a8","8ebd1912d6dd43b28e8d9d7ce90eebc2","1cd0269b17624ac6ae3ccd0e5ac0d2b5","5f2dc2e97e494dcba490ce69d44011fc","ebeae4d55614414db67370ca357dadec","cea9a0dbf74f4f9cbc65c259d799d111","16f3d881bf174217b99c65b0f686f1a0","39ab58ae08874af79c8b5732a3b53480","0057bfa29a49408eb4af39e5ec835d9e","f7e7851053f64abda95dff2e47836896","e4768f682d084632ade179ef82243f7f","f1b2fb21fe7f4e6aa0a8181b6901bd9b","b5c67ce56af7432eac354bf903f976dd","2b755a3a872443a9a2e8d81aa4a3727b","d81ed8a2cfa14187b973549b1060fbc1","ffbd4738441f4a42805c20fbda649013","ddd4287505b548278095e3387c58a3b5","59f25258bd44486db285487e66cdc2ff","6c693e9c571f4656b820bb9f75750cc5","2b2b91fd0c3042d9900b9769e6b0fd4e","643da12a123a44dc9cc45f74884f62ce","b1431a66d40d49d1b392007670c7adde","a705c489bd1745f4ad0e878d6dfeca15","d51cc638e58b4dec92dbacdb4b5ac57f","d440d3729e2f4a4facba257cd9e61f25"]},"id":"jZyTQraUvCvM","executionInfo":{"status":"ok","timestamp":1692587029758,"user_tz":-60,"elapsed":47148,"user":{"displayName":"Sumit Gupta","userId":"07308348120090087318"}},"outputId":"d22ea7d8-218c-4405-b18e-34f28fc5e648"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"287e30e99c8c4dcabaf690414eeaaa87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"630f783d3c1b460d89d6175a77a6406f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb2c696d553e4e26ba9cdb882ec4a43e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f2dc2e97e494dcba490ce69d44011fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d81ed8a2cfa14187b973549b1060fbc1"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["import torch\n","from torch import nn\n","from transformers import DebertaPreTrainedModel, DebertaModel\n","from transformers.modeling_outputs import SequenceClassifierOutput, MultipleChoiceModelOutput\n","from transformers.activations import ACT2FN\n","\n","\n","class ContextPooler(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.dense = nn.Linear(config.pooler_hidden_size, config.pooler_hidden_size)\n","        self.dropout = StableDropout(config.pooler_dropout)\n","        self.config = config\n","\n","    def forward(self, hidden_states):\n","        # We \"pool\" the model by simply taking the hidden state corresponding\n","        # to the first token.\n","\n","        context_token = hidden_states[:, 0]\n","        context_token = self.dropout(context_token)\n","        pooled_output = self.dense(context_token)\n","        pooled_output = ACT2FN[self.config.pooler_hidden_act](pooled_output)\n","        return pooled_output\n","\n","    @property\n","    def output_dim(self):\n","        return self.config.hidden_size\n","\n","\n","class DropoutContext(object):\n","    def __init__(self):\n","        self.dropout = 0\n","        self.mask = None\n","        self.scale = 1\n","        self.reuse_mask = True\n","\n","\n","def get_mask(input, local_context):\n","    if not isinstance(local_context, DropoutContext):\n","        dropout = local_context\n","        mask = None\n","    else:\n","        dropout = local_context.dropout\n","        dropout *= local_context.scale\n","        mask = local_context.mask if local_context.reuse_mask else None\n","\n","    if dropout > 0 and mask is None:\n","        mask = (1 - torch.empty_like(input).bernoulli_(1 - dropout)).bool()\n","\n","    if isinstance(local_context, DropoutContext):\n","        if local_context.mask is None:\n","            local_context.mask = mask\n","\n","    return mask, dropout\n","\n","\n","class XDropout(torch.autograd.Function):\n","    \"\"\"Optimized dropout function to save computation and memory by using mask operation instead of multiplication.\"\"\"\n","\n","    @staticmethod\n","    def forward(ctx, input, local_ctx):\n","        mask, dropout = get_mask(input, local_ctx)\n","        ctx.scale = 1.0 / (1 - dropout)\n","        if dropout > 0:\n","            ctx.save_for_backward(mask)\n","            return input.masked_fill(mask, 0) * ctx.scale\n","        else:\n","            return input\n","\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        if ctx.scale > 1:\n","            (mask,) = ctx.saved_tensors\n","            return grad_output.masked_fill(mask, 0) * ctx.scale, None\n","        else:\n","            return grad_output, None\n","\n","\n","class StableDropout(nn.Module):\n","    \"\"\"\n","    Optimized dropout module for stabilizing the training\n","\n","    Args:\n","        drop_prob (float): the dropout probabilities\n","    \"\"\"\n","\n","    def __init__(self, drop_prob):\n","        super().__init__()\n","        self.drop_prob = drop_prob\n","        self.count = 0\n","        self.context_stack = None\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Call the module\n","\n","        Args:\n","            x (:obj:`torch.tensor`): The input tensor to apply dropout\n","        \"\"\"\n","        if self.training and self.drop_prob > 0:\n","            return XDropout.apply(x, self.get_context())\n","        return x\n","\n","    def clear_context(self):\n","        self.count = 0\n","        self.context_stack = None\n","\n","    def init_context(self, reuse_mask=True, scale=1):\n","        if self.context_stack is None:\n","            self.context_stack = []\n","        self.count = 0\n","        for c in self.context_stack:\n","            c.reuse_mask = reuse_mask\n","            c.scale = scale\n","\n","    def get_context(self):\n","        if self.context_stack is not None:\n","            if self.count >= len(self.context_stack):\n","                self.context_stack.append(DropoutContext())\n","            ctx = self.context_stack[self.count]\n","            ctx.dropout = self.drop_prob\n","            self.count += 1\n","            return ctx\n","        else:\n","            return self.drop_prob\n","\n","\n","class DebertaForSequenceClassification(DebertaPreTrainedModel):\n","    def __init__(self, config):\n","        super().__init__(config)\n","\n","        num_labels = getattr(config, \"num_labels\", 2)\n","        self.num_labels = num_labels\n","\n","        self.deberta = DebertaModel(config)\n","\n","        self.classifier = nn.Linear(config.hidden_size, num_labels)\n","        drop_out = getattr(config, \"cls_dropout\", None)\n","        drop_out = self.config.hidden_dropout_prob if drop_out is None else drop_out\n","        self.dropout = nn.Dropout(drop_out)\n","\n","        self.init_weights()\n","\n","    def get_input_embeddings(self):\n","        return self.deberta.get_input_embeddings()\n","\n","    def set_input_embeddings(self, new_embeddings):\n","        self.deberta.set_input_embeddings(new_embeddings)\n","\n","    def forward(\n","        self,\n","        input_ids=None,\n","        attention_mask=None,\n","        token_type_ids=None,\n","        position_ids=None,\n","        inputs_embeds=None,\n","        labels=None,\n","        output_attentions=None,\n","        output_hidden_states=None,\n","        return_dict=None,\n","    ):\n","        r\"\"\"\n","        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n","            Labels for computing the sequence classification/regression loss. Indices should be in :obj:`[0, ...,\n","            config.num_labels - 1]`. If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),\n","            If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n","        \"\"\"\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","\n","        outputs = self.deberta(\n","            input_ids,\n","            token_type_ids=token_type_ids,\n","            attention_mask=attention_mask,\n","            position_ids=position_ids,\n","            inputs_embeds=inputs_embeds,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","\n","        pooled_output = self.dropout(outputs[1])\n","        logits = self.classifier(pooled_output)\n","\n","        loss = None\n","        if labels is not None:\n","            if self.num_labels == 1:\n","                # regression task\n","                loss_fn = nn.MSELoss()\n","                logits = logits.view(-1).to(labels.dtype)\n","                loss = loss_fn(logits, labels.view(-1))\n","            elif labels.dim() == 1 or labels.size(-1) == 1:\n","                label_index = (labels >= 0).nonzero()\n","                labels = labels.long()\n","                if label_index.size(0) > 0:\n","                    labeled_logits = torch.gather(logits, 0, label_index.expand(label_index.size(0), logits.size(1)))\n","                    labels = torch.gather(labels, 0, label_index.view(-1))\n","                    loss_fct = nn.CrossEntropyLoss()\n","                    loss = loss_fct(labeled_logits.view(-1, self.num_labels).float(), labels.view(-1))\n","                else:\n","                    loss = torch.tensor(0).to(logits)\n","            else:\n","                log_softmax = nn.LogSoftmax(-1)\n","                loss = -((log_softmax(logits) * labels).sum(-1)).mean()\n","        if not return_dict:\n","            output = (logits,) + outputs[1:]\n","            return ((loss,) + output) if loss is not None else output\n","        else:\n","            return SequenceClassifierOutput(\n","                loss=loss,\n","                logits=logits,\n","                hidden_states=outputs.hidden_states,\n","                attentions=outputs.attentions,\n","            )\n","\n","\n","class DebertaForMultipleChoice(DebertaPreTrainedModel):\n","    def __init__(self, config):\n","        super().__init__(config)\n","\n","        self.deberta = DebertaModel(config)\n","        self.pooler = ContextPooler(config)\n","        output_dim = self.pooler.output_dim\n","        drop_out = getattr(config, \"cls_dropout\", None)\n","        drop_out = self.config.hidden_dropout_prob if drop_out is None else drop_out\n","        self.dropout = StableDropout(drop_out)\n","        self.classifier = nn.Linear(output_dim, 1)\n","\n","        self.init_weights()\n","\n","    def forward(\n","            self,\n","            input_ids=None,\n","            attention_mask=None,\n","            token_type_ids=None,\n","            position_ids=None,\n","            inputs_embeds=None,\n","            labels=None,\n","            output_attentions=None,\n","            output_hidden_states=None,\n","            return_dict=None,\n","    ):\n","        r\"\"\"\n","        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n","            Labels for computing the multiple choice classification loss. Indices should be in ``[0, ...,\n","            num_choices-1]`` where :obj:`num_choices` is the size of the second dimension of the input tensors. (See\n","            :obj:`input_ids` above)\n","        \"\"\"\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","        num_choices = input_ids.shape[1] if input_ids is not None else inputs_embeds.shape[1]\n","\n","        input_ids = input_ids.view(-1, input_ids.size(-1)) if input_ids is not None else None\n","        attention_mask = attention_mask.view(-1, attention_mask.size(-1)) if attention_mask is not None else None\n","        token_type_ids = token_type_ids.view(-1, token_type_ids.size(-1)) if token_type_ids is not None else None\n","        position_ids = position_ids.view(-1, position_ids.size(-1)) if position_ids is not None else None\n","        inputs_embeds = (\n","            inputs_embeds.view(-1, inputs_embeds.size(-2), inputs_embeds.size(-1))\n","            if inputs_embeds is not None\n","            else None\n","        )\n","\n","        outputs = self.deberta(\n","            input_ids,\n","            token_type_ids=token_type_ids,\n","            attention_mask=attention_mask,\n","            position_ids=position_ids,\n","            inputs_embeds=inputs_embeds,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","\n","        encoder_layer = outputs[0]\n","        pooled_output = self.pooler(encoder_layer)\n","\n","        pooled_output = self.dropout(pooled_output)\n","        logits = self.classifier(pooled_output)\n","        reshaped_logits = logits.view(-1, num_choices)\n","\n","        loss = None\n","        if labels is not None:\n","            loss_fct = nn.CrossEntropyLoss()\n","            loss = loss_fct(reshaped_logits, labels)\n","\n","        if not return_dict:\n","            output = (reshaped_logits,) + outputs[2:]\n","            return ((loss,) + output) if loss is not None else output\n","\n","        return MultipleChoiceModelOutput(\n","            loss=loss,\n","            logits=reshaped_logits,\n","            hidden_states=outputs.hidden_states,\n","            attentions=outputs.attentions,\n","        )\n","\n"],"metadata":{"id":"2JRWfDkPeCtH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch import nn\n","from transformers import Trainer\n","\n","\n","class MultilabelTrainer(Trainer):\n","    padding=True\n","    truncation=True\n","    def compute_loss(self, model, inputs, return_outputs=False):\n","        labels = inputs.pop(\"labels\")\n","        outputs = model(**inputs)\n","        logits = outputs.logits\n","        loss_fct = nn.BCEWithLogitsLoss()\n","        loss = loss_fct(logits.view(-1, self.model.config.num_labels),\n","                        labels.float().view(-1, self.model.config.num_labels))\n","        return (loss, outputs) if return_outputs else loss\n","\n","\n","\n"],"metadata":{"id":"kKDleNojvHB9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6xloKsSiewHp","executionInfo":{"status":"ok","timestamp":1692587035260,"user_tz":-60,"elapsed":5034,"user":{"displayName":"Sumit Gupta","userId":"07308348120090087318"}},"outputId":"80738795-e413-474e-e07c-5e46208f1514"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n"]}]},{"cell_type":"code","source":["#!/usr/bin/env python\n","# coding=utf-8\n","\"\"\" Finetuning models on the ECtHR dataset (e.g. Bert, RoBERTa, LEGAL-BERT).\"\"\"\n","\n","import logging\n","import os\n","import random\n","import sys\n","from dataclasses import dataclass, field\n","from typing import Optional\n","\n","import datasets\n","import numpy as np\n","from datasets import load_dataset\n","from sklearn.metrics import f1_score\n","#from trainer import MultilabelTrainer\n","from scipy.special import expit\n","from torch import nn\n","import glob\n","import shutil\n","import torch\n","torch.cuda.empty_cache()\n","import transformers\n","from transformers import (\n","    AutoConfig,\n","    AutoModelForSequenceClassification,\n","    AutoTokenizer,\n","    DataCollatorWithPadding,\n","    EvalPrediction,\n","    HfArgumentParser,\n","    TrainingArguments,\n","    default_data_collator,\n","    set_seed,\n","    EarlyStoppingCallback,\n",")\n","from transformers.trainer_utils import get_last_checkpoint\n","from transformers.utils import check_min_version\n","from transformers.utils.versions import require_version\n","#from models.hierbert import HierarchicalBert\n","#from models.deberta import DebertaForSequenceClassification\n","\n","\n","# Will error if the minimal version of Transformers is not installed. Remove at your own risks.\n","check_min_version(\"4.9.0\")\n","\n","require_version(\"datasets>=1.8.0\", \"To fix: pip install -r examples/pytorch/text-classification/requirements.txt\")\n","\n","logger = logging.getLogger(__name__)\n","\n","from transformers import AutoModel, AutoTokenizer\n","\n","# First, load the tokenizer and pre-trained BERT model\n","tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","bert_model = AutoModel.from_pretrained('bert-base-uncased')\n","\n","# Then, create an instance of HierarchicalBert\n","max_segments = 64\n","max_segment_length = 128\n","HierarchicalBertObj = HierarchicalBert(encoder=bert_model, max_segments=max_segments, max_segment_length=max_segment_length)\n","#os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb=256,512,1024\"\n","\n","@dataclass\n","class DataTrainingArguments:\n","    \"\"\"\n","    Arguments pertaining to what data we are going to input our model for training and eval.\n","\n","    Using `HfArgumentParser` we can turn this class\n","    into argparse arguments to be able to specify them on\n","    the command line.\n","    \"\"\"\n","\n","    max_seq_length: Optional[int] = field(\n","        default=4096,\n","        metadata={\n","            \"help\": \"The maximum total input sequence length after tokenization. Sequences longer \"\n","            \"than this will be truncated, sequences shorter will be padded.\"\n","        },\n","    )\n","    max_segments: Optional[int] = field(\n","        default=64,\n","        metadata={\n","            \"help\": \"The maximum number of segments (paragraphs) to be considered. Sequences longer \"\n","                    \"than this will be truncated, sequences shorter will be padded.\"\n","        },\n","    )\n","    max_seg_length: Optional[int] = field(\n","        default=128,\n","        metadata={\n","            \"help\": \"The maximum segment (paragraph) length to be considered. Segments longer \"\n","                    \"than this will be truncated, sequences shorter will be padded.\"\n","        },\n","    )\n","    overwrite_cache: bool = field(\n","        default=False, metadata={\"help\": \"Overwrite the cached preprocessed datasets or not.\"}\n","    )\n","    pad_to_max_length: bool = field(\n","        default=True,\n","        metadata={\n","            \"help\": \"Whether to pad all samples to `max_seq_length`. \"\n","            \"If False, will pad the samples dynamically when batching to the maximum length in the batch.\"\n","        },\n","    )\n","    max_train_samples: Optional[int] = field(\n","        default=None,\n","        metadata={\n","            \"help\": \"For debugging purposes or quicker training, truncate the number of training examples to this \"\n","            \"value if set.\"\n","        },\n","    )\n","    max_eval_samples: Optional[int] = field(\n","        default=None,\n","        metadata={\n","            \"help\": \"For debugging purposes or quicker training, truncate the number of evaluation examples to this \"\n","            \"value if set.\"\n","        },\n","    )\n","    max_predict_samples: Optional[int] = field(\n","        default=None,\n","        metadata={\n","            \"help\": \"For debugging purposes or quicker training, truncate the number of prediction examples to this \"\n","            \"value if set.\"\n","        },\n","    )\n","    task: Optional[str] = field(\n","        default='ecthr_a',\n","        metadata={\n","            \"help\": \"Define downstream task\"\n","        },\n","    )\n","    server_ip: Optional[str] = field(default=None, metadata={\"help\": \"For distant debugging.\"})\n","    server_port: Optional[str] = field(default=None, metadata={\"help\": \"For distant debugging.\"})\n","\n","\n","@dataclass\n","class ModelArguments:\n","    \"\"\"\n","    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n","    \"\"\"\n","\n","    model_name_or_path: str = field(\n","        default=None, metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n","    )\n","    hierarchical: bool = field(\n","        default=True, metadata={\"help\": \"Whether to use a hierarchical variant or not\"}\n","    )\n","    config_name: Optional[str] = field(\n","        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n","    )\n","    tokenizer_name: Optional[str] = field(\n","        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n","    )\n","    cache_dir: Optional[str] = field(\n","        default=None,\n","        metadata={\"help\": \"Where do you want to store the pretrained models downloaded from huggingface.co\"},\n","    )\n","    do_lower_case: Optional[bool] = field(\n","        default=True,\n","        metadata={\"help\": \"arg to indicate if tokenizer should do lower case in AutoTokenizer.from_pretrained()\"},\n","    )\n","    use_fast_tokenizer: bool = field(\n","        default=True,\n","        metadata={\"help\": \"Whether to use one of the fast tokenizer (backed by the tokenizers library) or not.\"},\n","    )\n","    model_revision: str = field(\n","        default=\"main\",\n","        metadata={\"help\": \"The specific model version to use (can be a branch name, tag name or commit id).\"},\n","    )\n","    use_auth_token: bool = field(\n","        default=False,\n","        metadata={\n","            \"help\": \"Will use the token generated when running `transformers-cli login` (necessary to use this script \"\n","            \"with private models).\"\n","        },\n","    )\n","\n","\n","def main(training_args):\n","    # See all possible arguments in src/transformers/training_args.py\n","    # or by passing the --help flag to this script.\n","    # We now keep distinct sets of args, for a cleaner separation of concerns.\n","\n","    model_args = ModelArguments(\n","        model_name_or_path=\"bert-base-uncased\",\n","        hierarchical=True,\n","        do_lower_case=True,\n","        use_fast_tokenizer=True,\n","    )\n","    data_args = DataTrainingArguments(\n","        max_seq_length=128,\n","        max_segments=64,\n","        max_seg_length=128,\n","        overwrite_cache=False,\n","        pad_to_max_length=True,\n","    )\n","\n","\n","    # Fix boolean parameter\n","    if model_args.do_lower_case == 'False' or not model_args.do_lower_case:\n","        model_args.do_lower_case = False\n","    else:\n","        model_args.do_lower_case = True\n","\n","    if model_args.hierarchical == 'False' or not model_args.hierarchical:\n","        model_args.hierarchical = False\n","    else:\n","        model_args.hierarchical = True\n","\n","    # Setup distant debugging if needed\n","    if data_args.server_ip and data_args.server_port:\n","        # Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script\n","        import ptvsd\n","\n","        print(\"Waiting for debugger attach\")\n","        ptvsd.enable_attach(address=(data_args.server_ip, data_args.server_port), redirect_output=True)\n","        ptvsd.wait_for_attach()\n","\n","    # Setup logging\n","    logging.basicConfig(\n","        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n","        datefmt=\"%m/%d/%Y %H:%M:%S\",\n","        handlers=[logging.StreamHandler(sys.stdout)],\n","    )\n","\n","    log_level = training_args.get_process_log_level()\n","    logger.setLevel(log_level)\n","    datasets.utils.logging.set_verbosity(log_level)\n","    transformers.utils.logging.set_verbosity(log_level)\n","    transformers.utils.logging.enable_default_handler()\n","    transformers.utils.logging.enable_explicit_format()\n","\n","    # Log on each process the small summary:\n","    logger.warning(\n","        f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n","        + f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"\n","    )\n","    logger.info(f\"Training/evaluation parameters {training_args}\")\n","\n","    # Detecting last checkpoint.\n","    last_checkpoint = None\n","    if os.path.isdir(training_args.output_dir) and training_args.do_train and not training_args.overwrite_output_dir:\n","        last_checkpoint = get_last_checkpoint(training_args.output_dir)\n","        if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:\n","            raise ValueError(\n","                f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n","                \"Use --overwrite_output_dir to overcome.\"\n","            )\n","        elif last_checkpoint is not None:\n","            logger.info(\n","                f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"\n","                \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n","            )\n","\n","    # Set seed before initializing model.\n","    set_seed(training_args.seed)\n","\n","    # In distributed training, the load_dataset function guarantees that only one local process can concurrently\n","    # download the dataset.\n","    # Downloading and loading eurlex dataset from the hub.\n","    if training_args.do_train:\n","        train_dataset = load_dataset(\"lex_glue\", name=data_args.task, split=\"train\", data_dir='data', cache_dir=model_args.cache_dir)\n","\n","    if training_args.do_eval:\n","        eval_dataset = load_dataset(\"lex_glue\", name=data_args.task, split=\"validation\", data_dir='data', cache_dir=model_args.cache_dir)\n","\n","    if training_args.do_predict:\n","        predict_dataset = load_dataset(\"lex_glue\", name=data_args.task, split=\"test\", data_dir='data', cache_dir=model_args.cache_dir)\n","\n","    # Labels\n","    label_list = list(range(10))\n","    num_labels = len(label_list)\n","\n","    # Load pretrained model and tokenizer\n","    # In distributed training, the .from_pretrained methods guarantee that only one local process can concurrently\n","    # download model & vocab.\n","    config = AutoConfig.from_pretrained(\n","        model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n","        num_labels=num_labels,\n","        finetuning_task=f\"{data_args.task}\",\n","        cache_dir=model_args.cache_dir,\n","        revision=model_args.model_revision,\n","        use_auth_token=True if model_args.use_auth_token else None,\n","    )\n","    tokenizer = AutoTokenizer.from_pretrained(\n","        model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,\n","        do_lower_case=model_args.do_lower_case,\n","        cache_dir=model_args.cache_dir,\n","        use_fast=model_args.use_fast_tokenizer,\n","        revision=model_args.model_revision,\n","        use_auth_token=True if model_args.use_auth_token else None,\n","    )\n","    if config.model_type == 'deberta' and model_args.hierarchical:\n","        model = DebertaForSequenceClassification.from_pretrained(\n","            model_args.model_name_or_path,\n","            from_tf=bool(\".ckpt\" in model_args.model_name_or_path),\n","            config=config,\n","            cache_dir=model_args.cache_dir,\n","            revision=model_args.model_revision,\n","            use_auth_token=True if model_args.use_auth_token else None,\n","        )\n","    else:\n","        model = AutoModelForSequenceClassification.from_pretrained(\n","            model_args.model_name_or_path,\n","            from_tf=bool(\".ckpt\" in model_args.model_name_or_path),\n","            config=config,\n","            cache_dir=model_args.cache_dir,\n","            revision=model_args.model_revision,\n","            use_auth_token=True if model_args.use_auth_token else None,\n","        )\n","\n","    if model_args.hierarchical:\n","        # Hack the classifier encoder to use hierarchical BERT\n","        if config.model_type in ['bert', 'deberta']:\n","            if config.model_type == 'bert':\n","                segment_encoder = model.bert\n","            else:\n","                segment_encoder = model.deberta\n","            model_encoder = HierarchicalBert(encoder=segment_encoder,\n","                                             max_segments=data_args.max_segments,\n","                                             max_segment_length=data_args.max_seg_length)\n","            if config.model_type == 'bert':\n","                model.bert = model_encoder\n","            elif config.model_type == 'deberta':\n","                model.deberta = model_encoder\n","            else:\n","                raise NotImplementedError(f\"{config.model_type} is no supported yet!\")\n","        elif config.model_type == 'roberta':\n","            model_encoder = HierarchicalBert(encoder=model.roberta, max_segments=data_args.max_segments,\n","                                             max_segment_length=data_args.max_seg_length)\n","            model.roberta = model_encoder\n","            # Build a new classification layer, as well\n","            dense = nn.Linear(config.hidden_size, config.hidden_size)\n","            dense.load_state_dict(model.classifier.dense.state_dict())  # load weights\n","            dropout = nn.Dropout(config.hidden_dropout_prob).to(model.device)\n","            out_proj = nn.Linear(config.hidden_size, config.num_labels).to(model.device)\n","            out_proj.load_state_dict(model.classifier.out_proj.state_dict())  # load weights\n","            model.classifier = nn.Sequential(dense, dropout, out_proj).to(model.device)\n","        elif config.model_type in ['longformer', 'big_bird']:\n","            pass\n","        else:\n","            raise NotImplementedError(f\"{config.model_type} is no supported yet!\")\n","\n","    # Preprocessing the datasets\n","    # Padding strategy\n","    if data_args.pad_to_max_length:\n","        padding = \"max_length\"\n","    else:\n","        # We will pad later, dynamically at batch creation, to the max sequence length in each batch\n","        padding = False\n","\n","    def preprocess_function(examples):\n","        # Tokenize the texts\n","        if model_args.hierarchical:\n","            case_template = [[0] * data_args.max_seg_length]\n","            if config.model_type == 'roberta':\n","                batch = {'input_ids': [], 'attention_mask': []}\n","                for case in examples['text']:\n","                    case_encodings = tokenizer(case[:data_args.max_segments], padding=padding,\n","                                               max_length=data_args.max_seg_length, truncation=True)\n","                    batch['input_ids'].append(case_encodings['input_ids'] + case_template * (\n","                                data_args.max_segments - len(case_encodings['input_ids'])))\n","                    batch['attention_mask'].append(case_encodings['attention_mask'] + case_template * (\n","                                data_args.max_segments - len(case_encodings['attention_mask'])))\n","            else:\n","                batch = {'input_ids': [], 'attention_mask': [], 'token_type_ids': []}\n","                for case in examples['text']:\n","                    case_encodings = tokenizer(case[:data_args.max_segments], padding=padding,\n","                                               max_length=data_args.max_seg_length, truncation=True)\n","                    batch['input_ids'].append(case_encodings['input_ids'] + case_template * (\n","                            data_args.max_segments - len(case_encodings['input_ids'])))\n","                    batch['attention_mask'].append(case_encodings['attention_mask'] + case_template * (\n","                            data_args.max_segments - len(case_encodings['attention_mask'])))\n","                    batch['token_type_ids'].append(case_encodings['token_type_ids'] + case_template * (\n","                            data_args.max_segments - len(case_encodings['token_type_ids'])))\n","        elif config.model_type in ['longformer', 'big_bird']:\n","            cases = []\n","            max_position_embeddings = config.max_position_embeddings - 2 if config.model_type == 'longformer' \\\n","                else config.max_position_embeddings\n","            for case in examples['text']:\n","                cases.append(f' {tokenizer.sep_token} '.join(\n","                    [' '.join(fact.split()[:data_args.max_seg_length]) for fact in case[:data_args.max_segments]]))\n","            batch = tokenizer(cases, padding=padding, max_length=max_position_embeddings, truncation=True)\n","            if config.model_type == 'longformer':\n","                global_attention_mask = np.zeros((len(cases), max_position_embeddings), dtype=np.int32)\n","                # global attention on cls token\n","                global_attention_mask[:, 0] = 1\n","                batch['global_attention_mask'] = list(global_attention_mask)\n","        else:\n","            cases = []\n","            for case in examples['text']:\n","                cases.append(f'\\n'.join(case))\n","            batch = tokenizer(cases, padding=padding, max_length=512, truncation=True)\n","        batch[\"original_labels\"] = [[label for label in label_list if label in labels] for labels in examples[\"labels\"]]\n","        batch[\"labels\"] = [[1 if label in labels else 0 for label in label_list] for labels in examples[\"labels\"]]\n","\n","        return batch\n","\n","    if training_args.do_train:\n","        if data_args.max_train_samples is not None:\n","            train_dataset = train_dataset.select(range(data_args.max_train_samples))\n","        with training_args.main_process_first(desc=\"train dataset map pre-processing\"):\n","            train_dataset = train_dataset.map(\n","                preprocess_function,\n","                batched=True,\n","                load_from_cache_file=not data_args.overwrite_cache,\n","                desc=\"Running tokenizer on train dataset\",\n","            )\n","        # Log a few random samples from the training set:\n","        for index in random.sample(range(len(train_dataset)), 3):\n","            logger.info(f\"Sample {index} of the training set: {train_dataset[index]}.\")\n","\n","    if training_args.do_eval:\n","        if data_args.max_eval_samples is not None:\n","            eval_dataset = eval_dataset.select(range(data_args.max_eval_samples))\n","        with training_args.main_process_first(desc=\"validation dataset map pre-processing\"):\n","            eval_dataset = eval_dataset.map(\n","                preprocess_function,\n","                batched=True,\n","                load_from_cache_file=not data_args.overwrite_cache,\n","                desc=\"Running tokenizer on validation dataset\",\n","            )\n","\n","    if training_args.do_predict:\n","        if data_args.max_predict_samples is not None:\n","            predict_dataset = predict_dataset.select(range(data_args.max_predict_samples))\n","        with training_args.main_process_first(desc=\"prediction dataset map pre-processing\"):\n","            predict_dataset = predict_dataset.map(\n","                preprocess_function,\n","                batched=True,\n","                load_from_cache_file=not data_args.overwrite_cache,\n","                desc=\"Running tokenizer on prediction dataset\",\n","            )\n","\n","    # You can define your custom compute_metrics function. It takes an `EvalPrediction` object (a namedtuple with a\n","    # predictions and label_ids field) and has to return a dictionary string to float.\n","    def compute_metrics(p: EvalPrediction):\n","        # Fix gold labels\n","        y_true = np.zeros((p.label_ids.shape[0], p.label_ids.shape[1] + 1), dtype=np.int32)\n","        y_true[:, :-1] = p.label_ids\n","        y_true[:, -1] = (np.sum(p.label_ids, axis=1) == 0).astype('int32')\n","        # Fix predictions\n","        logits = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n","        preds = (expit(logits) > 0.5).astype('int32')\n","        y_pred = np.zeros((p.label_ids.shape[0], p.label_ids.shape[1] + 1), dtype=np.int32)\n","        y_pred[:, :-1] = preds\n","        y_pred[:, -1] = (np.sum(preds, axis=1) == 0).astype('int32')\n","        # Compute scores\n","        macro_f1 = f1_score(y_true=y_true, y_pred=y_pred, average='macro', zero_division=0)\n","        micro_f1 = f1_score(y_true=y_true, y_pred=y_pred, average='micro', zero_division=0)\n","        return {'macro-f1': macro_f1, 'micro-f1': micro_f1}\n","\n","    # Data collator will default to DataCollatorWithPadding, so we change it if we already did the padding.\n","    if data_args.pad_to_max_length:\n","        data_collator = default_data_collator\n","    elif training_args.fp16:\n","        data_collator = DataCollatorWithPadding(tokenizer, pad_to_multiple_of=8)\n","    else:\n","        data_collator = None\n","\n","    # Initialize our Trainer\n","    trainer = MultilabelTrainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=train_dataset if training_args.do_train else None,\n","        eval_dataset=eval_dataset if training_args.do_eval else None,\n","        compute_metrics=compute_metrics,\n","        tokenizer=tokenizer,\n","        data_collator=data_collator,\n","        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n","    )\n","\n","    # Training\n","    if training_args.do_train:\n","        checkpoint = None\n","        if training_args.resume_from_checkpoint is not None:\n","            checkpoint = training_args.resume_from_checkpoint\n","        elif last_checkpoint is not None:\n","            checkpoint = last_checkpoint\n","        train_result = trainer.train(resume_from_checkpoint=checkpoint)\n","        metrics = train_result.metrics\n","        max_train_samples = (\n","            data_args.max_train_samples if data_args.max_train_samples is not None else len(train_dataset)\n","        )\n","        metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n","\n","        trainer.save_model()  # Saves the tokenizer too for easy upload\n","\n","        trainer.log_metrics(\"train\", metrics)\n","        trainer.save_metrics(\"train\", metrics)\n","        trainer.save_state()\n","\n","    # Evaluation\n","    if training_args.do_eval:\n","        logger.info(\"*** Predict ***\")\n","        predictions, labels, metrics = trainer.predict(predict_dataset, metric_key_prefix=\"predict\")\n","\n","        # Get the actual predicted indexes (class labels)\n","        actual_predictions = predictions[0][:, 1]  # Assuming positive class is at index 1\n","\n","        # Apply the threshold for binary predictions\n","        threshold = 0.5\n","        binary_predictions = (actual_predictions > threshold).astype(int)\n","\n","\n","        # Get the input text from the dataset\n","        input_texts = predict_dataset['text']\n","\n","        # Create a DataFrame to hold the predictions, labels, and input text\n","        with open(\"predictions.txt\", \"w\") as f:\n","            for index, input_text, prediction, label in zip(range(len(input_texts)), input_texts, actual_predictions, labels):\n","                f.write(f\"Index: {index}\\n\")\n","                f.write(f\"Input Text: {input_text}\\n\")\n","                f.write(f\"Predictions: {prediction}\\n\")\n","                f.write(f\"Labels: {label}\\n\")\n","                f.write(\"\\n\")\n","\n","    # ... Your existing code ...\n","\n","    # Access the rows from the dataset associated with correct predictions\n","    # ... Your existing code ...\n","\n","# Access the rows from the dataset associated with correct predictions\n","    correct_predictions_dataset = predict_dataset.filter(\n","    lambda example, idx: all(actual_predictions[idx] == example[\"labels\"]),\n","    with_indices=True\n",")\n","\n","# Access the rows from the dataset associated with incorrect predictions\n","    incorrect_predictions_dataset = predict_dataset.filter(\n","    lambda example, idx: any(actual_predictions[idx] != example[\"labels\"]),\n","    with_indices=True\n",")\n","\n","# Access the rows from the dataset associated with original labels\n","    original_labels = predict_dataset['labels']\n","\n","# Get the input texts and input IDs from the datasets\n","    correct_input_texts = correct_predictions_dataset[\"text\"]\n","    correct_input_ids = correct_predictions_dataset[\"input_ids\"]\n","    incorrect_input_texts = incorrect_predictions_dataset[\"text\"]\n","    incorrect_input_ids = incorrect_predictions_dataset[\"input_ids\"]\n","\n","# Save the correct predictions to a file\n","    with open(\"correct_predictions.txt\", \"w\") as f:\n","       for idx, input_text, input_id, labels in zip(range(len(correct_input_texts)), correct_input_texts, correct_input_ids, correct_predictions_dataset[\"labels\"]):\n","         f.write(f\"Index: {idx}\\n\")\n","         f.write(f\"Input Text: {input_text}\\n\")\n","         f.write(f\"Input IDs: {input_id}\\n\")\n","         f.write(f\"Labels: {labels}\\n\")\n","         f.write(\"\\n\")\n","\n","# Save the incorrect predictions to a file\n","    # Save the incorrect predictions to a file\n","    with open(\"incorrect_predictions.txt\", \"w\") as f:\n","        for idx, input_text, input_id, labels, original_labels  in zip(\n","            range(len(incorrect_input_texts)),\n","            incorrect_input_texts,\n","            incorrect_input_ids,\n","            incorrect_predictions_dataset[\"labels\"],\n","            incorrect_predictions_dataset[\"original_labels\"],\n","\n","        ):\n","            f.write(f\"Index: {idx}\\n\")\n","            f.write(f\"Input Text: {input_text}\\n\")\n","            f.write(f\"Input IDs: {input_id}\\n\")\n","            f.write(f\"Labels: {labels}\\n\")  # Write the labels to the file\n","            f.write(f\"Original_Labels: {original_labels}\\n\")\n","            f.write(\"\\n\")\n","\n","\n","    # Prediction\n","    if training_args.do_predict:\n","        logger.info(\"*** Predict ***\")\n","        predictions, labels, metrics = trainer.predict(predict_dataset, metric_key_prefix=\"predict\")\n","\n","        max_predict_samples = (\n","            data_args.max_predict_samples if data_args.max_predict_samples is not None else len(predict_dataset)\n","        )\n","        metrics[\"predict_samples\"] = min(max_predict_samples, len(predict_dataset))\n","\n","        trainer.log_metrics(\"predict\", metrics)\n","        trainer.save_metrics(\"predict\", metrics)\n","\n","        output_predict_file = os.path.join(training_args.output_dir, \"test_predictions.csv\")\n","        if trainer.is_world_process_zero():\n","            with open(output_predict_file, \"w\") as writer:\n","                for index, pred_list in enumerate(predictions[0]):\n","                    pred_line = '\\t'.join([f'{pred:.5f}' for pred in pred_list])\n","                    writer.write(f\"{index}\\t{pred_line}\\n\")\n","\n","    # Prediction\n","    if training_args.do_predict:\n","        logger.info(\"*** Predict ***\")\n","        predictions, labels, metrics = trainer.predict(predict_dataset, metric_key_prefix=\"predict\")\n","\n","        max_predict_samples = (\n","            data_args.max_predict_samples if data_args.max_predict_samples is not None else len(predict_dataset)\n","        )\n","        metrics[\"predict_samples\"] = min(max_predict_samples, len(predict_dataset))\n","\n","        trainer.log_metrics(\"predict\", metrics)\n","        trainer.save_metrics(\"predict\", metrics)\n","\n","        output_predict_file = os.path.join(training_args.output_dir, \"test_predictions.csv\")\n","        if trainer.is_world_process_zero():\n","            with open(output_predict_file, \"w\") as writer:\n","                for index, pred_list in enumerate(predictions[0]):\n","                    pred_line = '\\t'.join([f'{pred:.5f}' for pred in pred_list])\n","                    writer.write(f\"{index}\\t{pred_line}\\n\")\n","\n","    # Clean up checkpoints\n","    checkpoints = [filepath for filepath in glob.glob(f'{training_args.output_dir}/*/') if '/checkpoint' in filepath]\n","    for checkpoint in checkpoints:\n","        shutil.rmtree(checkpoint)\n","\n","\n","if __name__ == \"__main__\":\n","    #For training\n","\n","    training_args = TrainingArguments(\n","        do_train = True,\n","        output_dir=os.getcwd(),\n","        overwrite_output_dir=True,\n","        num_train_epochs=1,\n","        per_device_train_batch_size=8,\n","        save_steps=500,\n","        save_total_limit=2,\n","        fp16=False,\n","        logging_dir=\"./logs\",\n","        logging_steps=100,\n","        evaluation_strategy=\"steps\",\n","        eval_steps=500,\n","        logging_first_step=False,\n","        load_best_model_at_end = True,\n","        metric_for_best_model=\"macro-f1\",\n","    )\n","    #main(training_args)\n","\n","# For Validation\n","    training_args = TrainingArguments(\n","        do_train = False,\n","        do_eval = True,\n","        output_dir=os.getcwd(),\n","        overwrite_output_dir=True,\n","        num_train_epochs=1,\n","        per_device_train_batch_size=8,\n","        save_steps=500,\n","        save_total_limit=2,\n","        fp16=False,\n","        logging_dir=\"./logs\",\n","        logging_steps=100,\n","        evaluation_strategy=\"steps\",\n","        eval_steps=500,\n","        logging_first_step=False,\n","        load_best_model_at_end = True,\n","        metric_for_best_model=\"macro-f1\",\n","    )\n","    #main(training_args)\n","\n","    # For Evaluation\n","    training_args = TrainingArguments(\n","        do_train = True,\n","        do_eval = True,\n","        do_predict = True,\n","        output_dir=os.getcwd(),\n","        overwrite_output_dir=True,\n","        num_train_epochs=2,\n","        per_device_train_batch_size=4,\n","        per_device_eval_batch_size=4,\n","        save_steps=500,\n","        save_total_limit=2,\n","        fp16=False,\n","        logging_dir=\"./logs\",\n","        logging_steps=100,\n","        evaluation_strategy=\"steps\",\n","        eval_steps=500,\n","        logging_first_step=False,\n","        load_best_model_at_end = True,\n","        metric_for_best_model=\"micro-f1\",\n","    )\n","    main(training_args)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["6b4acf12f3f949d49edf5a30f81f9faa","33d039029cc6442397351ad47d639f5b","da68f34c3c364bfbbb8d77551b2782d1","c07f1bb9535d41b191e1e7de34449f83","8c60dde2364c4d4c9701b8519da757f8","e7fe872209484907a7cdde4bb99dfc06","1e659bd88b0349f4bf20943604ae57e6","031fbd39dd8940d1b4d3095ee1a76947","1b10dadefd96440f9b4896753dc268cc","c7f4e5cda3b14ecfb3f2580a15a30dd1","8ba2987477c3430d997d5d223e08ba49","d21c33da17784f868469dc4c1d26d786","8258689509564276be46f14c28a2046f","d289fee5780b44fc96256e30792fdf53","7626427795544c51a557c418edf88642","2a97195deff94945956e892256c03943","af301bd5a73b4ec281d71bb95b8c6f70","15a7139db05d436cadc66b0430b3d586","dcba1eb30435432c8dbc950210d3e0ed","2984f00f639447e0972d59d8744a0d89","02e41b6218ee45a1b28e2daf122729d5","c626a973ad6146d6990ea34f2b125e13","5d2d5a2060454e2984e7695bc4ce13e6","7e777bd423e14a9ea27e09a36e2939bf","1d79629e65044930af373af82aecc873","006f640a19794042a9828344eae4ba66","e4440e587aa44c70a8638d3d0d675f82","4623d92ce52242f08a9d89d744559a11","cd7c74a461fa4ba389a7f5a5d071893e","43165da527204f75b6ee8effc7023fd2","cd2c3bac40a94799acfb8d7165aed6d5","a06a14de6c3e40b083762e9e8bffb6c6","0a3b25b7230a46d5a97d7acb5350cac8","a7aa9c3bcfd24b6791b6f900370f005b","2b52aab60c78461ba767c24555a3656b","a00b9fc84bfd4f95a2e12c415d4a849c","be06199c2b1d4ae2a07894bc2987d6fe","c595cdbe30834a0091317366bd21f08b","c1255e55f5f0491f901b8e5302fd8790","a6fc09d762b24169bdc70e32d7978260","2604d340be284cd8abd95904cb9a4398","de57eb04125a417e978b9608efe74909","ba94466392da4095acb863389f3d60d3","a475aaa9c50543d18b1f3ff8c7975ab8","abbf9abb049044749bd89a04045a4869","9afe29df5d4141908d09cc5439cf1f0d","cad439087738493f95be41ca8df53c50","20d5b1610ac34a7ba5b5375a09702ef6","6ed417e5a79649158339e4569a197a9e","4a8071e91ad34684aac95ae6afcb99a4","ba2e6916c1a04605b09fc7c4eb2bd543","119e268986034d7283b3e3405fd2065a","59490df592364b18ad7642f3573be79b","890424d5b06d4edea0e9f3dc8fe6e613","5d67da807ed14a43b572cb452f7d847f"]},"id":"jQytKfdOF4j3","executionInfo":{"status":"ok","timestamp":1692598583988,"user_tz":-60,"elapsed":6617460,"user":{"displayName":"Sumit Gupta","userId":"07308348120090087318"}},"outputId":"db14797e-5ea1-410f-8015-c77656d4b213"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:__main__:Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False\n","[WARNING|modeling_utils.py:3331] 2023-08-21 04:26:17,767 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["Running tokenizer on train dataset:   0%|          | 0/9000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b4acf12f3f949d49edf5a30f81f9faa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Running tokenizer on validation dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d21c33da17784f868469dc4c1d26d786"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Running tokenizer on prediction dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d2d5a2060454e2984e7695bc4ce13e6"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='4500' max='4500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4500/4500 1:43:27, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro-f1</th>\n","      <th>Micro-f1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.165700</td>\n","      <td>0.228937</td>\n","      <td>0.341642</td>\n","      <td>0.530530</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.139800</td>\n","      <td>0.215355</td>\n","      <td>0.429466</td>\n","      <td>0.568588</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.136400</td>\n","      <td>0.187615</td>\n","      <td>0.494645</td>\n","      <td>0.637363</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.142600</td>\n","      <td>0.173353</td>\n","      <td>0.447102</td>\n","      <td>0.634127</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.114900</td>\n","      <td>0.154034</td>\n","      <td>0.581512</td>\n","      <td>0.681041</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.102400</td>\n","      <td>0.153453</td>\n","      <td>0.570143</td>\n","      <td>0.677197</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.110700</td>\n","      <td>0.159753</td>\n","      <td>0.560743</td>\n","      <td>0.693396</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.106300</td>\n","      <td>0.144982</td>\n","      <td>0.632543</td>\n","      <td>0.705644</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.101500</td>\n","      <td>0.144922</td>\n","      <td>0.624403</td>\n","      <td>0.703897</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["***** train metrics *****\n","  epoch                    =        2.0\n","  total_flos               = 82258672GF\n","  train_loss               =      0.137\n","  train_runtime            = 1:43:28.89\n","  train_samples            =       9000\n","  train_samples_per_second =      2.899\n","  train_steps_per_second   =      0.725\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Filter:   0%|          | 0/1000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7aa9c3bcfd24b6791b6f900370f005b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Filter:   0%|          | 0/1000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abbf9abb049044749bd89a04045a4869"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["***** predict metrics *****\n","  predict_loss               =     0.1539\n","  predict_macro-f1           =     0.5896\n","  predict_micro-f1           =     0.7025\n","  predict_runtime            = 0:01:42.93\n","  predict_samples            =       1000\n","  predict_samples_per_second =      9.715\n","  predict_steps_per_second   =      2.429\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["***** predict metrics *****\n","  predict_loss               =     0.1539\n","  predict_macro-f1           =     0.5896\n","  predict_micro-f1           =     0.7025\n","  predict_runtime            = 0:01:42.49\n","  predict_samples            =       1000\n","  predict_samples_per_second =      9.756\n","  predict_steps_per_second   =      2.439\n"]}]},{"cell_type":"code","source":["import re\n","\n","# Read the \"incorrect-predictions.txt\" file\n","with open(\"/content/incorrect_predictions.txt\", \"r\") as f:\n","    lines = f.readlines()\n","\n","# Initialize variables\n","current_entry = {}\n","data_entries = []\n","text_entries = []\n","# Process the lines and create data entries\n","for line in lines:\n","    line = line.strip()\n","    if line.startswith(\"Index: \"):\n","        current_entry[\"Index\"] = int(line.split(\": \")[1])\n","    elif line.startswith(\"Input Text: \"):\n","        textstr = line.split(\": \")[1]\n","        text_entries.append(textstr)\n","    elif line.startswith(\"Input IDs: \"):\n","        input_ids_str = line.split(\": \")[1]\n","        input_ids = [int(id_str) for id_str in re.findall(r'\\d+', input_ids_str)]\n","        current_entry[\"input_ids\"] = input_ids\n","    elif line.startswith(\"Labels: \"):  # Process labels\n","        labels_str = line.split(\": \")[1]\n","        labels = [int(label_str) for label_str in re.findall(r'\\d+', labels_str)]\n","        current_entry[\"labels\"] = labels\n","    elif line.startswith(\"Original_Labels: \"):  # Process original labels\n","        labels_str = line.split(\": \")[1]\n","        original_labels = [int(label_str) for label_str in re.findall(r'\\d+', labels_str)]\n","        current_entry[\"original_labels\"] = original_labels\n","        data_entries.append(current_entry)\n","        current_entry = {}\n","\n","# Extract the list of labels from data entries\n","#text_lists = [entry.get(\"Input Text\", []) for entry in text_entries]\n","label_lists = [entry.get(\"original_labels\", []) for entry in data_entries]\n","\n","print(label_lists)\n","print(len(label_lists))\n","print(len(text_entries))\n","filtered_list = [item for item in set(tuple(lst) for lst in label_lists) if item]\n","#print(len(filtered_list))\n","# Print the list of labels for each entry\n","#for index, labels in enumerate(label_lists):\n","#    print(f\"Entry {index}: Labels = {labels}\")\n"],"metadata":{"id":"t_b8HwvnyujI","executionInfo":{"status":"ok","timestamp":1692598624803,"user_tz":-60,"elapsed":3340,"user":{"displayName":"Sumit Gupta","userId":"07308348120090087318"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5b7d9874-e336-4f98-9336-037f0e6b110e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[6], [4], [3], [3], [], [1], [3], [1], [3, 4], [3], [2], [3], [3], [0], [0], [1], [6], [3], [9], [3, 9], [5], [2], [1], [3], [3, 9], [1], [], [1], [0], [1, 2], [3, 9], [3], [3], [1], [3], [2], [3, 9], [3, 9], [1, 2], [3, 9], [], [4], [2], [2], [], [2, 3], [2], [], [], [1], [2], [7], [9], [], [7], [0], [7], [], [1, 4], [], [1], [3], [9], [4], [3], [9], [], [9], [1, 8], [], [3, 9], [3], [4], [0], [4], [3], [3], [1], [4], [3], [4], [2, 4], [3], [1, 2, 4], [3], [1, 2], [1], [3], [0], [3, 9], [3], [3], [3, 9], [7], [0], [], [3], [7], [0], [1], [6], [4], [4], [3], [0], [2], [3], [2], [1], [], [], [], [3, 4], [0], [3], [3], [4], [2], [], [3], [1, 2], [1], [1], [0, 1], [2], [6], [1, 2, 4], [3], [1, 2], [3], [1, 2, 3], [2], [], [4, 8], [3], [8, 9], [5], [9], [], [1], [3], [3], [], [4], [9], [1, 2], [], [1, 2], [3], [2], [3], [1, 4], [3], [], [], [3], [3, 9], [], [4], [4], [3], [], [0], [3, 9], [], [], [], [0, 2], [1], [3], [3], [3], [1], [3, 9], [3], [1], [9], [], [], [4], [2], [], [1], [3], [6], [2], [6], [2], [2], [9], [1], [0], [], [3], [7], [2], [7], [3, 9], [7], [3, 9], [3], [3, 9], [], [3, 6], [4], [6], [6], [6], [4], [6], [7], [4], [4], [3, 9], [2, 3], [3], [], [3], [3, 9], [], [3], [6], [3], [], [], [9], [], [2], [4], [1, 2, 7], [3], [2], [3], [2], [3], [3], [6], [7], [1, 2, 7], [2, 7], [6], [8], [8, 9], [3], [3], [1, 4], [4], [3], [], [1, 2], [2], [4], [2], [1], [3], [3], [6], [2], [2], [3, 9], [1], [], [2, 3, 6], [3, 9], [2, 4], [6], [4], [9], [3], [1], [3], [2, 4, 5], [2], [0], [], [3, 6], [], [3], [9], [], [3], [3], [4, 5], [], [3], [1], [1], [3], [], [2], [3], [1], [6], [4], [3], [], [1, 2], [3, 6], [], [7], [2], [], [3], [3], [1], [3], [3], [1, 2], [3], [3], [], [3], [], [2, 6], [2], [3], [2, 6], [6], [], [], [], [1, 2, 4], [1], [1, 2, 4], [2], [6], [], [9], [3], [], [3], [4], [3], [2], [2], [1, 2], [], [1, 3], [4], [3, 9], [1, 4], [4], [7], [], [3], [1], [2, 3, 7], [4], [3, 6], [6], [2], [3], [1], [6], [], [9], [3], [4], [3], [4], [4], [7], [6], [4], [], [9], [1, 9], [1], [6], [3], [], [2], [1, 3], [4, 8], [1], [], [0], [3], [1], [9], [2], [4], [2], [1, 2, 7], [], [6], [4], [1], [], [], [4], [3], [7], [], [3], [3], [9], [4], [2], [], [3], [], [1], [1], [0], [4], [1], [], [1], [], [2, 4], [], [3], [1, 2], [0], [1, 2], [1, 2], [1, 2, 3], [1], [1], [0], [1], [3, 9], [0], [3], [4], [2], [2], [], [], [3, 9], [9], [4], [4], [4], [3], [1, 3], [9], [], [2], [3], [2], [3, 6], [6], [6], [2], [3, 4, 8], [1], [0], [3], [9], [1, 2], [2], [1], [6], [2], [], [3], [2], [3], [3, 9], [], [3], [6], [3, 9], [9], [], [4], [1], [2], [3], [9], [2, 7], [6], [2], [5], [1], [2], [7], [], [7], [3], [3], [2], [3], [3], [2], [1, 3, 4], [6], [4], [1], [], [1], [1], [1, 2, 3, 6], [1, 2], [4], [1], [3], [], [], [1], [1, 3], [9], [0], [], [9], [6], [3], [0], [], [2], [1], [4], [4], [3], [], [3], [], [3], [3], [3], [], [], [0, 1, 2], [], [6], [3], [], [6], [3], [3], [4], [2], [9], [3], [1, 2], [6], [2], [1], [3], [4], [3, 9], [9], [9], [6], [3], [9], [], [4], [], [], [4], [1, 2, 4], [0], [1, 2, 3, 7], [1, 2], [1, 3], [], [], [3], [6], [6], [3], [3], [6], [1], [4, 8], [3, 9], [6], [6], [3], [3, 9], [1], [6], [2], [3, 9], [6], [6], [6], [2, 3], [3], [6], [0, 1, 2], [4], [4], [9], [3], [1, 3, 9], [], [1], [9], [9], [3], [6], [3], [3], [6], [2, 3, 7], [1, 2, 3], [9], [9], [9], [4], [], [1], [3], [9], [1], [3, 9], [], [0], [1], [4], [9], [0, 1, 2], [6], [2], [2], [1], [2], [], [], [], [], [], [2], [3], [3], [], [2, 9], [3], [2], [9], [3], [1, 2], [4], [], [9], [0, 1, 2], [1, 2], [0, 1, 2], [3], [], [1], [], [0], [], [1], [3], [4], [3], [], [1], [], [3], [3], [4], [0], [4], [3], [1, 4, 8], [6], [3], [3], [3], [3], [3], [4], [3], [3], [9], [2], [], [9], [], [2, 3, 7], [2], [7], [1], [3], [1, 4], [1], [2], [], [6], [], [3], [4], [1, 3], [3], [3], [3], [4], [3], [7], [1, 3], [7], [1, 3], [], [0, 1, 2], [4], [3, 9], [4], [4], [], [1, 4], [6], [1], [4], [3, 7], [1], [3], [2], [3, 6], [3], [3, 9], [3], [0, 8], [2], [3], [9], [4], [4], [2], [6], [], [1], [], [9], [3], [0], [9], [1], [9], [1, 4], [], [1, 2, 3, 4], [3, 9], [1], [3], [3], [3, 9], [9], [0], [3], [9], [], [4], [], [], [], [], [8, 9], [], [1], [0], [3], [2, 7], [], [], [], [3], [4, 6], [2], [4, 8], [1], [1, 3], [1], [9], [9], [2], [2], [9], [6], [9], [9], [3], [1], [4], [3], [0, 1, 2], [2], [2], [3, 9], [0, 1, 2], [9], [3], [4], [], [], [3], [1], [1], [1], [8, 9], [1], [], [], [1, 2], [], [2], [3], [0], [], [1, 2], [0], [3], [0, 2], [3], [9], [], [3, 6], [1, 3, 6], [2, 6], [3, 9], [3, 6, 7], [7], [3], [9], [9], [9], [3], [0], [9], [9], [9], [], [2, 3], [1], [1], [3], [3, 9], [8, 9], [1], [3, 9], [0, 1, 2], [1, 3], [4], [3], [2], [4], [6], [1], [1], [1, 2], [6], [2], [3], [0, 1, 2], [], [0], [1], [3], [3], [3], [9], [9], [4], [], [4], [1, 4], [], [3], [9], [9], [1, 2], [3], [4], [4], [0], [1], [1], [2], [1, 2], [1], [3, 7], [1, 3], [3], [], [], [3], [1], [1, 3], [4], [], [3, 4], [2, 6], [4], [1, 3], [], [0, 1], [3, 6], [], [9], [6], [1], [3], [2], [1, 8], [3], [3], [6], [3], [3], [2], [7], [3], [6, 7], [2, 3, 6, 7], [], [], [], [3, 4], [2, 3], [9], [3], [4], [2], [9], [4], [2], [1, 2, 4], [2], [3], [1], [4], [1], [1], [], [0], [3], [3], [1, 4], [4], [0, 1, 2], [4], [0, 1, 2], [3, 9], [0], [3], [9], [], [3], [], [9], [0, 1, 2], [], [0, 1, 2], [9], [], [3], [0, 1, 2], [3], [3, 4], [3], [3], [1, 2], [4, 8], [3], [3, 9], [3], [9], [2, 4], [0, 1], [3], [1], [4], [3], [3, 9], [3], [1, 3, 7], [9], [4], [3], [3, 9], [], [3], [], [1, 2], [2, 4], [], [2], [], [1, 2, 3], [3], [3], [1], [9], [3], [6], [3], [3, 9], [1, 2, 4], [1], [3], [1, 2, 3, 6], [3], [1], [4]]\n","1000\n","1000\n"]}]},{"cell_type":"code","source":["import json\n","import re\n","\n","# Read the \"incorrect-predictions.txt\" file\n","with open(\"/content/incorrect_predictions.txt\", \"r\") as f:\n","    lines = f.readlines()\n","\n","# Initialize variables\n","current_entry = {}\n","data_entries = []\n","\n","\n","# Process the lines and create data entries\n","for line in lines:\n","    line = line.strip()\n","    if line.startswith(\"Index: \"):\n","        current_entry[\"Index\"] = int(line.split(\": \")[1])\n","    elif line.startswith(\"Input Text: \"):\n","        current_entry[\"text\"] = line.split(\": \")[1]\n","    elif line.startswith(\"Input IDs: \"):\n","        input_ids_str = line.split(\": \")[1]\n","        input_ids = [int(id_str) for id_str in re.findall(r'\\d+', input_ids_str)]\n","        current_entry[\"input_ids\"] = input_ids\n","        current_entry[\"labels\"] = []  # Assuming no labels for incorrect predictions\n","        data_entries.append(current_entry)\n","        current_entry = {}\n","    elif line.startswith(\"Labels: \"):  # Process labels\n","        labels_str = line.split(\": \")[1]\n","        labels = [int(label_str) for label_str in re.findall(r'\\d+', labels_str)]\n","        current_entry[\"labels\"] = labels\n","        data_entries.append(current_entry)\n","        current_entry = {}\n","    elif line.startswith(\"Original_Labels: \"):  # Process original labels\n","        labels_str = line.split(\": \")[1]\n","        labels = [int(label_str) for label_str in re.findall(r'\\d+', labels_str)]\n","        current_entry[\"original_labels\"] = labels\n","        data_entries.append(current_entry)\n","        current_entry = {}\n","\n","# Save the data entries to a JSON file\n","output_filename = \"incorrect_predictions_dataset.json\"\n","with open(output_filename, \"w\") as json_file:\n","    json.dump(data_entries, json_file, indent=4)\n","\n","print(f\"Converted incorrect predictions saved to {output_filename}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w4Ti3-TVyyet","executionInfo":{"status":"ok","timestamp":1692598653927,"user_tz":-60,"elapsed":7633,"user":{"displayName":"Sumit Gupta","userId":"07308348120090087318"}},"outputId":"1788d446-042d-466e-e167-2ef46d25f187"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Converted incorrect predictions saved to incorrect_predictions_dataset.json\n"]}]},{"cell_type":"code","source":["from datasets import load_dataset\n","from datasets import load_dataset\n","# Load the dataset\n","dataset = load_dataset(\"lex_glue\", \"ecthr_b\")\n","test_dataset=dataset[\"train\"]\n","# List of target labels\n","target_labels = label_lists  # Replace with your list of target labels\n","print(label_lists)\n","# Initialize a list to store the matching texts\n","matching_texts = []\n","\n","# Iterate through the dataset\n","for entry in test_dataset:\n","    if \"text\" in entry and \"labels\" in entry:\n","        labels = entry[\"labels\"]\n","        text = entry[\"text\"]\n","\n","        # Check if any label matches the target labels\n","        if any(label in target_labels for label in labels):\n","            matching_texts.append(text)\n","# Print the matching texts\n","print(len(matching_texts))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oXOs2L4svV1S","executionInfo":{"status":"ok","timestamp":1692158573868,"user_tz":-60,"elapsed":3086,"user":{"displayName":"Sumit Gupta","userId":"07308348120090087318"}},"outputId":"5d6ee695-3135-4074-b579-217133974e2e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[6], [4], [3], [3], [1, 3], [1], [3], [1], [3, 4], [3], [2], [3], [3], [0], [0, 9], [1], [6], [3], [9], [3, 9], [5], [3, 9], [1], [3], [3, 9], [1], [1], [1], [0], [1, 2], [3, 9], [3], [3], [1], [3], [2], [3, 9], [3, 9], [1, 2], [3, 9], [3], [1, 4], [2], [2], [1, 4, 6], [2, 3], [2], [9], [2, 4], [1], [2], [7], [9], [4], [7], [0], [7], [3, 9], [1, 4], [1, 4, 8], [1], [3], [9], [3, 4], [3], [9], [3], [9], [1, 8], [3], [3, 9], [3], [4], [0], [4, 6], [3], [3], [1], [4], [3], [4], [2, 4], [3], [1, 2, 3, 4], [3], [1, 2], [1], [3], [0], [3, 9], [3], [3], [3, 9], [7], [0], [0, 1], [3], [5, 7], [0], [0, 1], [6], [4], [4], [3], [0], [2], [3], [2], [1], [1, 4], [3], [6], [3, 4], [0], [2, 3], [3], [4], [2], [3], [3, 9], [1, 2], [1], [0, 1], [0, 1], [2], [6], [1, 2, 4], [3], [1, 2], [3], [1, 2, 3], [2], [2, 4], [4, 8], [3, 9], [8], [5], [9], [6], [1], [3], [3], [0, 1, 3], [4], [9], [1, 2], [3, 9], [1, 2, 3], [3], [2], [3], [1, 4], [3], [1], [4], [3], [3, 9], [6], [4], [4, 8], [3], [3], [0], [3, 9], [1], [1], [0, 1, 3], [0, 2], [1], [3], [3], [3], [1], [3, 9], [3], [1, 2], [9], [9], [9], [3, 4], [2], [9], [1], [3], [6], [2], [4, 6], [2], [2], [9], [1], [0], [], [3], [7], [2], [7], [3, 9], [7], [3, 9], [3], [3, 9], [3, 9], [3, 6], [4], [6], [3, 6], [6], [4], [6], [7], [4], [4], [3, 9], [2, 3], [3], [4], [3], [3, 9], [3], [3], [6], [3], [3, 4], [0], [9], [0, 1, 3, 4], [2], [4], [1, 2, 6, 7], [3], [2], [3], [2], [3], [3], [6], [7], [1, 2, 6, 7], [1, 2, 6, 7], [6], [4, 8], [8, 9], [3], [3], [1, 4], [4], [3], [3, 9], [1, 2], [2], [4], [2], [1, 2, 3], [3], [3], [6], [2, 3], [1, 2], [3, 9], [1], [3, 8, 9], [2, 3, 6, 7], [3, 9], [2, 4], [6], [4], [9], [3], [1], [3], [2, 4, 5], [2], [0], [3], [3, 4, 6], [3, 4], [3], [9], [8], [3], [3], [4, 5], [2], [3], [1], [1], [3], [3, 6], [2, 6], [3], [1], [6], [3, 4], [3], [4], [1, 2], [3, 6], [4, 7], [7], [2], [0, 3], [3], [3], [1], [3], [2, 3], [1, 2], [3], [3], [1, 2, 3], [3], [9], [2, 6], [2], [3], [2, 6], [4, 6], [4], [4], [], [1, 2, 4], [1], [1, 2, 4], [2], [6], [3, 4], [9], [3], [3], [3, 9], [4], [3], [2], [2], [1, 2, 3], [4, 8], [1, 3], [2, 4], [3, 9], [1, 4], [4], [5, 7], [1, 3], [3], [1, 2], [2, 3, 7], [3, 4], [3, 6, 7], [6], [2], [3], [1], [3, 6], [3], [9], [3, 6], [4], [3], [4], [4], [7], [6], [4, 8], [1, 4], [9], [1, 9], [1], [6], [3], [3], [1, 2], [1, 3], [4, 8], [1], [0, 3], [0], [3], [1], [4, 9], [2], [4], [2], [1, 2, 3, 7], [], [6], [4], [1], [], [4], [3, 4], [3], [7], [3], [3], [3], [9], [4], [2], [3, 4], [3], [3], [1], [1], [0], [4], [1], [9], [1], [], [2, 3, 4], [2], [3], [1, 2], [0], [1, 2], [1, 2], [1, 2, 3], [1], [1], [0], [1], [3, 9], [0], [1, 3], [4], [2], [2], [3, 9], [3, 9], [3, 9], [9], [4], [4], [4], [3], [1, 3], [9], [6, 9], [2], [3], [2], [3, 6], [6], [6], [2, 4], [3, 4, 8], [1], [0], [3], [9], [1, 2], [2], [1], [6], [2], [3, 9], [3], [2], [3, 9], [3, 9], [4, 6], [3], [6], [3, 9], [9], [4], [4], [1], [2], [3], [9], [2, 7], [6], [2], [5], [1, 2], [2], [7], [1], [7], [3], [3], [2], [3], [3], [2], [1, 3, 4], [6], [4], [1], [3], [1], [1], [1, 2, 3, 6], [1, 2], [4], [1], [3], [4], [3, 9], [1], [1, 3], [9], [0], [1], [9], [6], [3], [0], [], [2], [1], [4, 9], [4], [3], [3], [3], [4], [3], [3], [3], [], [4], [0, 1, 2], [4], [6], [3], [3, 4], [5, 6], [3], [3], [4], [2], [9], [3], [1, 2], [6], [2], [1], [3], [4], [3, 9], [3, 9], [9], [6], [3], [9], [2], [4], [4, 6], [4, 6], [0, 4], [1, 2, 4], [0], [1, 2, 3, 7], [1, 2], [1, 3], [4, 6], [1, 2, 4, 6], [3, 4], [6], [6], [3], [3], [6], [1], [4, 8], [3, 9], [6], [6], [3], [3, 9], [1, 4], [6], [2], [3, 9], [6], [6], [6], [1, 2, 3], [3], [6], [0, 1, 2], [4], [4], [9], [3], [1, 3, 9], [4], [1, 2], [9], [9], [3, 9], [6], [3], [3], [6], [2, 3, 7], [1, 2, 3], [9], [9], [9], [4, 8], [3, 6, 7], [1, 3], [3], [9], [1], [3, 9], [0], [0, 3], [1, 3], [4], [9], [0, 1, 2], [6], [2], [2], [1], [2], [1, 3, 6], [1, 3], [2], [4], [2], [2], [3], [3], [], [2, 3, 9], [3], [2], [9], [3], [1, 2], [4, 8], [4], [8, 9], [0, 1, 2], [1, 2], [0, 1, 2], [3], [], [1], [2, 5, 6], [0, 3], [3], [1], [3], [4, 6], [3], [4, 8], [1], [1], [3, 9], [3], [4], [0], [4], [3], [1, 4, 8, 9], [6], [3], [1, 3], [3], [3], [3], [1, 4], [3], [3], [9], [2], [1], [9], [1, 9], [2, 3, 7, 8], [0, 1, 2], [7], [1], [3], [1, 4], [1], [2], [3, 4], [1, 4, 6], [3], [3], [1, 4], [1, 3], [3], [3], [3], [4], [3], [5, 7], [1, 3], [5, 7], [1, 3], [2, 3], [0, 1, 2], [4], [3, 9], [4], [1, 4], [1, 3], [1, 4], [4, 6], [1], [4], [3, 7], [1], [3], [2], [3, 6], [3], [3, 9], [3, 9], [0, 8], [2], [3], [9], [4], [4], [2], [6], [8, 9], [1], [], [9], [3], [0], [9], [1], [9], [1, 4], [3], [1, 2, 3, 4], [3, 9], [1], [3], [3], [3, 9], [9], [0, 1], [3], [9], [3], [4, 8], [4], [3], [3], [9], [8], [0, 3, 4], [1, 3], [0, 3], [3], [2, 7], [6], [2], [2, 4], [3], [3, 4, 6], [2], [4, 8], [1], [1, 3], [1], [9], [9], [2], [2], [9], [6], [9], [9], [3], [1], [4], [3], [0, 1, 2], [2], [2], [3, 9], [0, 1, 2], [9], [3], [4], [3], [3], [3], [1], [1], [1, 8], [8], [1], [3], [9], [1, 2], [0], [2], [3], [0], [4], [1, 2], [0], [3], [0, 2], [3], [9], [], [3, 6, 7], [1, 3, 6], [2, 6], [3, 9], [3, 6, 7], [1, 2, 3, 7], [1, 3], [9], [9], [9], [3], [0], [9], [9], [9], [3], [2, 3], [1], [1], [3], [3, 9], [8], [1], [3, 9], [0, 1, 2], [1, 3], [2, 3, 4], [3], [2], [4], [6], [1], [1], [1, 2], [6], [2], [3], [0, 1, 2], [], [0], [1, 4], [3], [3], [3], [9], [9], [4], [], [4], [1, 4], [4, 6], [3], [9], [9], [1, 2], [3], [1, 4], [4], [0], [1], [1, 3], [2, 4], [1, 2], [1], [3, 7], [1, 3], [2, 3], [2], [1, 3], [3], [1], [1, 3], [4], [4], [3, 4], [2, 6], [4], [1, 3], [2, 3, 6], [0, 1], [3, 6], [], [9], [6], [1], [3], [2], [1, 8], [3], [1, 3], [6], [3], [3, 9], [2], [2, 7, 8], [3, 9], [6, 7], [2, 3, 6, 7], [3, 6, 7], [3, 9], [6], [3, 4], [2, 3, 4], [9], [3], [4], [2], [9], [4], [2], [1, 2, 4], [0, 2], [3], [1], [4], [1], [1, 4], [3, 4], [0, 4], [3], [3], [1, 2, 4], [3, 4], [0, 1, 2], [4], [0, 1, 2], [3, 9], [0], [3, 4], [3, 9], [2, 3], [3], [4], [0, 9], [0, 1, 2], [0], [0, 1, 2], [9], [0, 3], [0, 3], [0, 1, 2], [3, 4], [3, 4], [3, 9], [3], [1, 2], [4, 8], [3], [3, 9], [3], [3, 9], [2, 4], [0, 1], [3], [1], [4], [3], [3, 9], [3], [1, 3, 7], [9], [4], [3], [3, 9], [1, 4], [3], [3, 4], [1, 2], [2, 4], [4, 8], [1, 2], [0, 1, 2, 3, 4], [1, 2, 3], [3], [3, 9], [1, 2], [3, 9], [3, 9], [6], [3, 6], [3, 9], [1, 2, 4, 6], [1], [3, 6], [1, 2, 3, 6], [3], [1], [4]]\n","0\n"]}]},{"cell_type":"code","source":["import json\n","from datasets import Dataset\n","from datasets import load_dataset, concatenate_datasets\n","from datasets import concatenate_datasets, Dataset, Value, Sequence\n","\n","import pandas as pd\n","\n","# Load JSON data from file\n","file_path = '/content/incorrect_predictions_dataset.json'\n","with open(file_path, 'r') as json_file:\n","    data = json.load(json_file)\n","\n","# Create a dictionary to store original_labels\n","labels_dict = {}\n","texts = []\n","\n","# Initialize lists to store texts and labels\n","\n","# Iterate through the data and extract relevant information\n","#texts = texts.cast(Sequence(feature=Value(dtype='string', id=None)))\n","for entry in data:\n","    if \"text\" in entry:\n","        text = entry[\"text\"]\n","        if \"Index\" in entry:\n","            index = entry[\"Index\"]\n","            #labels.append(labels_dict.get(index, []))\n","        texts.append(text)\n","labels=[]\n","for entry in data:\n","    if \"original_labels\" in entry:\n","        original_labels = entry[\"original_labels\"]\n","        if \"Index\" in entry:\n","            index = entry[\"Index\"]\n","            #labels.append(labels_dict.get(index, []))\n","        labels.append(original_labels)\n","\n","print(\"Number of Texts:\", len(texts))\n","print(\"Number of Labels:\", len(labels))\n","\n","data_dict = {\"text\": texts, \"labels\": labels}\n","\n","# Create a dataset using the data dictionary\n","dataset = Dataset.from_dict(data_dict)\n","\n","# Convert the \"text\" feature to a Sequence of strings\n","dataset = dataset.map(lambda example: {\"text\": [example[\"text\"]]})\n","\n","print(\"Number of Texts:\", len(texts))\n","print(\"Number of Labels:\", len(labels))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":121,"referenced_widgets":["d4c3a19a49604df8b90a50ff9d220801","befdd07cc38f435a950da0ae8d1a442e","16ee4fa46db243d5af2ddb855b2bd371","e98d421961d7412db3f15e5490d67a5b","85bc634cac77438ab91c125c5205ce06","78962328631149ad8f3d677d8fadbd34","8f9518de5d5f45a69b084023d94b024d","77e349ee00b14b5eb2464d4c49354950","efc4e93e6dc6499d9c9a05b84fd6af16","cf19bc3ac34c4ae58ed831709355132e","5eb08e922ff24be6b6f2279186b94c61"]},"id":"ZFbUGhQ0n7Gn","executionInfo":{"status":"ok","timestamp":1692598768704,"user_tz":-60,"elapsed":1457,"user":{"displayName":"Sumit Gupta","userId":"07308348120090087318"}},"outputId":"43dda4eb-e5c7-4318-eb63-bcdc8a202ca1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Texts: 1000\n","Number of Labels: 1000\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4c3a19a49604df8b90a50ff9d220801"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Number of Texts: 1000\n","Number of Labels: 1000\n"]}]},{"cell_type":"code","source":["from datasets import load_dataset, Dataset, concatenate_datasets\n","existing_dataset = load_dataset(\"lex_glue\", 'ecthr_a')\n","existing_train_dataset = existing_dataset[\"train\"]\n","\n","\n","merged_dataset = Dataset.from_dict({\n","    \"text\":  existing_train_dataset[\"text\"] + dataset[\"text\"],\n","    \"labels\": existing_train_dataset[\"labels\"] + dataset[\"labels\"],\n","})\n"],"metadata":{"id":"EAn6cZP5q4nb","executionInfo":{"status":"ok","timestamp":1692598787890,"user_tz":-60,"elapsed":10833,"user":{"displayName":"Sumit Gupta","userId":"07308348120090087318"}},"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["bc05f1ab61904c54bc09d2fb9481dc9e","59cf61ca0d484739a98119018701a4af","d6733d51c9a149dea796585f6e31de0c","c64ec7f8bd3f4e9995212d5ba8e8c8ed","7419e0ad49d5472da04eef5672a11fd1","8f89a1bf08614982aaa0b9d0f9ffb654","3511c0d020b548159c37ed2686dafbe8","844ae73426dc4f71abc7c9174e1cf829","9b2447ba944c4201b765b46dcdddd13c","def3ab23d75348caa485d9a7e2c9f969","37abc9c1f1c5437a8fc9fdcc330bbbb3","1e385b4518054708ba047a00aedea970","2e2ac5558c6249f28fd66951d28b1c41","24e4d8f3fad3414a8a12d969e31865f6","deed90d693cf4965b53feee4821d1304","3d255e8d34e448bba6a017b08317174b","b2a0b883e12f4da49a2736f8fe79b167","73499b12091a489fbb4ab1e3c8780825","1f71d06e1c35476b99d954b1cd89a540","3d2d870aa2024a459320c0ecf74dcbe2","68cd87c9fb5b4e1da5a3811a304bfb2a","82846ab8a4b4418280d7f76c68f57306","544a2c80725f4f49b8658dc7fc6f06e6","b69d0a6862394c7cbe11c899ab807ab8","ed7bde10d3f047bf9cac28c8977724ed","a626e461dd2f4536a25f5ca7d088e628","a0b68d6e236c49a99f873ebf8d2409a1","02de353f90774ac888ad924d30e5f83e","b2ada760a0f646c28c88957379d8b774","96ef4825c8884952949376f51c0fcce1","7e91bb99bae241cb8365eca872517881","23122cfb87d64e0092a7ab83bdb513d7","8189d3cb6c0c4b71870681514cb01ec0"]},"outputId":"d58b4843-fe40-49de-e297-e4c4db65e937"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Generating train split:   0%|          | 0/9000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc05f1ab61904c54bc09d2fb9481dc9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating test split:   0%|          | 0/1000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e385b4518054708ba047a00aedea970"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating validation split:   0%|          | 0/1000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"544a2c80725f4f49b8658dc7fc6f06e6"}},"metadata":{}}]},{"cell_type":"code","source":["print(\"Number of Texts:\", len(merged_dataset[\"text\"]))\n","print(\"Number of Labels:\", len(merged_dataset[\"labels\"]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z11Wwkp8rOdT","executionInfo":{"status":"ok","timestamp":1692598798190,"user_tz":-60,"elapsed":602,"user":{"displayName":"Sumit Gupta","userId":"07308348120090087318"}},"outputId":"e0a4c180-f5a5-40e3-a40f-f2448ffde026"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Texts: 10000\n","Number of Labels: 10000\n"]}]},{"cell_type":"code","source":["#!/usr/bin/env python\n","# coding=utf-8\n","\"\"\" Finetuning models on the ECtHR dataset (e.g. Bert, RoBERTa, LEGAL-BERT).\"\"\"\n","\n","import logging\n","import os\n","import random\n","import sys\n","from dataclasses import dataclass, field\n","from typing import Optional\n","\n","import datasets\n","import numpy as np\n","from datasets import load_dataset\n","from sklearn.metrics import f1_score\n","#from trainer import MultilabelTrainer\n","from scipy.special import expit\n","from torch import nn\n","import glob\n","import shutil\n","\n","import transformers\n","from transformers import (\n","    AutoConfig,\n","    AutoModelForSequenceClassification,\n","    AutoTokenizer,\n","    DataCollatorWithPadding,\n","    EvalPrediction,\n","    HfArgumentParser,\n","    TrainingArguments,\n","    default_data_collator,\n","    set_seed,\n","    EarlyStoppingCallback,\n",")\n","from transformers.trainer_utils import get_last_checkpoint\n","from transformers.utils import check_min_version\n","from transformers.utils.versions import require_version\n","#from models.hierbert import HierarchicalBert\n","#from models.deberta import DebertaForSequenceClassification\n","\n","\n","# Will error if the minimal version of Transformers is not installed. Remove at your own risks.\n","check_min_version(\"4.9.0\")\n","\n","require_version(\"datasets>=1.8.0\", \"To fix: pip install -r examples/pytorch/text-classification/requirements.txt\")\n","\n","logger = logging.getLogger(__name__)\n","\n","\n","@dataclass\n","class DataTrainingArguments:\n","    \"\"\"\n","    Arguments pertaining to what data we are going to input our model for training and eval.\n","\n","    Using `HfArgumentParser` we can turn this class\n","    into argparse arguments to be able to specify them on\n","    the command line.\n","    \"\"\"\n","\n","    max_seq_length: Optional[int] = field(\n","        default=4096,\n","        metadata={\n","            \"help\": \"The maximum total input sequence length after tokenization. Sequences longer \"\n","            \"than this will be truncated, sequences shorter will be padded.\"\n","        },\n","    )\n","    max_segments: Optional[int] = field(\n","        default=64,\n","        metadata={\n","            \"help\": \"The maximum number of segments (paragraphs) to be considered. Sequences longer \"\n","                    \"than this will be truncated, sequences shorter will be padded.\"\n","        },\n","    )\n","    max_seg_length: Optional[int] = field(\n","        default=128,\n","        metadata={\n","            \"help\": \"The maximum segment (paragraph) length to be considered. Segments longer \"\n","                    \"than this will be truncated, sequences shorter will be padded.\"\n","        },\n","    )\n","    overwrite_cache: bool = field(\n","        default=False, metadata={\"help\": \"Overwrite the cached preprocessed datasets or not.\"}\n","    )\n","    pad_to_max_length: bool = field(\n","        default=True,\n","        metadata={\n","            \"help\": \"Whether to pad all samples to `max_seq_length`. \"\n","            \"If False, will pad the samples dynamically when batching to the maximum length in the batch.\"\n","        },\n","    )\n","    max_train_samples: Optional[int] = field(\n","        default=None,\n","        metadata={\n","            \"help\": \"For debugging purposes or quicker training, truncate the number of training examples to this \"\n","            \"value if set.\"\n","        },\n","    )\n","    max_eval_samples: Optional[int] = field(\n","        default=None,\n","        metadata={\n","            \"help\": \"For debugging purposes or quicker training, truncate the number of evaluation examples to this \"\n","            \"value if set.\"\n","        },\n","    )\n","    max_predict_samples: Optional[int] = field(\n","        default=None,\n","        metadata={\n","            \"help\": \"For debugging purposes or quicker training, truncate the number of prediction examples to this \"\n","            \"value if set.\"\n","        },\n","    )\n","    task: Optional[str] = field(\n","        default='ecthr_a',\n","        metadata={\n","            \"help\": \"Define downstream task\"\n","        },\n","    )\n","    server_ip: Optional[str] = field(default=None, metadata={\"help\": \"For distant debugging.\"})\n","    server_port: Optional[str] = field(default=None, metadata={\"help\": \"For distant debugging.\"})\n","\n","\n","@dataclass\n","class ModelArguments:\n","    \"\"\"\n","    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n","    \"\"\"\n","\n","    model_name_or_path: str = field(\n","        default=None, metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n","    )\n","    hierarchical: bool = field(\n","        default=True, metadata={\"help\": \"Whether to use a hierarchical variant or not\"}\n","    )\n","    config_name: Optional[str] = field(\n","        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n","    )\n","    tokenizer_name: Optional[str] = field(\n","        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n","    )\n","    cache_dir: Optional[str] = field(\n","        default=None,\n","        metadata={\"help\": \"Where do you want to store the pretrained models downloaded from huggingface.co\"},\n","    )\n","    do_lower_case: Optional[bool] = field(\n","        default=True,\n","        metadata={\"help\": \"arg to indicate if tokenizer should do lower case in AutoTokenizer.from_pretrained()\"},\n","    )\n","    use_fast_tokenizer: bool = field(\n","        default=True,\n","        metadata={\"help\": \"Whether to use one of the fast tokenizer (backed by the tokenizers library) or not.\"},\n","    )\n","    model_revision: str = field(\n","        default=\"main\",\n","        metadata={\"help\": \"The specific model version to use (can be a branch name, tag name or commit id).\"},\n","    )\n","    use_auth_token: bool = field(\n","        default=False,\n","        metadata={\n","            \"help\": \"Will use the token generated when running `transformers-cli login` (necessary to use this script \"\n","            \"with private models).\"\n","        },\n","    )\n","\n","\n","def main(training_args):\n","    # See all possible arguments in src/transformers/training_args.py\n","    # or by passing the --help flag to this script.\n","    # We now keep distinct sets of args, for a cleaner separation of concerns.\n","\n","    model_args = ModelArguments(\n","        model_name_or_path=\"bert-base-uncased\",\n","        hierarchical=True,\n","        do_lower_case=True,\n","        use_fast_tokenizer=True,\n","    )\n","    data_args = DataTrainingArguments(\n","        max_seq_length=128,\n","        max_segments=64,\n","        max_seg_length=128,\n","        overwrite_cache=False,\n","        pad_to_max_length=True,\n","    )\n","\n","    # Fix boolean parameter\n","    if model_args.do_lower_case == 'False' or not model_args.do_lower_case:\n","        model_args.do_lower_case = False\n","    else:\n","        model_args.do_lower_case = True\n","\n","    if model_args.hierarchical == 'False' or not model_args.hierarchical:\n","        model_args.hierarchical = False\n","    else:\n","        model_args.hierarchical = True\n","\n","    # Setup distant debugging if needed\n","    if data_args.server_ip and data_args.server_port:\n","        # Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script\n","        import ptvsd\n","\n","        print(\"Waiting for debugger attach\")\n","        ptvsd.enable_attach(address=(data_args.server_ip, data_args.server_port), redirect_output=True)\n","        ptvsd.wait_for_attach()\n","\n","    # Setup logging\n","    logging.basicConfig(\n","        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n","        datefmt=\"%m/%d/%Y %H:%M:%S\",\n","        handlers=[logging.StreamHandler(sys.stdout)],\n","    )\n","\n","    log_level = training_args.get_process_log_level()\n","    logger.setLevel(log_level)\n","    datasets.utils.logging.set_verbosity(log_level)\n","    transformers.utils.logging.set_verbosity(log_level)\n","    transformers.utils.logging.enable_default_handler()\n","    transformers.utils.logging.enable_explicit_format()\n","\n","    # Log on each process the small summary:\n","    logger.warning(\n","        f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n","        + f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"\n","    )\n","    logger.info(f\"Training/evaluation parameters {training_args}\")\n","\n","    # Detecting last checkpoint.\n","    last_checkpoint = None\n","    if os.path.isdir(training_args.output_dir) and training_args.do_train and not training_args.overwrite_output_dir:\n","        last_checkpoint = get_last_checkpoint(training_args.output_dir)\n","        if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:\n","            raise ValueError(\n","                f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n","                \"Use --overwrite_output_dir to overcome.\"\n","            )\n","        elif last_checkpoint is not None:\n","            logger.info(\n","                f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"\n","                \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n","            )\n","\n","    # Set seed before initializing model.\n","    set_seed(training_args.seed)\n","\n","    # In distributed training, the load_dataset function guarantees that only one local process can concurrently\n","    # download the dataset.\n","    # Downloading and loading eurlex dataset from the hub.\n","    if training_args.do_train:\n","        train_dataset = merged_dataset\n","\n","    if training_args.do_eval:\n","        eval_dataset = load_dataset(\"lex_glue\", name=data_args.task, split=\"validation\", data_dir='data', cache_dir=model_args.cache_dir)\n","\n","    if training_args.do_predict:\n","        predict_dataset = load_dataset(\"lex_glue\", name=data_args.task, split=\"test\", data_dir='data', cache_dir=model_args.cache_dir)\n","\n","    # Labels\n","    label_list = list(range(10))\n","    num_labels = len(label_list)\n","\n","    # Load pretrained model and tokenizer\n","    # In distributed training, the .from_pretrained methods guarantee that only one local process can concurrently\n","    # download model & vocab.\n","    config = AutoConfig.from_pretrained(\n","        model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n","        num_labels=num_labels,\n","        finetuning_task=f\"{data_args.task}\",\n","        cache_dir=model_args.cache_dir,\n","        revision=model_args.model_revision,\n","        use_auth_token=True if model_args.use_auth_token else None,\n","    )\n","    tokenizer = AutoTokenizer.from_pretrained(\n","        model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,\n","        do_lower_case=model_args.do_lower_case,\n","        cache_dir=model_args.cache_dir,\n","        use_fast=model_args.use_fast_tokenizer,\n","        revision=model_args.model_revision,\n","        use_auth_token=True if model_args.use_auth_token else None,\n","    )\n","    if config.model_type == 'deberta' and model_args.hierarchical:\n","        model = DebertaForSequenceClassification.from_pretrained(\n","            model_args.model_name_or_path,\n","            from_tf=bool(\".ckpt\" in model_args.model_name_or_path),\n","            config=config,\n","            cache_dir=model_args.cache_dir,\n","            revision=model_args.model_revision,\n","            use_auth_token=True if model_args.use_auth_token else None,\n","        )\n","    else:\n","        model = AutoModelForSequenceClassification.from_pretrained(\n","            model_args.model_name_or_path,\n","            from_tf=bool(\".ckpt\" in model_args.model_name_or_path),\n","            config=config,\n","            cache_dir=model_args.cache_dir,\n","            revision=model_args.model_revision,\n","            use_auth_token=True if model_args.use_auth_token else None,\n","        )\n","\n","    if model_args.hierarchical:\n","        # Hack the classifier encoder to use hierarchical BERT\n","        if config.model_type in ['bert', 'deberta']:\n","            if config.model_type == 'bert':\n","                segment_encoder = model.bert\n","            else:\n","                segment_encoder = model.deberta\n","            model_encoder = HierarchicalBert(encoder=segment_encoder,\n","                                             max_segments=data_args.max_segments,\n","                                             max_segment_length=data_args.max_seg_length)\n","            if config.model_type == 'bert':\n","                model.bert = model_encoder\n","            elif config.model_type == 'deberta':\n","                model.deberta = model_encoder\n","            else:\n","                raise NotImplementedError(f\"{config.model_type} is no supported yet!\")\n","        elif config.model_type == 'roberta':\n","            model_encoder = HierarchicalBert(encoder=model.roberta, max_segments=data_args.max_segments,\n","                                             max_segment_length=data_args.max_seg_length)\n","            model.roberta = model_encoder\n","            # Build a new classification layer, as well\n","            dense = nn.Linear(config.hidden_size, config.hidden_size)\n","            dense.load_state_dict(model.classifier.dense.state_dict())  # load weights\n","            dropout = nn.Dropout(config.hidden_dropout_prob).to(model.device)\n","            out_proj = nn.Linear(config.hidden_size, config.num_labels).to(model.device)\n","            out_proj.load_state_dict(model.classifier.out_proj.state_dict())  # load weights\n","            model.classifier = nn.Sequential(dense, dropout, out_proj).to(model.device)\n","        elif config.model_type in ['longformer', 'big_bird']:\n","            pass\n","        else:\n","            raise NotImplementedError(f\"{config.model_type} is no supported yet!\")\n","\n","    # Preprocessing the datasets\n","    # Padding strategy\n","    if data_args.pad_to_max_length:\n","        padding = \"max_length\"\n","    else:\n","        # We will pad later, dynamically at batch creation, to the max sequence length in each batch\n","        padding = False\n","\n","    def preprocess_function(examples):\n","        # Tokenize the texts\n","        if model_args.hierarchical:\n","            case_template = [[0] * data_args.max_seg_length]\n","            if config.model_type == 'roberta':\n","                batch = {'input_ids': [], 'attention_mask': []}\n","                for case in examples['text']:\n","                    case_encodings = tokenizer(case[:data_args.max_segments], padding=padding,\n","                                               max_length=data_args.max_seg_length, truncation=True)\n","                    batch['input_ids'].append(case_encodings['input_ids'] + case_template * (\n","                                data_args.max_segments - len(case_encodings['input_ids'])))\n","                    batch['attention_mask'].append(case_encodings['attention_mask'] + case_template * (\n","                                data_args.max_segments - len(case_encodings['attention_mask'])))\n","            else:\n","                batch = {'input_ids': [], 'attention_mask': [], 'token_type_ids': []}\n","                for case in examples['text']:\n","                    case_encodings = tokenizer(case[:data_args.max_segments], padding=padding,\n","                                               max_length=data_args.max_seg_length, truncation=True)\n","                    batch['input_ids'].append(case_encodings['input_ids'] + case_template * (\n","                            data_args.max_segments - len(case_encodings['input_ids'])))\n","                    batch['attention_mask'].append(case_encodings['attention_mask'] + case_template * (\n","                            data_args.max_segments - len(case_encodings['attention_mask'])))\n","                    batch['token_type_ids'].append(case_encodings['token_type_ids'] + case_template * (\n","                            data_args.max_segments - len(case_encodings['token_type_ids'])))\n","        elif config.model_type in ['longformer', 'big_bird']:\n","            cases = []\n","            max_position_embeddings = config.max_position_embeddings - 2 if config.model_type == 'longformer' \\\n","                else config.max_position_embeddings\n","            for case in examples['text']:\n","                cases.append(f' {tokenizer.sep_token} '.join(\n","                    [' '.join(fact.split()[:data_args.max_seg_length]) for fact in case[:data_args.max_segments]]))\n","            batch = tokenizer(cases, padding=padding, max_length=max_position_embeddings, truncation=True)\n","            if config.model_type == 'longformer':\n","                global_attention_mask = np.zeros((len(cases), max_position_embeddings), dtype=np.int32)\n","                # global attention on cls token\n","                global_attention_mask[:, 0] = 1\n","                batch['global_attention_mask'] = list(global_attention_mask)\n","        else:\n","            cases = []\n","            for case in examples['text']:\n","                cases.append(f'\\n'.join(case))\n","            batch = tokenizer(cases, padding=padding, max_length=512, truncation=True)\n","\n","        batch[\"labels\"] = [[1 if label in labels else 0 for label in label_list] for labels in examples[\"labels\"]]\n","\n","        return batch\n","\n","    if training_args.do_train:\n","        if data_args.max_train_samples is not None:\n","            train_dataset = train_dataset.select(range(data_args.max_train_samples))\n","        with training_args.main_process_first(desc=\"train dataset map pre-processing\"):\n","            train_dataset = train_dataset.map(\n","                preprocess_function,\n","                batched=True,\n","                load_from_cache_file=not data_args.overwrite_cache,\n","                desc=\"Running tokenizer on train dataset\",\n","            )\n","        # Log a few random samples from the training set:\n","        for index in random.sample(range(len(train_dataset)), 3):\n","            logger.info(f\"Sample {index} of the training set: {train_dataset[index]}.\")\n","\n","    if training_args.do_eval:\n","        if data_args.max_eval_samples is not None:\n","            eval_dataset = eval_dataset.select(range(data_args.max_eval_samples))\n","        with training_args.main_process_first(desc=\"validation dataset map pre-processing\"):\n","            eval_dataset = eval_dataset.map(\n","                preprocess_function,\n","                batched=True,\n","                load_from_cache_file=not data_args.overwrite_cache,\n","                desc=\"Running tokenizer on validation dataset\",\n","            )\n","\n","    if training_args.do_predict:\n","        if data_args.max_predict_samples is not None:\n","            predict_dataset = predict_dataset.select(range(data_args.max_predict_samples))\n","        with training_args.main_process_first(desc=\"prediction dataset map pre-processing\"):\n","            predict_dataset = predict_dataset.map(\n","                preprocess_function,\n","                batched=True,\n","                load_from_cache_file=not data_args.overwrite_cache,\n","                desc=\"Running tokenizer on prediction dataset\",\n","            )\n","\n","    # You can define your custom compute_metrics function. It takes an `EvalPrediction` object (a namedtuple with a\n","    # predictions and label_ids field) and has to return a dictionary string to float.\n","    def compute_metrics(p: EvalPrediction):\n","        # Fix gold labels\n","        y_true = np.zeros((p.label_ids.shape[0], p.label_ids.shape[1] + 1), dtype=np.int32)\n","        y_true[:, :-1] = p.label_ids\n","        y_true[:, -1] = (np.sum(p.label_ids, axis=1) == 0).astype('int32')\n","        # Fix predictions\n","        logits = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n","        preds = (expit(logits) > 0.5).astype('int32')\n","        y_pred = np.zeros((p.label_ids.shape[0], p.label_ids.shape[1] + 1), dtype=np.int32)\n","        y_pred[:, :-1] = preds\n","        y_pred[:, -1] = (np.sum(preds, axis=1) == 0).astype('int32')\n","        # Compute scores\n","        macro_f1 = f1_score(y_true=y_true, y_pred=y_pred, average='macro', zero_division=0)\n","        micro_f1 = f1_score(y_true=y_true, y_pred=y_pred, average='micro', zero_division=0)\n","        return {'macro-f1': macro_f1, 'micro-f1': micro_f1}\n","\n","    # Data collator will default to DataCollatorWithPadding, so we change it if we already did the padding.\n","    if data_args.pad_to_max_length:\n","        data_collator = default_data_collator\n","    elif training_args.fp16:\n","        data_collator = DataCollatorWithPadding(tokenizer, pad_to_multiple_of=8)\n","    else:\n","        data_collator = None\n","\n","    # Initialize our Trainer\n","    trainer = MultilabelTrainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=train_dataset if training_args.do_train else None,\n","        eval_dataset=eval_dataset if training_args.do_eval else None,\n","        compute_metrics=compute_metrics,\n","        tokenizer=tokenizer,\n","        data_collator=data_collator,\n","        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n","    )\n","\n","    # Training\n","    if training_args.do_train:\n","        checkpoint = None\n","        if training_args.resume_from_checkpoint is not None:\n","            checkpoint = training_args.resume_from_checkpoint\n","        elif last_checkpoint is not None:\n","            checkpoint = last_checkpoint\n","        train_result = trainer.train(resume_from_checkpoint=checkpoint)\n","        metrics = train_result.metrics\n","        max_train_samples = (\n","            data_args.max_train_samples if data_args.max_train_samples is not None else len(train_dataset)\n","        )\n","        metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n","\n","        trainer.save_model()  # Saves the tokenizer too for easy upload\n","\n","        trainer.log_metrics(\"train\", metrics)\n","        trainer.save_metrics(\"train\", metrics)\n","        trainer.save_state()\n","\n","    # Evaluation\n","    if training_args.do_eval:\n","        logger.info(\"*** Evaluate ***\")\n","        metrics = trainer.evaluate(eval_dataset=eval_dataset)\n","\n","        max_eval_samples = data_args.max_eval_samples if data_args.max_eval_samples is not None else len(eval_dataset)\n","        metrics[\"eval_samples\"] = min(max_eval_samples, len(eval_dataset))\n","\n","        trainer.log_metrics(\"eval\", metrics)\n","        trainer.save_metrics(\"eval\", metrics)\n","\n","    # Prediction\n","    if training_args.do_predict:\n","        logger.info(\"*** Predict ***\")\n","        predictions, labels, metrics = trainer.predict(predict_dataset, metric_key_prefix=\"predict\")\n","\n","        max_predict_samples = (\n","            data_args.max_predict_samples if data_args.max_predict_samples is not None else len(predict_dataset)\n","        )\n","        metrics[\"predict_samples\"] = min(max_predict_samples, len(predict_dataset))\n","\n","        trainer.log_metrics(\"predict\", metrics)\n","        trainer.save_metrics(\"predict\", metrics)\n","\n","        output_predict_file = os.path.join(training_args.output_dir, \"test_predictions.csv\")\n","        if trainer.is_world_process_zero():\n","            with open(output_predict_file, \"w\") as writer:\n","                for index, pred_list in enumerate(predictions[0]):\n","                    pred_line = '\\t'.join([f'{pred:.5f}' for pred in pred_list])\n","                    writer.write(f\"{index}\\t{pred_line}\\n\")\n","\n","    # Clean up checkpoints\n","    checkpoints = [filepath for filepath in glob.glob(f'{training_args.output_dir}/*/') if '/checkpoint' in filepath]\n","    for checkpoint in checkpoints:\n","        shutil.rmtree(checkpoint)\n","\n","\n","if __name__ == \"__main__\":\n","    training_args = TrainingArguments(\n","        do_train = True,\n","        do_eval = True,\n","        do_predict = True,\n","        output_dir=os.getcwd(),\n","        overwrite_output_dir=True,\n","        num_train_epochs=2,\n","        per_device_train_batch_size=4,\n","        per_device_eval_batch_size=4,\n","        save_steps=500,\n","        save_total_limit=2,\n","        fp16=False,\n","        logging_dir=\"./logs\",\n","        logging_steps=100,\n","        evaluation_strategy=\"steps\",\n","        eval_steps=500,\n","        logging_first_step=False,\n","        load_best_model_at_end = True,\n","        metric_for_best_model=\"micro-f1\",\n","    )\n","    main(training_args)\n","\n"],"metadata":{"id":"RiXeMpZWvcgM","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f70d15af949d414b803634e6c1f391ec","50a3899eba3944c78fb6c4808351bc75","f7b8a26f8c6e4033a87bf12675381e4f","7bebc66ed79a412297f25d8acac99c6b","23a4f9555da346089dd06b580437fbde","8fe379558ffa46a18c8f7ddd0d387fb9","b6156c33b1e145d988ac668d5ed86b82","a9ce81938f464d8cb2502102171fefe0","c80f835a0a074c5ab7e6d7752e58783e","3a27785b1a5f4de1a7441f006a455d24","908d186dab7f4724a276e14810a0bcac","4b9918cbf1be4a5e851a706e93b62111","c61389f402eb45ecb85d7f2153f570d7","c19d04ec54bb40048e82623d557016e7","91db8b9d7b9d4085bafc06be36160e1c","ff8e9b636914415cb133d330b1e35dde","2f2524c7b3ff42468c72e0796888aa71","b62c3fd8540a45c082c7821566c4cb4f","ef407401a7c244e8b0deda161fff7a1f","8afcf9e5dcfe4797bf16b9fc6cf45beb","f2b773b636bf4dca9457430ac7583d2c","59756d9dc6a94f828f7e5567a5c882d1","bbf6fb7e11c742cd8550ebfc38e2c527","de57dae9dee646708073ffef9f51b889","56ffa4b2535144f88902fe8ba483652c","83d5c422812243e88e502271914ed04e","578e6906573b4df6bf39f84481857bcd","96184b13cb2b404a8fa385ea595120e7","24dd9366a23044deb987bc4ad360bb56","762b0854af66448d858cb3d0b3146302","77ae753e09cc4b4a980ba4822c88a50b","b0e6c5bf9ddd46039f9870cb09bbfc23","e2e29ed56b66437d960355dd115bb985"]},"executionInfo":{"status":"ok","timestamp":1692606035096,"user_tz":-60,"elapsed":7202909,"user":{"displayName":"Sumit Gupta","userId":"07308348120090087318"}},"outputId":"0824e211-c2cc-4711-89dc-fe2876860cb7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:__main__:Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False\n","[WARNING|modeling_utils.py:3331] 2023-08-21 06:20:38,870 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["Running tokenizer on train dataset:   0%|          | 0/10000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f70d15af949d414b803634e6c1f391ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Running tokenizer on validation dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b9918cbf1be4a5e851a706e93b62111"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Running tokenizer on prediction dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbf6fb7e11c742cd8550ebfc38e2c527"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='5000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5000/5000 1:55:15, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro-f1</th>\n","      <th>Micro-f1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.194400</td>\n","      <td>0.204295</td>\n","      <td>0.373758</td>\n","      <td>0.568284</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.156200</td>\n","      <td>0.196128</td>\n","      <td>0.395173</td>\n","      <td>0.594637</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.142200</td>\n","      <td>0.176720</td>\n","      <td>0.471873</td>\n","      <td>0.617355</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.144100</td>\n","      <td>0.165887</td>\n","      <td>0.525580</td>\n","      <td>0.657028</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.150800</td>\n","      <td>0.149872</td>\n","      <td>0.559435</td>\n","      <td>0.685668</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.122600</td>\n","      <td>0.149508</td>\n","      <td>0.514612</td>\n","      <td>0.676797</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.124500</td>\n","      <td>0.165385</td>\n","      <td>0.561741</td>\n","      <td>0.678783</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.108500</td>\n","      <td>0.143873</td>\n","      <td>0.633314</td>\n","      <td>0.701330</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.102600</td>\n","      <td>0.140962</td>\n","      <td>0.636863</td>\n","      <td>0.711469</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.102400</td>\n","      <td>0.143853</td>\n","      <td>0.646531</td>\n","      <td>0.710652</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["***** train metrics *****\n","  epoch                    =        2.0\n","  total_flos               = 91398524GF\n","  train_loss               =     0.1431\n","  train_runtime            = 1:55:16.96\n","  train_samples            =      10000\n","  train_samples_per_second =      2.891\n","  train_steps_per_second   =      0.723\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["***** eval metrics *****\n","  epoch                   =        2.0\n","  eval_loss               =      0.141\n","  eval_macro-f1           =     0.6369\n","  eval_micro-f1           =     0.7115\n","  eval_runtime            = 0:01:42.68\n","  eval_samples            =       1000\n","  eval_samples_per_second =      9.739\n","  eval_steps_per_second   =      2.435\n","***** predict metrics *****\n","  predict_loss               =     0.1317\n","  predict_macro-f1           =     0.6007\n","  predict_micro-f1           =     0.7276\n","  predict_runtime            = 0:01:42.68\n","  predict_samples            =       1000\n","  predict_samples_per_second =      9.738\n","  predict_steps_per_second   =      2.435\n"]}]},{"cell_type":"code","source":["#!/usr/bin/env python\n","# coding=utf-8\n","\"\"\" Finetuning models on the ECtHR dataset (e.g. Bert, RoBERTa, LEGAL-BERT).\"\"\"\n","\n","import logging\n","import os\n","import random\n","import sys\n","from dataclasses import dataclass, field\n","from typing import Optional\n","\n","import datasets\n","import numpy as np\n","from datasets import load_dataset\n","from sklearn.metrics import f1_score\n","#from trainer import MultilabelTrainer\n","from scipy.special import expit\n","from torch import nn\n","import glob\n","import shutil\n","import torch\n","torch.cuda.empty_cache()\n","import transformers\n","from transformers import (\n","    AutoConfig,\n","    AutoModelForSequenceClassification,\n","    AutoTokenizer,\n","    DataCollatorWithPadding,\n","    EvalPrediction,\n","    HfArgumentParser,\n","    TrainingArguments,\n","    default_data_collator,\n","    set_seed,\n","    EarlyStoppingCallback,\n",")\n","from transformers.trainer_utils import get_last_checkpoint\n","from transformers.utils import check_min_version\n","from transformers.utils.versions import require_version\n","#from models.hierbert import HierarchicalBert\n","#from models.deberta import DebertaForSequenceClassification\n","\n","\n","# Will error if the minimal version of Transformers is not installed. Remove at your own risks.\n","check_min_version(\"4.9.0\")\n","\n","require_version(\"datasets>=1.8.0\", \"To fix: pip install -r examples/pytorch/text-classification/requirements.txt\")\n","\n","logger = logging.getLogger(__name__)\n","\n","from transformers import AutoModel, AutoTokenizer\n","\n","# First, load the tokenizer and pre-trained BERT model\n","tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","bert_model = AutoModel.from_pretrained('bert-base-uncased')\n","\n","# Then, create an instance of HierarchicalBert\n","max_segments = 64\n","max_segment_length = 128\n","HierarchicalBertObj = HierarchicalBert(encoder=bert_model, max_segments=max_segments, max_segment_length=max_segment_length)\n","#os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb=256,512,1024\"\n","\n","@dataclass\n","class DataTrainingArguments:\n","    \"\"\"\n","    Arguments pertaining to what data we are going to input our model for training and eval.\n","\n","    Using `HfArgumentParser` we can turn this class\n","    into argparse arguments to be able to specify them on\n","    the command line.\n","    \"\"\"\n","\n","    max_seq_length: Optional[int] = field(\n","        default=4096,\n","        metadata={\n","            \"help\": \"The maximum total input sequence length after tokenization. Sequences longer \"\n","            \"than this will be truncated, sequences shorter will be padded.\"\n","        },\n","    )\n","    max_segments: Optional[int] = field(\n","        default=64,\n","        metadata={\n","            \"help\": \"The maximum number of segments (paragraphs) to be considered. Sequences longer \"\n","                    \"than this will be truncated, sequences shorter will be padded.\"\n","        },\n","    )\n","    max_seg_length: Optional[int] = field(\n","        default=128,\n","        metadata={\n","            \"help\": \"The maximum segment (paragraph) length to be considered. Segments longer \"\n","                    \"than this will be truncated, sequences shorter will be padded.\"\n","        },\n","    )\n","    overwrite_cache: bool = field(\n","        default=False, metadata={\"help\": \"Overwrite the cached preprocessed datasets or not.\"}\n","    )\n","    pad_to_max_length: bool = field(\n","        default=True,\n","        metadata={\n","            \"help\": \"Whether to pad all samples to `max_seq_length`. \"\n","            \"If False, will pad the samples dynamically when batching to the maximum length in the batch.\"\n","        },\n","    )\n","    max_train_samples: Optional[int] = field(\n","        default=None,\n","        metadata={\n","            \"help\": \"For debugging purposes or quicker training, truncate the number of training examples to this \"\n","            \"value if set.\"\n","        },\n","    )\n","    max_eval_samples: Optional[int] = field(\n","        default=None,\n","        metadata={\n","            \"help\": \"For debugging purposes or quicker training, truncate the number of evaluation examples to this \"\n","            \"value if set.\"\n","        },\n","    )\n","    max_predict_samples: Optional[int] = field(\n","        default=None,\n","        metadata={\n","            \"help\": \"For debugging purposes or quicker training, truncate the number of prediction examples to this \"\n","            \"value if set.\"\n","        },\n","    )\n","    task: Optional[str] = field(\n","        default=None,\n","        metadata={\n","            \"help\": \"Define downstream task\"\n","        },\n","    )\n","    server_ip: Optional[str] = field(default=None, metadata={\"help\": \"For distant debugging.\"})\n","    server_port: Optional[str] = field(default=None, metadata={\"help\": \"For distant debugging.\"})\n","\n","\n","@dataclass\n","class ModelArguments:\n","    \"\"\"\n","    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n","    \"\"\"\n","\n","    model_name_or_path: str = field(\n","        default=None, metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n","    )\n","    hierarchical: bool = field(\n","        default=True, metadata={\"help\": \"Whether to use a hierarchical variant or not\"}\n","    )\n","    config_name: Optional[str] = field(\n","        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n","    )\n","    tokenizer_name: Optional[str] = field(\n","        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n","    )\n","    cache_dir: Optional[str] = field(\n","        default=None,\n","        metadata={\"help\": \"Where do you want to store the pretrained models downloaded from huggingface.co\"},\n","    )\n","    do_lower_case: Optional[bool] = field(\n","        default=True,\n","        metadata={\"help\": \"arg to indicate if tokenizer should do lower case in AutoTokenizer.from_pretrained()\"},\n","    )\n","    use_fast_tokenizer: bool = field(\n","        default=True,\n","        metadata={\"help\": \"Whether to use one of the fast tokenizer (backed by the tokenizers library) or not.\"},\n","    )\n","    model_revision: str = field(\n","        default=\"main\",\n","        metadata={\"help\": \"The specific model version to use (can be a branch name, tag name or commit id).\"},\n","    )\n","    use_auth_token: bool = field(\n","        default=False,\n","        metadata={\n","            \"help\": \"Will use the token generated when running `transformers-cli login` (necessary to use this script \"\n","            \"with private models).\"\n","        },\n","    )\n","\n","\n","def main(training_args):\n","    # See all possible arguments in src/transformers/training_args.py\n","    # or by passing the --help flag to this script.\n","    # We now keep distinct sets of args, for a cleaner separation of concerns.\n","\n","    model_args = ModelArguments(\n","        model_name_or_path=\"bert-base-uncased\",\n","        hierarchical=True,\n","        do_lower_case=True,\n","        use_fast_tokenizer=True,\n","    )\n","    data_args = DataTrainingArguments(\n","        max_seq_length=128,\n","        max_segments=64,\n","        max_seg_length=128,\n","        overwrite_cache=False,\n","        pad_to_max_length=True,\n","    )\n","\n","\n","    # Fix boolean parameter\n","    if model_args.do_lower_case == 'False' or not model_args.do_lower_case:\n","        model_args.do_lower_case = False\n","    else:\n","        model_args.do_lower_case = True\n","\n","    if model_args.hierarchical == 'False' or not model_args.hierarchical:\n","        model_args.hierarchical = False\n","    else:\n","        model_args.hierarchical = True\n","\n","    # Setup distant debugging if needed\n","    if data_args.server_ip and data_args.server_port:\n","        # Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script\n","        import ptvsd\n","\n","        print(\"Waiting for debugger attach\")\n","        ptvsd.enable_attach(address=(data_args.server_ip, data_args.server_port), redirect_output=True)\n","        ptvsd.wait_for_attach()\n","\n","    # Setup logging\n","    logging.basicConfig(\n","        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n","        datefmt=\"%m/%d/%Y %H:%M:%S\",\n","        handlers=[logging.StreamHandler(sys.stdout)],\n","    )\n","\n","    log_level = training_args.get_process_log_level()\n","    logger.setLevel(log_level)\n","    datasets.utils.logging.set_verbosity(log_level)\n","    transformers.utils.logging.set_verbosity(log_level)\n","    transformers.utils.logging.enable_default_handler()\n","    transformers.utils.logging.enable_explicit_format()\n","\n","    # Log on each process the small summary:\n","    logger.warning(\n","        f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n","        + f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"\n","    )\n","    logger.info(f\"Training/evaluation parameters {training_args}\")\n","\n","    # Detecting last checkpoint.\n","    last_checkpoint = None\n","    if os.path.isdir(training_args.output_dir) and training_args.do_train and not training_args.overwrite_output_dir:\n","        last_checkpoint = get_last_checkpoint(training_args.output_dir)\n","        if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:\n","            raise ValueError(\n","                f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n","                \"Use --overwrite_output_dir to overcome.\"\n","            )\n","        elif last_checkpoint is not None:\n","            logger.info(\n","                f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"\n","                \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n","            )\n","\n","    # Set seed before initializing model.\n","    set_seed(training_args.seed)\n","\n","    # In distributed training, the load_dataset function guarantees that only one local process can concurrently\n","    # download the dataset.\n","    # Downloading and loading eurlex dataset from the hub.\n","    if training_args.do_train:\n","        train_dataset = load_dataset(\"lex_glue\",\"ecthr_b\", split=\"train\", data_dir='data', cache_dir=model_args.cache_dir)\n","\n","    if training_args.do_eval:\n","        eval_dataset = load_dataset(\"lex_glue\",\"ecthr_b\", split=\"validation\", data_dir='data', cache_dir=model_args.cache_dir)\n","\n","    if training_args.do_predict:\n","        predict_dataset = load_dataset(\"lex_glue\", \"ecthr_b\" ,split=\"test\", data_dir='data', cache_dir=model_args.cache_dir)\n","\n","    # Labels\n","    label_list = list(range(10))\n","    num_labels = len(label_list)\n","\n","    # Load pretrained model and tokenizer\n","    # In distributed training, the .from_pretrained methods guarantee that only one local process can concurrently\n","    # download model & vocab.\n","    config = AutoConfig.from_pretrained(\n","        model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n","        num_labels=num_labels,\n","        finetuning_task=f\"{data_args.task}\",\n","        cache_dir=model_args.cache_dir,\n","        revision=model_args.model_revision,\n","        use_auth_token=True if model_args.use_auth_token else None,\n","    )\n","    tokenizer = AutoTokenizer.from_pretrained(\n","        model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,\n","        do_lower_case=model_args.do_lower_case,\n","        cache_dir=model_args.cache_dir,\n","        use_fast=model_args.use_fast_tokenizer,\n","        revision=model_args.model_revision,\n","        use_auth_token=True if model_args.use_auth_token else None,\n","    )\n","    if config.model_type == 'deberta' and model_args.hierarchical:\n","        model = DebertaForSequenceClassification.from_pretrained(\n","            model_args.model_name_or_path,\n","            from_tf=bool(\".ckpt\" in model_args.model_name_or_path),\n","            config=config,\n","            cache_dir=model_args.cache_dir,\n","            revision=model_args.model_revision,\n","            use_auth_token=True if model_args.use_auth_token else None,\n","        )\n","    else:\n","        model = AutoModelForSequenceClassification.from_pretrained(\n","            model_args.model_name_or_path,\n","            from_tf=bool(\".ckpt\" in model_args.model_name_or_path),\n","            config=config,\n","            cache_dir=model_args.cache_dir,\n","            revision=model_args.model_revision,\n","            use_auth_token=True if model_args.use_auth_token else None,\n","        )\n","\n","    if model_args.hierarchical:\n","        # Hack the classifier encoder to use hierarchical BERT\n","        if config.model_type in ['bert', 'deberta']:\n","            if config.model_type == 'bert':\n","                segment_encoder = model.bert\n","            else:\n","                segment_encoder = model.deberta\n","            model_encoder = HierarchicalBert(encoder=segment_encoder,\n","                                             max_segments=data_args.max_segments,\n","                                             max_segment_length=data_args.max_seg_length)\n","            if config.model_type == 'bert':\n","                model.bert = model_encoder\n","            elif config.model_type == 'deberta':\n","                model.deberta = model_encoder\n","            else:\n","                raise NotImplementedError(f\"{config.model_type} is no supported yet!\")\n","        elif config.model_type == 'roberta':\n","            model_encoder = HierarchicalBert(encoder=model.roberta, max_segments=data_args.max_segments,\n","                                             max_segment_length=data_args.max_seg_length)\n","            model.roberta = model_encoder\n","            # Build a new classification layer, as well\n","            dense = nn.Linear(config.hidden_size, config.hidden_size)\n","            dense.load_state_dict(model.classifier.dense.state_dict())  # load weights\n","            dropout = nn.Dropout(config.hidden_dropout_prob).to(model.device)\n","            out_proj = nn.Linear(config.hidden_size, config.num_labels).to(model.device)\n","            out_proj.load_state_dict(model.classifier.out_proj.state_dict())  # load weights\n","            model.classifier = nn.Sequential(dense, dropout, out_proj).to(model.device)\n","        elif config.model_type in ['longformer', 'big_bird']:\n","            pass\n","        else:\n","            raise NotImplementedError(f\"{config.model_type} is no supported yet!\")\n","\n","    # Preprocessing the datasets\n","    # Padding strategy\n","    if data_args.pad_to_max_length:\n","        padding = \"max_length\"\n","    else:\n","        # We will pad later, dynamically at batch creation, to the max sequence length in each batch\n","        padding = False\n","\n","    def preprocess_function(examples):\n","        # Tokenize the texts\n","        if model_args.hierarchical:\n","            case_template = [[0] * data_args.max_seg_length]\n","            if config.model_type == 'roberta':\n","                batch = {'input_ids': [], 'attention_mask': []}\n","                for case in examples['text']:\n","                    case_encodings = tokenizer(case[:data_args.max_segments], padding=padding,\n","                                               max_length=data_args.max_seg_length, truncation=True)\n","                    batch['input_ids'].append(case_encodings['input_ids'] + case_template * (\n","                                data_args.max_segments - len(case_encodings['input_ids'])))\n","                    batch['attention_mask'].append(case_encodings['attention_mask'] + case_template * (\n","                                data_args.max_segments - len(case_encodings['attention_mask'])))\n","            else:\n","                batch = {'input_ids': [], 'attention_mask': [], 'token_type_ids': []}\n","                for case in examples['text']:\n","                    case_encodings = tokenizer(case[:data_args.max_segments], padding=padding,\n","                                               max_length=data_args.max_seg_length, truncation=True)\n","                    batch['input_ids'].append(case_encodings['input_ids'] + case_template * (\n","                            data_args.max_segments - len(case_encodings['input_ids'])))\n","                    batch['attention_mask'].append(case_encodings['attention_mask'] + case_template * (\n","                            data_args.max_segments - len(case_encodings['attention_mask'])))\n","                    batch['token_type_ids'].append(case_encodings['token_type_ids'] + case_template * (\n","                            data_args.max_segments - len(case_encodings['token_type_ids'])))\n","        elif config.model_type in ['longformer', 'big_bird']:\n","            cases = []\n","            max_position_embeddings = config.max_position_embeddings - 2 if config.model_type == 'longformer' \\\n","                else config.max_position_embeddings\n","            for case in examples['text']:\n","                cases.append(f' {tokenizer.sep_token} '.join(\n","                    [' '.join(fact.split()[:data_args.max_seg_length]) for fact in case[:data_args.max_segments]]))\n","            batch = tokenizer(cases, padding=padding, max_length=max_position_embeddings, truncation=True)\n","            if config.model_type == 'longformer':\n","                global_attention_mask = np.zeros((len(cases), max_position_embeddings), dtype=np.int32)\n","                # global attention on cls token\n","                global_attention_mask[:, 0] = 1\n","                batch['global_attention_mask'] = list(global_attention_mask)\n","        else:\n","            cases = []\n","            for case in examples['text']:\n","                cases.append(f'\\n'.join(case))\n","            batch = tokenizer(cases, padding=padding, max_length=512, truncation=True)\n","\n","        batch[\"labels\"] = [[1 if label in labels else 0 for label in label_list] for labels in examples[\"labels\"]]\n","\n","        return batch\n","\n","    if training_args.do_train:\n","        if data_args.max_train_samples is not None:\n","            train_dataset = train_dataset.select(range(data_args.max_train_samples))\n","        with training_args.main_process_first(desc=\"train dataset map pre-processing\"):\n","            train_dataset = train_dataset.map(\n","                preprocess_function,\n","                batched=True,\n","                load_from_cache_file=not data_args.overwrite_cache,\n","                desc=\"Running tokenizer on train dataset\",\n","            )\n","        # Log a few random samples from the training set:\n","        for index in random.sample(range(len(train_dataset)), 3):\n","            logger.info(f\"Sample {index} of the training set: {train_dataset[index]}.\")\n","\n","    if training_args.do_eval:\n","        if data_args.max_eval_samples is not None:\n","            eval_dataset = eval_dataset.select(range(data_args.max_eval_samples))\n","        with training_args.main_process_first(desc=\"validation dataset map pre-processing\"):\n","            eval_dataset = eval_dataset.map(\n","                preprocess_function,\n","                batched=True,\n","                load_from_cache_file=not data_args.overwrite_cache,\n","                desc=\"Running tokenizer on validation dataset\",\n","            )\n","\n","    if training_args.do_predict:\n","        if data_args.max_predict_samples is not None:\n","            predict_dataset = predict_dataset.select(range(data_args.max_predict_samples))\n","        with training_args.main_process_first(desc=\"prediction dataset map pre-processing\"):\n","            predict_dataset = predict_dataset.map(\n","                preprocess_function,\n","                batched=True,\n","                load_from_cache_file=not data_args.overwrite_cache,\n","                desc=\"Running tokenizer on prediction dataset\",\n","            )\n","\n","    # You can define your custom compute_metrics function. It takes an `EvalPrediction` object (a namedtuple with a\n","    # predictions and label_ids field) and has to return a dictionary string to float.\n","    def compute_metrics(p: EvalPrediction):\n","        # Fix gold labels\n","        y_true = np.zeros((p.label_ids.shape[0], p.label_ids.shape[1] + 1), dtype=np.int32)\n","        y_true[:, :-1] = p.label_ids\n","        y_true[:, -1] = (np.sum(p.label_ids, axis=1) == 0).astype('int32')\n","        # Fix predictions\n","        logits = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n","        preds = (expit(logits) > 0.5).astype('int32')\n","        y_pred = np.zeros((p.label_ids.shape[0], p.label_ids.shape[1] + 1), dtype=np.int32)\n","        y_pred[:, :-1] = preds\n","        y_pred[:, -1] = (np.sum(preds, axis=1) == 0).astype('int32')\n","        # Compute scores\n","        macro_f1 = f1_score(y_true=y_true, y_pred=y_pred, average='macro', zero_division=0)\n","        micro_f1 = f1_score(y_true=y_true, y_pred=y_pred, average='micro', zero_division=0)\n","        return {'macro-f1': macro_f1, 'micro-f1': micro_f1}\n","\n","    # Data collator will default to DataCollatorWithPadding, so we change it if we already did the padding.\n","    if data_args.pad_to_max_length:\n","        data_collator = default_data_collator\n","    elif training_args.fp16:\n","        data_collator = DataCollatorWithPadding(tokenizer, pad_to_multiple_of=8)\n","    else:\n","        data_collator = None\n","\n","    # Initialize our Trainer\n","    trainer = MultilabelTrainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=train_dataset if training_args.do_train else None,\n","        eval_dataset=eval_dataset if training_args.do_eval else None,\n","        compute_metrics=compute_metrics,\n","        tokenizer=tokenizer,\n","        data_collator=data_collator,\n","        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n","    )\n","\n","    # Training\n","    if training_args.do_train:\n","        checkpoint = None\n","        if training_args.resume_from_checkpoint is not None:\n","            checkpoint = training_args.resume_from_checkpoint\n","        elif last_checkpoint is not None:\n","            checkpoint = last_checkpoint\n","        train_result = trainer.train(resume_from_checkpoint=checkpoint)\n","        metrics = train_result.metrics\n","        max_train_samples = (\n","            data_args.max_train_samples if data_args.max_train_samples is not None else len(train_dataset)\n","        )\n","        metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n","\n","        trainer.save_model()  # Saves the tokenizer too for easy upload\n","\n","        trainer.log_metrics(\"train\", metrics)\n","        trainer.save_metrics(\"train\", metrics)\n","        trainer.save_state()\n","\n","    # Evaluation\n","    if training_args.do_eval:\n","        logger.info(\"*** Evaluate ***\")\n","        metrics = trainer.evaluate(eval_dataset=eval_dataset)\n","\n","        max_eval_samples = data_args.max_eval_samples if data_args.max_eval_samples is not None else len(eval_dataset)\n","        metrics[\"eval_samples\"] = min(max_eval_samples, len(eval_dataset))\n","\n","        trainer.log_metrics(\"eval\", metrics)\n","        trainer.save_metrics(\"eval\", metrics)\n","\n","    # Prediction\n","    if training_args.do_predict:\n","        logger.info(\"*** Predict ***\")\n","        predictions, labels, metrics = trainer.predict(predict_dataset, metric_key_prefix=\"predict\")\n","\n","        max_predict_samples = (\n","            data_args.max_predict_samples if data_args.max_predict_samples is not None else len(predict_dataset)\n","        )\n","        metrics[\"predict_samples\"] = min(max_predict_samples, len(predict_dataset))\n","\n","        trainer.log_metrics(\"predict\", metrics)\n","        trainer.save_metrics(\"predict\", metrics)\n","\n","        output_predict_file = os.path.join(training_args.output_dir, \"test_predictions.csv\")\n","        if trainer.is_world_process_zero():\n","            with open(output_predict_file, \"w\") as writer:\n","                for index, pred_list in enumerate(predictions[0]):\n","                    pred_line = '\\t'.join([f'{pred:.5f}' for pred in pred_list])\n","                    writer.write(f\"{index}\\t{pred_line}\\n\")\n","\n","    # Clean up checkpoints\n","    checkpoints = [filepath for filepath in glob.glob(f'{training_args.output_dir}/*/') if '/checkpoint' in filepath]\n","    for checkpoint in checkpoints:\n","        shutil.rmtree(checkpoint)\n","\n","\n","if __name__ == \"__main__\":\n","    #For training\n","\n","    # For Evaluation\n","    training_args = TrainingArguments(\n","        do_train = True,\n","        do_eval = True,\n","        do_predict = True,\n","        output_dir=os.getcwd(),\n","        overwrite_output_dir=True,\n","        num_train_epochs=1,\n","        per_device_train_batch_size=4,\n","        per_device_eval_batch_size=4,\n","        save_steps=500,\n","        save_total_limit=2,\n","        fp16=False,\n","        logging_dir=\"./logs\",\n","        logging_steps=100,\n","        evaluation_strategy=\"steps\",\n","        eval_steps=500,\n","        logging_first_step=False,\n","        load_best_model_at_end = True,\n","        metric_for_best_model=\"micro-f1\",\n","    )\n","    main(training_args)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":740,"referenced_widgets":["2f89f97c7368470fb0ef3ce28d8a11b4","ce5f656f447048ccac175fd73b55e58e","cdc34063596945faaa7644096d0ec815","256462799bbf436586f10cef999b8f63","5838e4540e2644e4a093edd3101ef155","db3b2a0847c145d7ac8a322f855a5e72","e44e0af0661d4f17ab6c7cdbb0605175","770e708189cf4885af012f324a7869ec","c6b0898c534e4bc2a900af64ce4ed7dd","f026678d68dd40649278ba05fd27b92e","b278865cbfa849558704797ee74a78f4","5c8c76c1130c4440a372955e36cc8902","92d0c2b058fc41ecbc5f22c71d16c8f3","0b7920ff168d4b61b01dc47b555678e1","d31746dceff74918813229b3e088a3d4","92d91e48c97a45cba44c53a46c4ed910","b15ca471fcee45d8911723f86888f727","8e48b8b7563e4725aabc1b461495142d","1366e323131b4c688db200c8ec755555","b7cc7ebbd2a24c0fa304dc2f0ae64710","4e6333808d72440d9f31cea54a125bf5","7aa3f25a952349d6850a186a2cf0a9bf","b5ec0a07e0234c729246a99a5d9a3e83","0d6a3fefdefc47cfa681e9fbee26ab94","65abf54748d54aafa76decf30d916b7b","ad6017cd3b244c2783fe093cc076b48f","62d002120a224ae4bcd29532844e3853","0b795e964bb04df5a043fe8e677c0a56","e29b4885a96b45d6829cf979d2708c94","645c1dc1b0314456a684efb79886e1c5","73c441cb624c42b19d95376a6bee0f68","225717a7e11843bca9cf9478c1d4af5e","bd65a300338a4693a7322b6dab0c7ac4"]},"id":"_9_y1P6S_dum","executionInfo":{"status":"error","timestamp":1692069094396,"user_tz":-60,"elapsed":121196,"user":{"displayName":"Sumit Gupta","userId":"07308348120090087318"}},"outputId":"32499538-85ab-4aec-a6f5-5f9d667d4324"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:__main__:Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False\n","[WARNING|modeling_utils.py:3331] 2023-08-15 03:09:43,349 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["Running tokenizer on train dataset:   0%|          | 0/9000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f89f97c7368470fb0ef3ce28d8a11b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Running tokenizer on validation dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c8c76c1130c4440a372955e36cc8902"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Running tokenizer on prediction dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5ec0a07e0234c729246a99a5d9a3e83"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='39' max='2250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [  39/2250 00:43 < 42:59, 0.86 it/s, Epoch 0.02/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-6d817bdf8f71>\u001b[0m in \u001b[0;36m<cell line: 528>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0mmetric_for_best_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"micro-f1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     )\n\u001b[0;32m--> 552\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-35-6d817bdf8f71>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(training_args)\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlast_checkpoint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m         \u001b[0mtrain_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         max_train_samples = (\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1537\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1538\u001b[0m         )\n\u001b[0;32m-> 1539\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1540\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1541\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1808\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1809\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1811\u001b[0m                 if (\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2663\u001b[0m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2664\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2665\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2667\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1851\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0munscale_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}